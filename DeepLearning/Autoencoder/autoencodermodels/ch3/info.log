run_train.py --max-value 14054 --datadir . --train-metafile /mountb/single_cell_flist/train_ch3_small.csv --val-metafile /mountb/single_cell_flist/val_ch3_small.csv --save-dir /mountb/autoencoder/ch3 --model-type AE46 --dataset-type 46 --latent-dims 2048
Namespace(batch_size=128, datadir='.', dataset_type='46', debug_mode=False, latent_dims=2048, learning_rate=0.001, max_epochs=2000, max_value=14054, model_type='AE46', num_workers=8, optimizer='adam', save_dir='/mountb/autoencoder/ch3', save_freq=50, seed=42, train_metafile='/mountb/single_cell_flist/train_ch3_small.csv', val_metafile='/mountb/single_cell_flist/val_ch3_small.csv', weight_decay=1e-05)
AE46(
  (encoder): Sequential(
    (0): Conv2d(1, 46, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(46, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(92, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(184, 368, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (12): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (fc1): Linear(in_features=1472, out_features=2048, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): ConvTranspose2d(368, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): ConvTranspose2d(184, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
    (9): ConvTranspose2d(92, 46, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace=True)
    (12): ConvTranspose2d(46, 1, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Sigmoid()
  )
  (d1): Linear(in_features=2048, out_features=1472, bias=True)
  (mseloss): MSELoss()
)
Epoch 0:
Training summary: {'train_recon_loss': 0.0071696993035540845, 'train_loss': 0.0071696993035540845}
Evaluation summary: {'test_recon_loss': 0.0015156755873811428, 'test_loss': 0.0015156755873811428}
Best loss: 0.0015156755873811428
Epoch 1:
Training summary: {'train_recon_loss': 0.0009247364615980375, 'train_loss': 0.0009247364615980375}
Evaluation summary: {'test_recon_loss': 0.0006827457819113767, 'test_loss': 0.0006827457819113767}
Best loss: 0.0006827457819113767
Epoch 2:
Training summary: {'train_recon_loss': 0.0007049073641539746, 'train_loss': 0.0007049073641539746}
Evaluation summary: {'test_recon_loss': 0.0007155781075604198, 'test_loss': 0.0007155781075604198}
Best loss: 0.0006827457819113767
Epoch 3:
Training summary: {'train_recon_loss': 0.0006586538175040323, 'train_loss': 0.0006586538175040323}
Evaluation summary: {'test_recon_loss': 0.0013190871996150572, 'test_loss': 0.0013190871996150572}
Best loss: 0.0006827457819113767
Epoch 4:
Training summary: {'train_recon_loss': 0.0007108070198286082, 'train_loss': 0.0007108070198286082}
Evaluation summary: {'test_recon_loss': 0.00072339004206086, 'test_loss': 0.00072339004206086}
Best loss: 0.0006827457819113767
Epoch 5:
Training summary: {'train_recon_loss': 0.0005449296444014387, 'train_loss': 0.0005449296444014387}
Evaluation summary: {'test_recon_loss': 0.00048107086525908644, 'test_loss': 0.00048107086525908644}
Best loss: 0.00048107086525908644
Epoch 6:
Training summary: {'train_recon_loss': 0.00046420700114027837, 'train_loss': 0.00046420700114027837}
Evaluation summary: {'test_recon_loss': 0.00042275377307016333, 'test_loss': 0.00042275377307016333}
Best loss: 0.00042275377307016333
Epoch 7:
Training summary: {'train_recon_loss': 0.00042941240852331733, 'train_loss': 0.00042941240852331733}
Evaluation summary: {'test_recon_loss': 0.0003804888184133665, 'test_loss': 0.0003804888184133665}
Best loss: 0.0003804888184133665
Epoch 8:
Training summary: {'train_recon_loss': 0.00039265117973711185, 'train_loss': 0.00039265117973711185}
Evaluation summary: {'test_recon_loss': 0.00031782266549058895, 'test_loss': 0.00031782266549058895}
Best loss: 0.00031782266549058895
Epoch 9:
Training summary: {'train_recon_loss': 0.00038394748757024805, 'train_loss': 0.00038394748757024805}
Evaluation summary: {'test_recon_loss': 0.000469605275008079, 'test_loss': 0.000469605275008079}
Best loss: 0.00031782266549058895
Epoch 10:
Training summary: {'train_recon_loss': 0.00037794314801418207, 'train_loss': 0.00037794314801418207}
Evaluation summary: {'test_recon_loss': 0.00031922087318005614, 'test_loss': 0.00031922087318005614}
Best loss: 0.00031782266549058895
Epoch 11:
Training summary: {'train_recon_loss': 0.0003667812065668516, 'train_loss': 0.0003667812065668516}
Evaluation summary: {'test_recon_loss': 0.0002883570862572956, 'test_loss': 0.0002883570862572956}
Best loss: 0.0002883570862572956
Epoch 12:
Training summary: {'train_recon_loss': 0.0003659610480780534, 'train_loss': 0.0003659610480780534}
Evaluation summary: {'test_recon_loss': 0.0002683631256472924, 'test_loss': 0.0002683631256472924}
Best loss: 0.0002683631256472924
Epoch 13:
Training summary: {'train_recon_loss': 0.0003617761088243121, 'train_loss': 0.0003617761088243121}
Evaluation summary: {'test_recon_loss': 0.00033161343166377376, 'test_loss': 0.00033161343166377376}
Best loss: 0.0002683631256472924
Epoch 14:
Training summary: {'train_recon_loss': 0.0005973304788271035, 'train_loss': 0.0005973304788271035}
Evaluation summary: {'test_recon_loss': 0.0008051349746369186, 'test_loss': 0.0008051349746369186}
Best loss: 0.0002683631256472924
Epoch 15:
Training summary: {'train_recon_loss': 0.0003997089301226517, 'train_loss': 0.0003997089301226517}
Evaluation summary: {'test_recon_loss': 0.00028631390155424343, 'test_loss': 0.00028631390155424343}
Best loss: 0.0002683631256472924
Epoch 16:
Training summary: {'train_recon_loss': 0.00034688993337787935, 'train_loss': 0.00034688993337787935}
Evaluation summary: {'test_recon_loss': 0.00029173079052805597, 'test_loss': 0.00029173079052805597}
Best loss: 0.0002683631256472924
Epoch 17:
Training summary: {'train_recon_loss': 0.0003525439930626012, 'train_loss': 0.0003525439930626012}
Evaluation summary: {'test_recon_loss': 0.0007610425631382789, 'test_loss': 0.0007610425631382789}
Best loss: 0.0002683631256472924
Epoch 18:
Training summary: {'train_recon_loss': 0.0003430622611258606, 'train_loss': 0.0003430622611258606}
Evaluation summary: {'test_recon_loss': 0.00027643414099423516, 'test_loss': 0.00027643414099423516}
Best loss: 0.0002683631256472924
Epoch 19:
Training summary: {'train_recon_loss': 0.00033884773317493263, 'train_loss': 0.00033884773317493263}
Evaluation summary: {'test_recon_loss': 0.0002914019703984619, 'test_loss': 0.0002914019703984619}
Best loss: 0.0002683631256472924
Epoch 20:
Training summary: {'train_recon_loss': 0.0003399825599133004, 'train_loss': 0.0003399825599133004}
Evaluation summary: {'test_recon_loss': 0.0002803048330235334, 'test_loss': 0.0002803048330235334}
Best loss: 0.0002683631256472924
Epoch 21:
Training summary: {'train_recon_loss': 0.0003278979149187564, 'train_loss': 0.0003278979149187564}
Evaluation summary: {'test_recon_loss': 0.0002971161982349103, 'test_loss': 0.0002971161982349103}
Best loss: 0.0002683631256472924
Epoch 22:
Training summary: {'train_recon_loss': 0.0003537367403315129, 'train_loss': 0.0003537367403315129}
Evaluation summary: {'test_recon_loss': 0.08304817056277294, 'test_loss': 0.08304817056277294}
Best loss: 0.0002683631256472924
Epoch 23:
Training summary: {'train_recon_loss': 0.0006516446773542419, 'train_loss': 0.0006516446773542419}
Evaluation summary: {'test_recon_loss': 0.000311143928309167, 'test_loss': 0.000311143928309167}
Best loss: 0.0002683631256472924
Epoch 24:
Training summary: {'train_recon_loss': 0.0003244011525248585, 'train_loss': 0.0003244011525248585}
Evaluation summary: {'test_recon_loss': 0.0002951514987703413, 'test_loss': 0.0002951514987703413}
Best loss: 0.0002683631256472924
Epoch 25:
Training summary: {'train_recon_loss': 0.0003110199264072165, 'train_loss': 0.0003110199264072165}
Evaluation summary: {'test_recon_loss': 0.0003028119357292567, 'test_loss': 0.0003028119357292567}
Best loss: 0.0002683631256472924
Epoch 26:
Training summary: {'train_recon_loss': 0.0003047637814613119, 'train_loss': 0.0003047637814613119}
Evaluation summary: {'test_recon_loss': 0.00022631084199954438, 'test_loss': 0.00022631084199954438}
Best loss: 0.00022631084199954438
Epoch 27:
Training summary: {'train_recon_loss': 0.0003015903004053522, 'train_loss': 0.0003015903004053522}
Evaluation summary: {'test_recon_loss': 0.00022232803606843417, 'test_loss': 0.00022232803606843417}
Best loss: 0.00022232803606843417
Epoch 28:
Training summary: {'train_recon_loss': 0.0003072517904625342, 'train_loss': 0.0003072517904625342}
Evaluation summary: {'test_recon_loss': 0.00024296544782859394, 'test_loss': 0.00024296544782859394}
Best loss: 0.00022232803606843417
Epoch 29:
Training summary: {'train_recon_loss': 0.00030017694543311594, 'train_loss': 0.00030017694543311594}
Evaluation summary: {'test_recon_loss': 0.00035033681771498245, 'test_loss': 0.00035033681771498245}
Best loss: 0.00022232803606843417
Epoch 30:
Training summary: {'train_recon_loss': 0.0002887818676490722, 'train_loss': 0.0002887818676490722}
Evaluation summary: {'test_recon_loss': 0.00025628069888792237, 'test_loss': 0.00025628069888792237}
Best loss: 0.00022232803606843417
Epoch 31:
Training summary: {'train_recon_loss': 0.00047621405236616347, 'train_loss': 0.00047621405236616347}
Evaluation summary: {'test_recon_loss': 0.0036842703068855967, 'test_loss': 0.0036842703068855967}
Best loss: 0.00022232803606843417
Epoch 32:
Training summary: {'train_recon_loss': 0.0007750938513111344, 'train_loss': 0.0007750938513111344}
Evaluation summary: {'test_recon_loss': 0.00042817131811013744, 'test_loss': 0.00042817131811013744}
Best loss: 0.00022232803606843417
Epoch 33:
Training summary: {'train_recon_loss': 0.0003277775308062971, 'train_loss': 0.0003277775308062971}
Evaluation summary: {'test_recon_loss': 0.0002873850672751967, 'test_loss': 0.0002873850672751967}
Best loss: 0.00022232803606843417
Epoch 34:
Training summary: {'train_recon_loss': 0.0003028732737394254, 'train_loss': 0.0003028732737394254}
Evaluation summary: {'test_recon_loss': 0.00023126410092946182, 'test_loss': 0.00023126410092946182}
Best loss: 0.00022232803606843417
Epoch 35:
Training summary: {'train_recon_loss': 0.00029563625748746424, 'train_loss': 0.00029563625748746424}
Evaluation summary: {'test_recon_loss': 0.0004040473817014579, 'test_loss': 0.0004040473817014579}
Best loss: 0.00022232803606843417
Epoch 36:
Training summary: {'train_recon_loss': 0.00029672300505785896, 'train_loss': 0.00029672300505785896}
Evaluation summary: {'test_recon_loss': 0.0003050032838000545, 'test_loss': 0.0003050032838000545}
Best loss: 0.00022232803606843417
Epoch 37:
Training summary: {'train_recon_loss': 0.0002761972778519556, 'train_loss': 0.0002761972778519556}
Evaluation summary: {'test_recon_loss': 0.00020054900053814468, 'test_loss': 0.00020054900053814468}
Best loss: 0.00020054900053814468
Epoch 38:
Training summary: {'train_recon_loss': 0.0006511981331442183, 'train_loss': 0.0006511981331442183}
Evaluation summary: {'test_recon_loss': 0.0022400896193669837, 'test_loss': 0.0022400896193669837}
Best loss: 0.00020054900053814468
Epoch 39:
Training summary: {'train_recon_loss': 0.0005146338944123843, 'train_loss': 0.0005146338944123843}
Evaluation summary: {'test_recon_loss': 0.00032662114164973375, 'test_loss': 0.00032662114164973375}
Best loss: 0.00020054900053814468
Epoch 40:
Training summary: {'train_recon_loss': 0.0002849191234559365, 'train_loss': 0.0002849191234559365}
Evaluation summary: {'test_recon_loss': 0.00022818248160598071, 'test_loss': 0.00022818248160598071}
Best loss: 0.00020054900053814468
Epoch 41:
Training summary: {'train_recon_loss': 0.0002804512163743872, 'train_loss': 0.0002804512163743872}
Evaluation summary: {'test_recon_loss': 0.00022520388401978532, 'test_loss': 0.00022520388401978532}
Best loss: 0.00020054900053814468
Epoch 42:
Training summary: {'train_recon_loss': 0.0002758034354083196, 'train_loss': 0.0002758034354083196}
Evaluation summary: {'test_recon_loss': 0.00019811644192715616, 'test_loss': 0.00019811644192715616}
Best loss: 0.00019811644192715616
Epoch 43:
Training summary: {'train_recon_loss': 0.00026653958348781133, 'train_loss': 0.00026653958348781133}
Evaluation summary: {'test_recon_loss': 0.00021540328567562906, 'test_loss': 0.00021540328567562906}
Best loss: 0.00019811644192715616
Epoch 44:
Training summary: {'train_recon_loss': 0.00026496033015160696, 'train_loss': 0.00026496033015160696}
Evaluation summary: {'test_recon_loss': 0.0002597150730089482, 'test_loss': 0.0002597150730089482}
Best loss: 0.00019811644192715616
Epoch 45:
Training summary: {'train_recon_loss': 0.0002667629377494395, 'train_loss': 0.0002667629377494395}
Evaluation summary: {'test_recon_loss': 0.0002591688413815314, 'test_loss': 0.0002591688413815314}
Best loss: 0.00019811644192715616
Epoch 46:
Training summary: {'train_recon_loss': 0.0002576776486270249, 'train_loss': 0.0002576776486270249}
Evaluation summary: {'test_recon_loss': 0.0001920176063951467, 'test_loss': 0.0001920176063951467}
Best loss: 0.0001920176063951467
Epoch 47:
Training summary: {'train_recon_loss': 0.0008122504723970799, 'train_loss': 0.0008122504723970799}
Evaluation summary: {'test_recon_loss': 0.000463340039958181, 'test_loss': 0.000463340039958181}
Best loss: 0.0001920176063951467
Epoch 48:
Training summary: {'train_recon_loss': 0.00032855475906265377, 'train_loss': 0.00032855475906265377}
Evaluation summary: {'test_recon_loss': 0.00028040021397673286, 'test_loss': 0.00028040021397673286}
Best loss: 0.0001920176063951467
Epoch 49:
Training summary: {'train_recon_loss': 0.0002913457369413342, 'train_loss': 0.0002913457369413342}
Evaluation summary: {'test_recon_loss': 0.0002081827085340337, 'test_loss': 0.0002081827085340337}
Best loss: 0.0001920176063951467
Epoch 50:
Training summary: {'train_recon_loss': 0.00026598085339556274, 'train_loss': 0.00026598085339556274}
Evaluation summary: {'test_recon_loss': 0.0002316562774326095, 'test_loss': 0.0002316562774326095}
Best loss: 0.0001920176063951467
Epoch 51:
Training summary: {'train_recon_loss': 0.00026299226930872585, 'train_loss': 0.00026299226930872585}
Evaluation summary: {'test_recon_loss': 0.00045521487693066183, 'test_loss': 0.00045521487693066183}
Best loss: 0.0001920176063951467
Epoch 52:
Training summary: {'train_recon_loss': 0.0002688189917097985, 'train_loss': 0.0002688189917097985}
Evaluation summary: {'test_recon_loss': 0.00019368490215733336, 'test_loss': 0.00019368490215733336}
Best loss: 0.0001920176063951467
Epoch 53:
Training summary: {'train_recon_loss': 0.00025890623867719876, 'train_loss': 0.00025890623867719876}
Evaluation summary: {'test_recon_loss': 0.0002488154049575855, 'test_loss': 0.0002488154049575855}
Best loss: 0.0001920176063951467
Epoch 54:
Training summary: {'train_recon_loss': 0.0002534143766450001, 'train_loss': 0.0002534143766450001}
Evaluation summary: {'test_recon_loss': 0.00025615779363575463, 'test_loss': 0.00025615779363575463}
Best loss: 0.0001920176063951467
Epoch 55:
Training summary: {'train_recon_loss': 0.0002677457311423907, 'train_loss': 0.0002677457311423907}
Evaluation summary: {'test_recon_loss': 0.0002003179872575652, 'test_loss': 0.0002003179872575652}
Best loss: 0.0001920176063951467
Epoch 56:
Training summary: {'train_recon_loss': 0.00026042612097057423, 'train_loss': 0.00026042612097057423}
Evaluation summary: {'test_recon_loss': 0.00018446354614697823, 'test_loss': 0.00018446354614697823}
Best loss: 0.00018446354614697823
Epoch 57:
Training summary: {'train_recon_loss': 0.0004965394508110462, 'train_loss': 0.0004965394508110462}
Evaluation summary: {'test_recon_loss': 0.0008223495245042352, 'test_loss': 0.0008223495245042352}
Best loss: 0.00018446354614697823
Epoch 58:
Training summary: {'train_recon_loss': 0.00043877710277389834, 'train_loss': 0.00043877710277389834}
Evaluation summary: {'test_recon_loss': 0.0002942772921107729, 'test_loss': 0.0002942772921107729}
Best loss: 0.00018446354614697823
Epoch 59:
Training summary: {'train_recon_loss': 0.0002909990585147478, 'train_loss': 0.0002909990585147478}
Evaluation summary: {'test_recon_loss': 0.00023318023511681568, 'test_loss': 0.00023318023511681568}
Best loss: 0.00018446354614697823
Epoch 60:
Training summary: {'train_recon_loss': 0.00027490784007378827, 'train_loss': 0.00027490784007378827}
Evaluation summary: {'test_recon_loss': 0.00020947475288842483, 'test_loss': 0.00020947475288842483}
Best loss: 0.00018446354614697823
Epoch 61:
Training summary: {'train_recon_loss': 0.0002600704489204649, 'train_loss': 0.0002600704489204649}
Evaluation summary: {'test_recon_loss': 0.00021599990534223475, 'test_loss': 0.00021599990534223475}
Best loss: 0.00018446354614697823
Epoch 62:
Training summary: {'train_recon_loss': 0.00026094707912438845, 'train_loss': 0.00026094707912438845}
Evaluation summary: {'test_recon_loss': 0.00020949195211451653, 'test_loss': 0.00020949195211451653}
Best loss: 0.00018446354614697823
Epoch 63:
Training summary: {'train_recon_loss': 0.0002740348181020889, 'train_loss': 0.0002740348181020889}
Evaluation summary: {'test_recon_loss': 0.00023990659294297447, 'test_loss': 0.00023990659294297447}
Best loss: 0.00018446354614697823
Epoch 64:
Training summary: {'train_recon_loss': 0.0002560644953187914, 'train_loss': 0.0002560644953187914}
Evaluation summary: {'test_recon_loss': 0.0004952014466077429, 'test_loss': 0.0004952014466077429}
Best loss: 0.00018446354614697823
Epoch 65:
Training summary: {'train_recon_loss': 0.0002649153392548449, 'train_loss': 0.0002649153392548449}
Evaluation summary: {'test_recon_loss': 0.0004577349329825393, 'test_loss': 0.0004577349329825393}
Best loss: 0.00018446354614697823
Epoch 66:
Training summary: {'train_recon_loss': 0.0002514526022294973, 'train_loss': 0.0002514526022294973}
Evaluation summary: {'test_recon_loss': 0.0003814064333084903, 'test_loss': 0.0003814064333084903}
Best loss: 0.00018446354614697823
Epoch 67:
Training summary: {'train_recon_loss': 0.0002611271311284632, 'train_loss': 0.0002611271311284632}
Evaluation summary: {'test_recon_loss': 0.00020087408255134329, 'test_loss': 0.00020087408255134329}
Best loss: 0.00018446354614697823
Epoch 68:
Training summary: {'train_recon_loss': 0.00042129743699471434, 'train_loss': 0.00042129743699471434}
Evaluation summary: {'test_recon_loss': 0.0035137318066050856, 'test_loss': 0.0035137318066050856}
Best loss: 0.00018446354614697823
Epoch 69:
Training summary: {'train_recon_loss': 0.0006632776315685589, 'train_loss': 0.0006632776315685589}
Evaluation summary: {'test_recon_loss': 0.00025121389423502833, 'test_loss': 0.00025121389423502833}
Best loss: 0.00018446354614697823
Epoch 70:
Training summary: {'train_recon_loss': 0.00029890642727868383, 'train_loss': 0.00029890642727868383}
Evaluation summary: {'test_recon_loss': 0.00020952374811508177, 'test_loss': 0.00020952374811508177}
Best loss: 0.00018446354614697823
Epoch 71:
Training summary: {'train_recon_loss': 0.0002631536582244193, 'train_loss': 0.0002631536582244193}
Evaluation summary: {'test_recon_loss': 0.0002075118141028997, 'test_loss': 0.0002075118141028997}
Best loss: 0.00018446354614697823
Epoch 72:
Training summary: {'train_recon_loss': 0.0002624155008063372, 'train_loss': 0.0002624155008063372}
Evaluation summary: {'test_recon_loss': 0.000470723062323049, 'test_loss': 0.000470723062323049}
Best loss: 0.00018446354614697823
Epoch 73:
Training summary: {'train_recon_loss': 0.0002556704488398212, 'train_loss': 0.0002556704488398212}
Evaluation summary: {'test_recon_loss': 0.0002867223996658758, 'test_loss': 0.0002867223996658758}
Best loss: 0.00018446354614697823
Epoch 74:
Training summary: {'train_recon_loss': 0.000509355691286888, 'train_loss': 0.000509355691286888}
Evaluation summary: {'test_recon_loss': 0.0027465466090272157, 'test_loss': 0.0027465466090272157}
Best loss: 0.00018446354614697823
Epoch 75:
Training summary: {'train_recon_loss': 0.0009755865837753398, 'train_loss': 0.0009755865837753398}
Evaluation summary: {'test_recon_loss': 0.00047655782063168973, 'test_loss': 0.00047655782063168973}
Best loss: 0.00018446354614697823
Epoch 76:
Training summary: {'train_recon_loss': 0.0003467991341318028, 'train_loss': 0.0003467991341318028}
Evaluation summary: {'test_recon_loss': 0.0002381802157703151, 'test_loss': 0.0002381802157703151}
Best loss: 0.00018446354614697823
Epoch 77:
Training summary: {'train_recon_loss': 0.0003057705946928941, 'train_loss': 0.0003057705946928941}
Evaluation summary: {'test_recon_loss': 0.0002712101643351522, 'test_loss': 0.0002712101643351522}
Best loss: 0.00018446354614697823
Epoch 78:
Training summary: {'train_recon_loss': 0.0002879889619922554, 'train_loss': 0.0002879889619922554}
Evaluation summary: {'test_recon_loss': 0.0004621583403940371, 'test_loss': 0.0004621583403940371}
Best loss: 0.00018446354614697823
Epoch 79:
Training summary: {'train_recon_loss': 0.0002766469727830163, 'train_loss': 0.0002766469727830163}
Evaluation summary: {'test_recon_loss': 0.00022559863837903012, 'test_loss': 0.00022559863837903012}
Best loss: 0.00018446354614697823
Epoch 80:
Training summary: {'train_recon_loss': 0.0002791019869619046, 'train_loss': 0.0002791019869619046}
Evaluation summary: {'test_recon_loss': 0.00021044254507791697, 'test_loss': 0.00021044254507791697}
Best loss: 0.00018446354614697823
Epoch 81:
Training summary: {'train_recon_loss': 0.00027215936338523267, 'train_loss': 0.00027215936338523267}
Evaluation summary: {'test_recon_loss': 0.0002181834224294694, 'test_loss': 0.0002181834224294694}
Best loss: 0.00018446354614697823
Epoch 82:
Training summary: {'train_recon_loss': 0.00025214576936786006, 'train_loss': 0.00025214576936786006}
Evaluation summary: {'test_recon_loss': 0.0003777999834285461, 'test_loss': 0.0003777999834285461}
Best loss: 0.00018446354614697823
Epoch 83:
Training summary: {'train_recon_loss': 0.0002694942425095635, 'train_loss': 0.0002694942425095635}
Evaluation summary: {'test_recon_loss': 0.00023816520708365012, 'test_loss': 0.00023816520708365012}
Best loss: 0.00018446354614697823
Epoch 84:
Training summary: {'train_recon_loss': 0.00026085939625065854, 'train_loss': 0.00026085939625065854}
Evaluation summary: {'test_recon_loss': 0.0002049691840525353, 'test_loss': 0.0002049691840525353}
Best loss: 0.00018446354614697823
Epoch 85:
Training summary: {'train_recon_loss': 0.00026344352425137753, 'train_loss': 0.00026344352425137753}
Evaluation summary: {'test_recon_loss': 0.00019430846354724705, 'test_loss': 0.00019430846354724705}
Best loss: 0.00018446354614697823
Epoch 86:
Training summary: {'train_recon_loss': 0.0002528345221853089, 'train_loss': 0.0002528345221853089}
Evaluation summary: {'test_recon_loss': 0.00020094297889767517, 'test_loss': 0.00020094297889767517}
Best loss: 0.00018446354614697823
Epoch 87:
Training summary: {'train_recon_loss': 0.0009248892734452094, 'train_loss': 0.0009248892734452094}
Evaluation summary: {'test_recon_loss': 0.0006973538554269231, 'test_loss': 0.0006973538554269231}
Best loss: 0.00018446354614697823
Epoch 88:
Training summary: {'train_recon_loss': 0.0004377104406516143, 'train_loss': 0.0004377104406516143}
Evaluation summary: {'test_recon_loss': 0.0003954348432749924, 'test_loss': 0.0003954348432749924}
Best loss: 0.00018446354614697823
Epoch 89:
Training summary: {'train_recon_loss': 0.0003029303429829279, 'train_loss': 0.0003029303429829279}
Evaluation summary: {'test_recon_loss': 0.00024152532694697866, 'test_loss': 0.00024152532694697866}
Best loss: 0.00018446354614697823
Epoch 90:
Training summary: {'train_recon_loss': 0.0002787911377159398, 'train_loss': 0.0002787911377159398}
Evaluation summary: {'test_recon_loss': 0.00023372188070939186, 'test_loss': 0.00023372188070939186}
Best loss: 0.00018446354614697823
Epoch 91:
Training summary: {'train_recon_loss': 0.0002721689909426314, 'train_loss': 0.0002721689909426314}
Evaluation summary: {'test_recon_loss': 0.00021235583814443134, 'test_loss': 0.00021235583814443134}
Best loss: 0.00018446354614697823
Epoch 92:
Training summary: {'train_recon_loss': 0.00025615597685943795, 'train_loss': 0.00025615597685943795}
Evaluation summary: {'test_recon_loss': 0.00022011542867246222, 'test_loss': 0.00022011542867246222}
Best loss: 0.00018446354614697823
Epoch 93:
Training summary: {'train_recon_loss': 0.0005883452854649484, 'train_loss': 0.0005883452854649484}
Evaluation summary: {'test_recon_loss': 0.0016744144945061636, 'test_loss': 0.0016744144945061636}
Best loss: 0.00018446354614697823
Epoch 94:
Training summary: {'train_recon_loss': 0.0005317638174555838, 'train_loss': 0.0005317638174555838}
Evaluation summary: {'test_recon_loss': 0.0003430744002370952, 'test_loss': 0.0003430744002370952}
Best loss: 0.00018446354614697823
Epoch 95:
Training summary: {'train_recon_loss': 0.0002930369658511657, 'train_loss': 0.0002930369658511657}
Evaluation summary: {'test_recon_loss': 0.00026763182206878566, 'test_loss': 0.00026763182206878566}
Best loss: 0.00018446354614697823
Epoch 96:
Training summary: {'train_recon_loss': 0.00027253074677313047, 'train_loss': 0.00027253074677313047}
Evaluation summary: {'test_recon_loss': 0.0012143016570940566, 'test_loss': 0.0012143016570940566}
Best loss: 0.00018446354614697823
Epoch 97:
Training summary: {'train_recon_loss': 0.00027192312319698807, 'train_loss': 0.00027192312319698807}
Evaluation summary: {'test_recon_loss': 0.0005401897571006655, 'test_loss': 0.0005401897571006655}
Best loss: 0.00018446354614697823
Epoch 98:
Training summary: {'train_recon_loss': 0.0002568393595316759, 'train_loss': 0.0002568393595316759}
Evaluation summary: {'test_recon_loss': 0.00029895504331719445, 'test_loss': 0.00029895504331719445}
Best loss: 0.00018446354614697823
Epoch 99:
Training summary: {'train_recon_loss': 0.00025658724798599607, 'train_loss': 0.00025658724798599607}
Evaluation summary: {'test_recon_loss': 0.000483919223078824, 'test_loss': 0.000483919223078824}
Best loss: 0.00018446354614697823
Epoch 100:
Training summary: {'train_recon_loss': 0.000257088991107054, 'train_loss': 0.000257088991107054}
Evaluation summary: {'test_recon_loss': 0.0003002140055728004, 'test_loss': 0.0003002140055728004}
Best loss: 0.00018446354614697823
Epoch 101:
Training summary: {'train_recon_loss': 0.00026197300125744427, 'train_loss': 0.00026197300125744427}
Evaluation summary: {'test_recon_loss': 0.00022450703494043963, 'test_loss': 0.00022450703494043963}
Best loss: 0.00018446354614697823
Epoch 102:
Training summary: {'train_recon_loss': 0.0006959743525200636, 'train_loss': 0.0006959743525200636}
Evaluation summary: {'test_recon_loss': 0.0005518425518704146, 'test_loss': 0.0005518425518704146}
Best loss: 0.00018446354614697823
Epoch 103:
Training summary: {'train_recon_loss': 0.0003056409599073562, 'train_loss': 0.0003056409599073562}
Evaluation summary: {'test_recon_loss': 0.00030950025654514064, 'test_loss': 0.00030950025654514064}
Best loss: 0.00018446354614697823
Epoch 104:
Training summary: {'train_recon_loss': 0.0002649654778530541, 'train_loss': 0.0002649654778530541}
Evaluation summary: {'test_recon_loss': 0.0002743800156675583, 'test_loss': 0.0002743800156675583}
Best loss: 0.00018446354614697823
Epoch 105:
Training summary: {'train_recon_loss': 0.0002472305322471552, 'train_loss': 0.0002472305322471552}
Evaluation summary: {'test_recon_loss': 0.00020795541365893242, 'test_loss': 0.00020795541365893242}
Best loss: 0.00018446354614697823
Epoch 106:
Training summary: {'train_recon_loss': 0.0002549124025787448, 'train_loss': 0.0002549124025787448}
Evaluation summary: {'test_recon_loss': 0.00023811153278440988, 'test_loss': 0.00023811153278440988}
Best loss: 0.00018446354614697823
Epoch 107:
Training summary: {'train_recon_loss': 0.0002699192038639743, 'train_loss': 0.0002699192038639743}
Evaluation summary: {'test_recon_loss': 0.00019017808603162567, 'test_loss': 0.00019017808603162567}
Best loss: 0.00018446354614697823
Epoch 108:
Training summary: {'train_recon_loss': 0.0002536560632603145, 'train_loss': 0.0002536560632603145}
Evaluation summary: {'test_recon_loss': 0.00033641629768751415, 'test_loss': 0.00033641629768751415}
Best loss: 0.00018446354614697823
Epoch 109:
Training summary: {'train_recon_loss': 0.00025719848429362933, 'train_loss': 0.00025719848429362933}
Evaluation summary: {'test_recon_loss': 0.0003390463261307476, 'test_loss': 0.0003390463261307476}
Best loss: 0.00018446354614697823
Epoch 110:
Training summary: {'train_recon_loss': 0.0002565943851605034, 'train_loss': 0.0002565943851605034}
Evaluation summary: {'test_recon_loss': 0.00024014601552238874, 'test_loss': 0.00024014601552238874}
Best loss: 0.00018446354614697823
Epoch 111:
Training summary: {'train_recon_loss': 0.0008734321585661397, 'train_loss': 0.0008734321585661397}
Evaluation summary: {'test_recon_loss': 0.0007581602542825915, 'test_loss': 0.0007581602542825915}
Best loss: 0.00018446354614697823
Epoch 112:
Training summary: {'train_recon_loss': 0.0003922803011412692, 'train_loss': 0.0003922803011412692}
Evaluation summary: {'test_recon_loss': 0.0003520976792159425, 'test_loss': 0.0003520976792159425}
Best loss: 0.00018446354614697823
Epoch 113:
Training summary: {'train_recon_loss': 0.00029022158688660747, 'train_loss': 0.00029022158688660747}
Evaluation summary: {'test_recon_loss': 0.00030675306959659167, 'test_loss': 0.00030675306959659167}
Best loss: 0.00018446354614697823
Epoch 114:
Training summary: {'train_recon_loss': 0.0004437624905900139, 'train_loss': 0.0004437624905900139}
Evaluation summary: {'test_recon_loss': 0.0008716447864951923, 'test_loss': 0.0008716447864951923}
Best loss: 0.00018446354614697823
Epoch 115:
Training summary: {'train_recon_loss': 0.00030410635318399784, 'train_loss': 0.00030410635318399784}
Evaluation summary: {'test_recon_loss': 0.00042796449947749937, 'test_loss': 0.00042796449947749937}
Best loss: 0.00018446354614697823
Epoch 116:
Training summary: {'train_recon_loss': 0.00027080465419968306, 'train_loss': 0.00027080465419968306}
Evaluation summary: {'test_recon_loss': 0.0003200813907517947, 'test_loss': 0.0003200813907517947}
Best loss: 0.00018446354614697823
Epoch 117:
Training summary: {'train_recon_loss': 0.0002765485435512822, 'train_loss': 0.0002765485435512822}
Evaluation summary: {'test_recon_loss': 0.00027522219036601656, 'test_loss': 0.00027522219036601656}
Best loss: 0.00018446354614697823
Epoch 118:
Training summary: {'train_recon_loss': 0.00026129649367097904, 'train_loss': 0.00026129649367097904}
Evaluation summary: {'test_recon_loss': 0.00026214956130402717, 'test_loss': 0.00026214956130402717}
Best loss: 0.00018446354614697823
Epoch 119:
Training summary: {'train_recon_loss': 0.00025193955523127303, 'train_loss': 0.00025193955523127303}
Evaluation summary: {'test_recon_loss': 0.00023175604328697726, 'test_loss': 0.00023175604328697726}
Best loss: 0.00018446354614697823
Epoch 120:
Training summary: {'train_recon_loss': 0.00045596872938281864, 'train_loss': 0.00045596872938281864}
Evaluation summary: {'test_recon_loss': 0.002496523282815147, 'test_loss': 0.002496523282815147}
Best loss: 0.00018446354614697823
Epoch 121:
Training summary: {'train_recon_loss': 0.0007369146729525773, 'train_loss': 0.0007369146729525773}
Evaluation summary: {'test_recon_loss': 0.00029852148072585387, 'test_loss': 0.00029852148072585387}
Best loss: 0.00018446354614697823
Epoch 122:
Training summary: {'train_recon_loss': 0.0002973824723258817, 'train_loss': 0.0002973824723258817}
Evaluation summary: {'test_recon_loss': 0.0002799214181822498, 'test_loss': 0.0002799214181822498}
Best loss: 0.00018446354614697823
Epoch 123:
Training summary: {'train_recon_loss': 0.0002683057448626806, 'train_loss': 0.0002683057448626806}
Evaluation summary: {'test_recon_loss': 0.00028928991006291123, 'test_loss': 0.00028928991006291123}
Best loss: 0.00018446354614697823
Epoch 124:
Training summary: {'train_recon_loss': 0.0002653789266885511, 'train_loss': 0.0002653789266885511}
Evaluation summary: {'test_recon_loss': 0.0003679596233508263, 'test_loss': 0.0003679596233508263}
Best loss: 0.00018446354614697823
Epoch 125:
Training summary: {'train_recon_loss': 0.00027351802845494537, 'train_loss': 0.00027351802845494537}
Evaluation summary: {'test_recon_loss': 0.00031283394218892155, 'test_loss': 0.00031283394218892155}
Best loss: 0.00018446354614697823
Epoch 126:
Training summary: {'train_recon_loss': 0.0002496157817163278, 'train_loss': 0.0002496157817163278}
Evaluation summary: {'test_recon_loss': 0.00020477247543300575, 'test_loss': 0.00020477247543300575}
Best loss: 0.00018446354614697823
Epoch 127:
Training summary: {'train_recon_loss': 0.00025401301189389926, 'train_loss': 0.00025401301189389926}
Evaluation summary: {'test_recon_loss': 0.0009117283839879521, 'test_loss': 0.0009117283839879521}
Best loss: 0.00018446354614697823
Epoch 128:
Training summary: {'train_recon_loss': 0.00025490903453025213, 'train_loss': 0.00025490903453025213}
Evaluation summary: {'test_recon_loss': 0.00037631172502638105, 'test_loss': 0.00037631172502638105}
Best loss: 0.00018446354614697823
Epoch 129:
Training summary: {'train_recon_loss': 0.0006991432894191163, 'train_loss': 0.0006991432894191163}
Evaluation summary: {'test_recon_loss': 0.0006786336815547466, 'test_loss': 0.0006786336815547466}
Best loss: 0.00018446354614697823
Epoch 130:
Training summary: {'train_recon_loss': 0.00040743566272338533, 'train_loss': 0.00040743566272338533}
Evaluation summary: {'test_recon_loss': 0.00028014777699218567, 'test_loss': 0.00028014777699218567}
Best loss: 0.00018446354614697823
Epoch 131:
Training summary: {'train_recon_loss': 0.00028605544526218835, 'train_loss': 0.00028605544526218835}
Evaluation summary: {'test_recon_loss': 0.00023231684565957743, 'test_loss': 0.00023231684565957743}
Best loss: 0.00018446354614697823
Epoch 132:
Training summary: {'train_recon_loss': 0.0002830695814065153, 'train_loss': 0.0002830695814065153}
Evaluation summary: {'test_recon_loss': 0.000304567663781161, 'test_loss': 0.000304567663781161}
Best loss: 0.00018446354614697823
Epoch 133:
Training summary: {'train_recon_loss': 0.00026049824874677823, 'train_loss': 0.00026049824874677823}
Evaluation summary: {'test_recon_loss': 0.00030833298844837727, 'test_loss': 0.00030833298844837727}
Best loss: 0.00018446354614697823
Epoch 134:
Training summary: {'train_recon_loss': 0.0002603409137478507, 'train_loss': 0.0002603409137478507}
Evaluation summary: {'test_recon_loss': 0.0002703607486816635, 'test_loss': 0.0002703607486816635}
Best loss: 0.00018446354614697823
Epoch 135:
Training summary: {'train_recon_loss': 0.0002680115734227827, 'train_loss': 0.0002680115734227827}
Evaluation summary: {'test_recon_loss': 0.0002526640630644734, 'test_loss': 0.0002526640630644734}
Best loss: 0.00018446354614697823
Epoch 136:
Training summary: {'train_recon_loss': 0.00026599334860582526, 'train_loss': 0.00026599334860582526}
Evaluation summary: {'test_recon_loss': 0.00027853339309777934, 'test_loss': 0.00027853339309777934}
Best loss: 0.00018446354614697823
Epoch 137:
Training summary: {'train_recon_loss': 0.0003595795248332352, 'train_loss': 0.0003595795248332352}
Evaluation summary: {'test_recon_loss': 0.003237523487711299, 'test_loss': 0.003237523487711299}
Best loss: 0.00018446354614697823
Epoch 138:
Training summary: {'train_recon_loss': 0.00047933031678263027, 'train_loss': 0.00047933031678263027}
Evaluation summary: {'test_recon_loss': 0.00021539407174582357, 'test_loss': 0.00021539407174582357}
Best loss: 0.00018446354614697823
Epoch 139:
Training summary: {'train_recon_loss': 0.0002560583313228975, 'train_loss': 0.0002560583313228975}
Evaluation summary: {'test_recon_loss': 0.0002207683356895484, 'test_loss': 0.0002207683356895484}
Best loss: 0.00018446354614697823
Epoch 140:
Training summary: {'train_recon_loss': 0.0002634870745342427, 'train_loss': 0.0002634870745342427}
Evaluation summary: {'test_recon_loss': 0.0002856624948053576, 'test_loss': 0.0002856624948053576}
Best loss: 0.00018446354614697823
Epoch 141:
Training summary: {'train_recon_loss': 0.00025665535344314395, 'train_loss': 0.00025665535344314395}
Evaluation summary: {'test_recon_loss': 0.00023550993537923325, 'test_loss': 0.00023550993537923325}
Best loss: 0.00018446354614697823
Epoch 142:
Training summary: {'train_recon_loss': 0.0002624715754547147, 'train_loss': 0.0002624715754547147}
Evaluation summary: {'test_recon_loss': 0.000235555005682282, 'test_loss': 0.000235555005682282}
Best loss: 0.00018446354614697823
Epoch 143:
Training summary: {'train_recon_loss': 0.000588741229811902, 'train_loss': 0.000588741229811902}
Evaluation summary: {'test_recon_loss': 0.0008518341340225201, 'test_loss': 0.0008518341340225201}
Best loss: 0.00018446354614697823
Epoch 144:
Training summary: {'train_recon_loss': 0.00037093425082481346, 'train_loss': 0.00037093425082481346}
Evaluation summary: {'test_recon_loss': 0.00023559714274140825, 'test_loss': 0.00023559714274140825}
Best loss: 0.00018446354614697823
Epoch 145:
Training summary: {'train_recon_loss': 0.000259680164702913, 'train_loss': 0.000259680164702913}
Evaluation summary: {'test_recon_loss': 0.00031507315422640776, 'test_loss': 0.00031507315422640776}
Best loss: 0.00018446354614697823
Epoch 146:
Training summary: {'train_recon_loss': 0.00025955805924800034, 'train_loss': 0.00025955805924800034}
Evaluation summary: {'test_recon_loss': 0.0002592610853664024, 'test_loss': 0.0002592610853664024}
Best loss: 0.00018446354614697823
Epoch 147:
Training summary: {'train_recon_loss': 0.0002626340974144085, 'train_loss': 0.0002626340974144085}
Evaluation summary: {'test_recon_loss': 0.0002471876551286412, 'test_loss': 0.0002471876551286412}
Best loss: 0.00018446354614697823
Epoch 148:
Training summary: {'train_recon_loss': 0.0006541768683097158, 'train_loss': 0.0006541768683097158}
Evaluation summary: {'test_recon_loss': 0.0004481066100707278, 'test_loss': 0.0004481066100707278}
Best loss: 0.00018446354614697823
Epoch 149:
Training summary: {'train_recon_loss': 0.0003030176994412591, 'train_loss': 0.0003030176994412591}
Evaluation summary: {'test_recon_loss': 0.00035843963712834515, 'test_loss': 0.00035843963712834515}
Best loss: 0.00018446354614697823
Epoch 150:
Training summary: {'train_recon_loss': 0.0002560068951874836, 'train_loss': 0.0002560068951874836}
Evaluation summary: {'test_recon_loss': 0.0002778854958212192, 'test_loss': 0.0002778854958212192}
Best loss: 0.00018446354614697823
Epoch 151:
Training summary: {'train_recon_loss': 0.00025744669366353995, 'train_loss': 0.00025744669366353995}
Evaluation summary: {'test_recon_loss': 0.00020298093441247357, 'test_loss': 0.00020298093441247357}
Best loss: 0.00018446354614697823
Epoch 152:
Training summary: {'train_recon_loss': 0.0002562421300852027, 'train_loss': 0.0002562421300852027}
Evaluation summary: {'test_recon_loss': 0.00022825527497559, 'test_loss': 0.00022825527497559}
Best loss: 0.00018446354614697823
Epoch 153:
Training summary: {'train_recon_loss': 0.0005758489389445584, 'train_loss': 0.0005758489389445584}
Evaluation summary: {'test_recon_loss': 0.0015027364494489865, 'test_loss': 0.0015027364494489865}
Best loss: 0.00018446354614697823
Epoch 154:
Training summary: {'train_recon_loss': 0.0004033965790642643, 'train_loss': 0.0004033965790642643}
Evaluation summary: {'test_recon_loss': 0.00020459636920757302, 'test_loss': 0.00020459636920757302}
Best loss: 0.00018446354614697823
Epoch 155:
Training summary: {'train_recon_loss': 0.00025409150770133184, 'train_loss': 0.00025409150770133184}
Evaluation summary: {'test_recon_loss': 0.00026359860059611254, 'test_loss': 0.00026359860059611254}
Best loss: 0.00018446354614697823
Epoch 156:
Training summary: {'train_recon_loss': 0.00025726322370767275, 'train_loss': 0.00025726322370767275}
Evaluation summary: {'test_recon_loss': 0.00033682957941332404, 'test_loss': 0.00033682957941332404}
Best loss: 0.00018446354614697823
Epoch 157:
Training summary: {'train_recon_loss': 0.000253622191646523, 'train_loss': 0.000253622191646523}
Evaluation summary: {'test_recon_loss': 0.00020930180138775437, 'test_loss': 0.00020930180138775437}
Best loss: 0.00018446354614697823
Epoch 158:
Training summary: {'train_recon_loss': 0.0002637775249517186, 'train_loss': 0.0002637775249517186}
Evaluation summary: {'test_recon_loss': 0.00025401855035786004, 'test_loss': 0.00025401855035786004}
Best loss: 0.00018446354614697823
Epoch 159:
Training summary: {'train_recon_loss': 0.00023892593154886929, 'train_loss': 0.00023892593154886929}
Evaluation summary: {'test_recon_loss': 0.0006205523299624726, 'test_loss': 0.0006205523299624726}
Best loss: 0.00018446354614697823
Epoch 160:
Training summary: {'train_recon_loss': 0.0002614554483803438, 'train_loss': 0.0002614554483803438}
Evaluation summary: {'test_recon_loss': 0.00018711095000383562, 'test_loss': 0.00018711095000383562}
Best loss: 0.00018446354614697823
Epoch 161:
Training summary: {'train_recon_loss': 0.0002371911199614506, 'train_loss': 0.0002371911199614506}
Evaluation summary: {'test_recon_loss': 0.00019948794441709852, 'test_loss': 0.00019948794441709852}
Best loss: 0.00018446354614697823
Epoch 162:
Training summary: {'train_recon_loss': 0.00025143811258412506, 'train_loss': 0.00025143811258412506}
Evaluation summary: {'test_recon_loss': 0.00019207706481551905, 'test_loss': 0.00019207706481551905}
Best loss: 0.00018446354614697823
Epoch 163:
Training summary: {'train_recon_loss': 0.0003081685104730287, 'train_loss': 0.0003081685104730287}
Evaluation summary: {'test_recon_loss': 0.008435475539559643, 'test_loss': 0.008435475539559643}
Best loss: 0.00018446354614697823
Epoch 164:
Training summary: {'train_recon_loss': 0.0005359022054153198, 'train_loss': 0.0005359022054153198}
Evaluation summary: {'test_recon_loss': 0.000630796413048797, 'test_loss': 0.000630796413048797}
Best loss: 0.00018446354614697823
Epoch 165:
Training summary: {'train_recon_loss': 0.0002553085424509902, 'train_loss': 0.0002553085424509902}
Evaluation summary: {'test_recon_loss': 0.00023107121443220632, 'test_loss': 0.00023107121443220632}
Best loss: 0.00018446354614697823
Epoch 166:
Training summary: {'train_recon_loss': 0.0002542869879493106, 'train_loss': 0.0002542869879493106}
Evaluation summary: {'test_recon_loss': 0.0002169970847791261, 'test_loss': 0.0002169970847791261}
Best loss: 0.00018446354614697823
Epoch 167:
Training summary: {'train_recon_loss': 0.00024601755681338274, 'train_loss': 0.00024601755681338274}
Evaluation summary: {'test_recon_loss': 0.00019469534000409434, 'test_loss': 0.00019469534000409434}
Best loss: 0.00018446354614697823
Epoch 168:
Training summary: {'train_recon_loss': 0.00024597159443487344, 'train_loss': 0.00024597159443487344}
Evaluation summary: {'test_recon_loss': 0.00020375190691466412, 'test_loss': 0.00020375190691466412}
Best loss: 0.00018446354614697823
Epoch 169:
Training summary: {'train_recon_loss': 0.0002462569598578303, 'train_loss': 0.0002462569598578303}
Evaluation summary: {'test_recon_loss': 0.00020866838840659214, 'test_loss': 0.00020866838840659214}
Best loss: 0.00018446354614697823
Epoch 170:
Training summary: {'train_recon_loss': 0.0008158152149113998, 'train_loss': 0.0008158152149113998}
Evaluation summary: {'test_recon_loss': 0.0005005915350793016, 'test_loss': 0.0005005915350793016}
Best loss: 0.00018446354614697823
Epoch 171:
Training summary: {'train_recon_loss': 0.00030179874196195285, 'train_loss': 0.00030179874196195285}
Evaluation summary: {'test_recon_loss': 0.0006166590566005615, 'test_loss': 0.0006166590566005615}
Best loss: 0.00018446354614697823
Epoch 172:
Training summary: {'train_recon_loss': 0.00025314925296183533, 'train_loss': 0.00025314925296183533}
Evaluation summary: {'test_recon_loss': 0.00022926519693019807, 'test_loss': 0.00022926519693019807}
Best loss: 0.00018446354614697823
Epoch 173:
Training summary: {'train_recon_loss': 0.00023441481939393544, 'train_loss': 0.00023441481939393544}
Evaluation summary: {'test_recon_loss': 0.0003066903437942635, 'test_loss': 0.0003066903437942635}
Best loss: 0.00018446354614697823
Epoch 174:
Training summary: {'train_recon_loss': 0.000596943849222792, 'train_loss': 0.000596943849222792}
Evaluation summary: {'test_recon_loss': 0.00022349637997833344, 'test_loss': 0.00022349637997833344}
Best loss: 0.00018446354614697823
Epoch 175:
Training summary: {'train_recon_loss': 0.0002469313989898153, 'train_loss': 0.0002469313989898153}
Evaluation summary: {'test_recon_loss': 0.00106160548708717, 'test_loss': 0.00106160548708717}
Best loss: 0.00018446354614697823
Epoch 176:
generate_recon.py --datadir . --metafile /mountb/single_cell_flist/ch3_all.csv --save-dir /mountb/autoencoder/ch3 --latent-dims 2048 --ae-features --pretrained-file /mountb/autoencoder/ch3/models/best.pth
Namespace(ae_features=True, batch_size=128, datadir='.', latent_dims=2048, metafile='/mountb/single_cell_flist/ch3_all.csv', pca_features=False, pretrained_file='/mountb/autoencoder/ch3/models/best.pth', save_dir='/mountb/autoencoder/ch3')
Dataset length is 9068498
AE46(
  (encoder): Sequential(
    (0): Conv2d(1, 46, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(46, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(92, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(184, 368, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (12): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (fc1): Linear(in_features=1472, out_features=2048, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): ConvTranspose2d(368, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): ConvTranspose2d(184, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
    (9): ConvTranspose2d(92, 46, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace=True)
    (12): ConvTranspose2d(46, 1, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Sigmoid()
  )
  (d1): Linear(in_features=2048, out_features=1472, bias=True)
  (mseloss): MSELoss()
)
Training summary: {'train_recon_loss': 0.0002474502927256343, 'train_loss': 0.0002474502927256343}
Evaluation summary: {'test_recon_loss': 0.00023268111521746747, 'test_loss': 0.00023268111521746747}
Best loss: 0.00018446354614697823
Epoch 177:
Training summary: {'train_recon_loss': 0.00042018276103381426, 'train_loss': 0.00042018276103381426}
Evaluation summary: {'test_recon_loss': 0.0003226988290596212, 'test_loss': 0.0003226988290596212}
Best loss: 0.00018446354614697823
Epoch 178:
Training summary: {'train_recon_loss': 0.00023496863667218866, 'train_loss': 0.00023496863667218866}
