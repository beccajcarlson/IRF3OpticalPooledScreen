run_train.py --max-value 23873 --datadir . --train-metafile /mountb/single_cell_flist/train_ch2_small.csv --val-metafile /mountb/single_cell_flist/val_ch2_small.csv --save-dir /mountb/autoencoder/ch2 --model-type AE46 --dataset-type 46 --latent-dims 2048
Namespace(batch_size=128, datadir='.', dataset_type='46', debug_mode=False, latent_dims=2048, learning_rate=0.001, max_epochs=2000, max_value=23873, model_type='AE46', num_workers=8, optimizer='adam', save_dir='/mountb/autoencoder/ch2', save_freq=50, seed=42, train_metafile='/mountb/single_cell_flist/train_ch2_small.csv', val_metafile='/mountb/single_cell_flist/val_ch2_small.csv', weight_decay=1e-05)
AE46(
  (encoder): Sequential(
    (0): Conv2d(1, 46, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(46, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(92, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(184, 368, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (12): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (fc1): Linear(in_features=1472, out_features=2048, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): ConvTranspose2d(368, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): ConvTranspose2d(184, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
    (9): ConvTranspose2d(92, 46, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace=True)
    (12): ConvTranspose2d(46, 1, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Sigmoid()
  )
  (d1): Linear(in_features=2048, out_features=1472, bias=True)
  (mseloss): MSELoss()
)
Epoch 0:
Training summary: {'train_recon_loss': 0.008257952979897468, 'train_loss': 0.008257952979897468}
Evaluation summary: {'test_recon_loss': 0.0033218448644611476, 'test_loss': 0.0033218448644611476}
Best loss: 0.0033218448644611476
Epoch 1:
Training summary: {'train_recon_loss': 0.0018427604873164452, 'train_loss': 0.0018427604873164452}
Evaluation summary: {'test_recon_loss': 0.003563639016457606, 'test_loss': 0.003563639016457606}
Best loss: 0.0033218448644611476
Epoch 2:
Training summary: {'train_recon_loss': 0.0012456473159931222, 'train_loss': 0.0012456473159931222}
Evaluation summary: {'test_recon_loss': 0.001224028105414816, 'test_loss': 0.001224028105414816}
Best loss: 0.001224028105414816
Epoch 3:
Training summary: {'train_recon_loss': 0.0009155864422143742, 'train_loss': 0.0009155864422143742}
Evaluation summary: {'test_recon_loss': 0.0009815327845223033, 'test_loss': 0.0009815327845223033}
Best loss: 0.0009815327845223033
Epoch 4:
Training summary: {'train_recon_loss': 0.0007522985929057214, 'train_loss': 0.0007522985929057214}
Evaluation summary: {'test_recon_loss': 0.0007518849086611605, 'test_loss': 0.0007518849086611605}
Best loss: 0.0007518849086611605
Epoch 5:
Training summary: {'train_recon_loss': 0.0006657505408752146, 'train_loss': 0.0006657505408752146}
Evaluation summary: {'test_recon_loss': 0.0005417495824349062, 'test_loss': 0.0005417495824349062}
Best loss: 0.0005417495824349062
Epoch 6:
Training summary: {'train_recon_loss': 0.0006092497451615915, 'train_loss': 0.0006092497451615915}
Evaluation summary: {'test_recon_loss': 0.0006258281743924274, 'test_loss': 0.0006258281743924274}
Best loss: 0.0005417495824349062
Epoch 7:
Training summary: {'train_recon_loss': 0.0005750209244269243, 'train_loss': 0.0005750209244269243}
Evaluation summary: {'test_recon_loss': 0.00046341482356716807, 'test_loss': 0.00046341482356716807}
Best loss: 0.00046341482356716807
Epoch 8:
Training summary: {'train_recon_loss': 0.0005434670193695097, 'train_loss': 0.0005434670193695097}
Evaluation summary: {'test_recon_loss': 0.0004975930109073791, 'test_loss': 0.0004975930109073791}
Best loss: 0.00046341482356716807
Epoch 9:
Training summary: {'train_recon_loss': 0.0005105652318002034, 'train_loss': 0.0005105652318002034}
Evaluation summary: {'test_recon_loss': 0.0004604325836599389, 'test_loss': 0.0004604325836599389}
Best loss: 0.0004604325836599389
Epoch 10:
Training summary: {'train_recon_loss': 0.0014323271684926146, 'train_loss': 0.0014323271684926146}
Evaluation summary: {'test_recon_loss': 0.001380448580358852, 'test_loss': 0.001380448580358852}
Best loss: 0.0004604325836599389
Epoch 11:
Training summary: {'train_recon_loss': 0.0007908684500804099, 'train_loss': 0.0007908684500804099}
Evaluation summary: {'test_recon_loss': 0.0005065279176591635, 'test_loss': 0.0005065279176591635}
Best loss: 0.0004604325836599389
Epoch 12:
Training summary: {'train_recon_loss': 0.0005632958869271265, 'train_loss': 0.0005632958869271265}
Evaluation summary: {'test_recon_loss': 0.00045310345297362394, 'test_loss': 0.00045310345297362394}
Best loss: 0.00045310345297362394
Epoch 13:
Training summary: {'train_recon_loss': 0.000507823475319794, 'train_loss': 0.000507823475319794}
Evaluation summary: {'test_recon_loss': 0.0004633438506648599, 'test_loss': 0.0004633438506648599}
Best loss: 0.00045310345297362394
Epoch 14:
Training summary: {'train_recon_loss': 0.0004908515487706238, 'train_loss': 0.0004908515487706238}
Evaluation summary: {'test_recon_loss': 0.0004498194957324878, 'test_loss': 0.0004498194957324878}
Best loss: 0.0004498194957324878
Epoch 15:
Training summary: {'train_recon_loss': 0.0004647370706955729, 'train_loss': 0.0004647370706955729}
Evaluation summary: {'test_recon_loss': 0.00044797978223696177, 'test_loss': 0.00044797978223696177}
Best loss: 0.00044797978223696177
Epoch 16:
Training summary: {'train_recon_loss': 0.001673098758143592, 'train_loss': 0.001673098758143592}
Evaluation summary: {'test_recon_loss': 0.0008343675431541295, 'test_loss': 0.0008343675431541295}
Best loss: 0.00044797978223696177
Epoch 17:
Training summary: {'train_recon_loss': 0.0006469030305702085, 'train_loss': 0.0006469030305702085}
Evaluation summary: {'test_recon_loss': 0.0005050489269551554, 'test_loss': 0.0005050489269551554}
Best loss: 0.00044797978223696177
Epoch 18:
Training summary: {'train_recon_loss': 0.0005354644718243453, 'train_loss': 0.0005354644718243453}
Evaluation summary: {'test_recon_loss': 0.0004630816733165001, 'test_loss': 0.0004630816733165001}
Best loss: 0.00044797978223696177
Epoch 19:
Training summary: {'train_recon_loss': 0.00048350489810652084, 'train_loss': 0.00048350489810652084}
Evaluation summary: {'test_recon_loss': 0.00042158256484718426, 'test_loss': 0.00042158256484718426}
Best loss: 0.00042158256484718426
Epoch 20:
Training summary: {'train_recon_loss': 0.00046517358274839147, 'train_loss': 0.00046517358274839147}
Evaluation summary: {'test_recon_loss': 0.00040419339914591555, 'test_loss': 0.00040419339914591555}
Best loss: 0.00040419339914591555
Epoch 21:
Training summary: {'train_recon_loss': 0.0023070334882825927, 'train_loss': 0.0023070334882825927}
Evaluation summary: {'test_recon_loss': 0.0013102948435291533, 'test_loss': 0.0013102948435291533}
Best loss: 0.00040419339914591555
Epoch 22:
Training summary: {'train_recon_loss': 0.000891933322439049, 'train_loss': 0.000891933322439049}
Evaluation summary: {'test_recon_loss': 0.0006126768738880963, 'test_loss': 0.0006126768738880963}
Best loss: 0.00040419339914591555
Epoch 23:
Training summary: {'train_recon_loss': 0.0005964830894884574, 'train_loss': 0.0005964830894884574}
Evaluation summary: {'test_recon_loss': 0.0005697290776962163, 'test_loss': 0.0005697290776962163}
Best loss: 0.00040419339914591555
Epoch 24:
Training summary: {'train_recon_loss': 0.0005266282033539695, 'train_loss': 0.0005266282033539695}
Evaluation summary: {'test_recon_loss': 0.0004393092605974506, 'test_loss': 0.0004393092605974506}
Best loss: 0.00040419339914591555
Epoch 25:
Training summary: {'train_recon_loss': 0.00048584230272954955, 'train_loss': 0.00048584230272954955}
Evaluation summary: {'test_recon_loss': 0.00041488479178850934, 'test_loss': 0.00041488479178850934}
Best loss: 0.00040419339914591555
Epoch 26:
Training summary: {'train_recon_loss': 0.0004711248497984638, 'train_loss': 0.0004711248497984638}
Evaluation summary: {'test_recon_loss': 0.00040210960303454715, 'test_loss': 0.00040210960303454715}
Best loss: 0.00040210960303454715
Epoch 27:
Training summary: {'train_recon_loss': 0.0016297586628852086, 'train_loss': 0.0016297586628852086}
Evaluation summary: {'test_recon_loss': 0.0017441849244372648, 'test_loss': 0.0017441849244372648}
Best loss: 0.00040210960303454715
Epoch 28:
Training summary: {'train_recon_loss': 0.0009480251246971133, 'train_loss': 0.0009480251246971133}
Evaluation summary: {'test_recon_loss': 0.0006446410687262123, 'test_loss': 0.0006446410687262123}
Best loss: 0.00040210960303454715
Epoch 29:
Training summary: {'train_recon_loss': 0.0006096787670402631, 'train_loss': 0.0006096787670402631}
Evaluation summary: {'test_recon_loss': 0.0005245705465516061, 'test_loss': 0.0005245705465516061}
Best loss: 0.00040210960303454715
Epoch 30:
Training summary: {'train_recon_loss': 0.0005239467626082131, 'train_loss': 0.0005239467626082131}
Evaluation summary: {'test_recon_loss': 0.00046049887385108323, 'test_loss': 0.00046049887385108323}
Best loss: 0.00040210960303454715
Epoch 31:
Training summary: {'train_recon_loss': 0.0004892023728647048, 'train_loss': 0.0004892023728647048}
Evaluation summary: {'test_recon_loss': 0.000427376742436749, 'test_loss': 0.000427376742436749}
Best loss: 0.00040210960303454715
Epoch 32:
Training summary: {'train_recon_loss': 0.0004578932592511185, 'train_loss': 0.0004578932592511185}
Evaluation summary: {'test_recon_loss': 0.00040208445515712833, 'test_loss': 0.00040208445515712833}
Best loss: 0.00040208445515712833
Epoch 33:
Training summary: {'train_recon_loss': 0.00045021938368005113, 'train_loss': 0.00045021938368005113}
Evaluation summary: {'test_recon_loss': 0.0003644253337683936, 'test_loss': 0.0003644253337683936}
Best loss: 0.0003644253337683936
Epoch 34:
Training summary: {'train_recon_loss': 0.002172419790761848, 'train_loss': 0.002172419790761848}
Evaluation summary: {'test_recon_loss': 0.0009288042762716051, 'test_loss': 0.0009288042762716051}
Best loss: 0.0003644253337683936
Epoch 35:
Training summary: {'train_recon_loss': 0.0007092198078802796, 'train_loss': 0.0007092198078802796}
Evaluation summary: {'test_recon_loss': 0.0005628914854328233, 'test_loss': 0.0005628914854328233}
Best loss: 0.0003644253337683936
Epoch 36:
Training summary: {'train_recon_loss': 0.0005557153029132856, 'train_loss': 0.0005557153029132856}
Evaluation summary: {'test_recon_loss': 0.0005180465514552531, 'test_loss': 0.0005180465514552531}
Best loss: 0.0003644253337683936
Epoch 37:
Training summary: {'train_recon_loss': 0.0004884385366639436, 'train_loss': 0.0004884385366639436}
Evaluation summary: {'test_recon_loss': 0.00042209138182607974, 'test_loss': 0.00042209138182607974}
Best loss: 0.0003644253337683936
Epoch 38:
Training summary: {'train_recon_loss': 0.0004683052297219201, 'train_loss': 0.0004683052297219201}
Evaluation summary: {'test_recon_loss': 0.0004289495988076857, 'test_loss': 0.0004289495988076857}
Best loss: 0.0003644253337683936
Epoch 39:
Training summary: {'train_recon_loss': 0.000452850980619577, 'train_loss': 0.000452850980619577}
Evaluation summary: {'test_recon_loss': 0.00040083278683460707, 'test_loss': 0.00040083278683460707}
Best loss: 0.0003644253337683936
Epoch 40:
Training summary: {'train_recon_loss': 0.0017846845289488243, 'train_loss': 0.0017846845289488243}
Evaluation summary: {'test_recon_loss': 0.0014457636397382685, 'test_loss': 0.0014457636397382685}
Best loss: 0.0003644253337683936
Epoch 41:
Training summary: {'train_recon_loss': 0.0011192852539271968, 'train_loss': 0.0011192852539271968}
Evaluation summary: {'test_recon_loss': 0.0008617601357824051, 'test_loss': 0.0008617601357824051}
Best loss: 0.0003644253337683936
Epoch 42:
Training summary: {'train_recon_loss': 0.0006865427617268322, 'train_loss': 0.0006865427617268322}
Evaluation summary: {'test_recon_loss': 0.0007291552254908777, 'test_loss': 0.0007291552254908777}
Best loss: 0.0003644253337683936
Epoch 43:
Training summary: {'train_recon_loss': 0.0005690841222891102, 'train_loss': 0.0005690841222891102}
Evaluation summary: {'test_recon_loss': 0.0004984757920348744, 'test_loss': 0.0004984757920348744}
Best loss: 0.0003644253337683936
Epoch 44:
Training summary: {'train_recon_loss': 0.0005085421543051705, 'train_loss': 0.0005085421543051705}
Evaluation summary: {'test_recon_loss': 0.0004477908281394544, 'test_loss': 0.0004477908281394544}
Best loss: 0.0003644253337683936
Epoch 45:
Training summary: {'train_recon_loss': 0.0004818605116318396, 'train_loss': 0.0004818605116318396}
Evaluation summary: {'test_recon_loss': 0.0005159210416037194, 'test_loss': 0.0005159210416037194}
Best loss: 0.0003644253337683936
Epoch 46:
Training summary: {'train_recon_loss': 0.0004580544404292235, 'train_loss': 0.0004580544404292235}
Evaluation summary: {'test_recon_loss': 0.0003989356204585789, 'test_loss': 0.0003989356204585789}
Best loss: 0.0003644253337683936
Epoch 47:
Training summary: {'train_recon_loss': 0.0016421729275794673, 'train_loss': 0.0016421729275794673}
Evaluation summary: {'test_recon_loss': 0.0015087604849017154, 'test_loss': 0.0015087604849017154}
Best loss: 0.0003644253337683936
Epoch 48:
Training summary: {'train_recon_loss': 0.000937457792374532, 'train_loss': 0.000937457792374532}
Evaluation summary: {'test_recon_loss': 0.0008092652520679062, 'test_loss': 0.0008092652520679062}
Best loss: 0.0003644253337683936
Epoch 49:
Training summary: {'train_recon_loss': 0.0006152986603963445, 'train_loss': 0.0006152986603963445}
Evaluation summary: {'test_recon_loss': 0.0004994518974229524, 'test_loss': 0.0004994518974229524}
Best loss: 0.0003644253337683936
Epoch 50:
Training summary: {'train_recon_loss': 0.0005139079013927396, 'train_loss': 0.0005139079013927396}
Evaluation summary: {'test_recon_loss': 0.000429527374057783, 'test_loss': 0.000429527374057783}
Best loss: 0.0003644253337683936
Epoch 51:
Training summary: {'train_recon_loss': 0.0004794773166051446, 'train_loss': 0.0004794773166051446}
Evaluation summary: {'test_recon_loss': 0.00042134022438210743, 'test_loss': 0.00042134022438210743}
Best loss: 0.0003644253337683936
Epoch 52:
Training summary: {'train_recon_loss': 0.0016048828268657312, 'train_loss': 0.0016048828268657312}
Evaluation summary: {'test_recon_loss': 0.002071515129444804, 'test_loss': 0.002071515129444804}
Best loss: 0.0003644253337683936
Epoch 53:
Training summary: {'train_recon_loss': 0.0010479430084128275, 'train_loss': 0.0010479430084128275}
Evaluation summary: {'test_recon_loss': 0.0007412064003759365, 'test_loss': 0.0007412064003759365}
Best loss: 0.0003644253337683936
Epoch 54:
Training summary: {'train_recon_loss': 0.0005867867711018245, 'train_loss': 0.0005867867711018245}
Evaluation summary: {'test_recon_loss': 0.0004905394092617474, 'test_loss': 0.0004905394092617474}
Best loss: 0.0003644253337683936
Epoch 55:
Training summary: {'train_recon_loss': 0.000512929448969793, 'train_loss': 0.000512929448969793}
Evaluation summary: {'test_recon_loss': 0.0004392891739029464, 'test_loss': 0.0004392891739029464}
Best loss: 0.0003644253337683936
Epoch 56:
Training summary: {'train_recon_loss': 0.00046988131182042854, 'train_loss': 0.00046988131182042854}
Evaluation summary: {'test_recon_loss': 0.00039848373863871387, 'test_loss': 0.00039848373863871387}
Best loss: 0.0003644253337683936
Epoch 57:
Training summary: {'train_recon_loss': 0.0007063647187701608, 'train_loss': 0.0007063647187701608}
Evaluation summary: {'test_recon_loss': 0.2348398577937246, 'test_loss': 0.2348398577937246}
Best loss: 0.0003644253337683936
Epoch 58:
Training summary: {'train_recon_loss': 0.0019425432141804409, 'train_loss': 0.0019425432141804409}
Evaluation summary: {'test_recon_loss': 0.0008100030323085714, 'test_loss': 0.0008100030323085714}
Best loss: 0.0003644253337683936
Epoch 59:
Training summary: {'train_recon_loss': 0.0006342453033356457, 'train_loss': 0.0006342453033356457}
Evaluation summary: {'test_recon_loss': 0.0005076922704272996, 'test_loss': 0.0005076922704272996}
Best loss: 0.0003644253337683936
Epoch 60:
Training summary: {'train_recon_loss': 0.0005125274872259232, 'train_loss': 0.0005125274872259232}
Evaluation summary: {'test_recon_loss': 0.0004622172638949276, 'test_loss': 0.0004622172638949276}
Best loss: 0.0003644253337683936
Epoch 61:
Training summary: {'train_recon_loss': 0.00046717611283628245, 'train_loss': 0.00046717611283628245}
Evaluation summary: {'test_recon_loss': 0.0004710390645172204, 'test_loss': 0.0004710390645172204}
Best loss: 0.0003644253337683936
Epoch 62:
Training summary: {'train_recon_loss': 0.00044376308094527464, 'train_loss': 0.00044376308094527464}
Evaluation summary: {'test_recon_loss': 0.00044113205382365767, 'test_loss': 0.00044113205382365767}
Best loss: 0.0003644253337683936
Epoch 63:
Training summary: {'train_recon_loss': 0.0019805507299197373, 'train_loss': 0.0019805507299197373}
Evaluation summary: {'test_recon_loss': 0.0010355159805220523, 'test_loss': 0.0010355159805220523}
Best loss: 0.0003644253337683936
Epoch 64:
Training summary: {'train_recon_loss': 0.0006890157059735088, 'train_loss': 0.0006890157059735088}
Evaluation summary: {'test_recon_loss': 0.0005190983355800437, 'test_loss': 0.0005190983355800437}
Best loss: 0.0003644253337683936
Epoch 65:
Training summary: {'train_recon_loss': 0.0005313776476763672, 'train_loss': 0.0005313776476763672}
Evaluation summary: {'test_recon_loss': 0.0004556899832092743, 'test_loss': 0.0004556899832092743}
Best loss: 0.0003644253337683936
Epoch 66:
Training summary: {'train_recon_loss': 0.0004739107402837951, 'train_loss': 0.0004739107402837951}
Evaluation summary: {'test_recon_loss': 0.00039012509053653374, 'test_loss': 0.00039012509053653374}
Best loss: 0.0003644253337683936
Epoch 67:
Training summary: {'train_recon_loss': 0.0004591210791553198, 'train_loss': 0.0004591210791553198}
Evaluation summary: {'test_recon_loss': 0.00042137905984217873, 'test_loss': 0.00042137905984217873}
Best loss: 0.0003644253337683936
Epoch 68:
Training summary: {'train_recon_loss': 0.001636007272715717, 'train_loss': 0.001636007272715717}
Evaluation summary: {'test_recon_loss': 0.0030380773270932892, 'test_loss': 0.0030380773270932892}
Best loss: 0.0003644253337683936
Epoch 69:
Training summary: {'train_recon_loss': 0.0012506353552658904, 'train_loss': 0.0012506353552658904}
Evaluation summary: {'test_recon_loss': 0.0010262195408325427, 'test_loss': 0.0010262195408325427}
Best loss: 0.0003644253337683936
Epoch 70:
Training summary: {'train_recon_loss': 0.0007317693236196753, 'train_loss': 0.0007317693236196753}
Evaluation summary: {'test_recon_loss': 0.0005796390896380236, 'test_loss': 0.0005796390896380236}
Best loss: 0.0003644253337683936
Epoch 71:
Training summary: {'train_recon_loss': 0.0005686325422679838, 'train_loss': 0.0005686325422679838}
Evaluation summary: {'test_recon_loss': 0.0005166153794904173, 'test_loss': 0.0005166153794904173}
Best loss: 0.0003644253337683936
Epoch 72:
Training summary: {'train_recon_loss': 0.0005100692479209739, 'train_loss': 0.0005100692479209739}
Evaluation summary: {'test_recon_loss': 0.00048318178264708235, 'test_loss': 0.00048318178264708235}
Best loss: 0.0003644253337683936
Epoch 73:
Training summary: {'train_recon_loss': 0.0004702544550130854, 'train_loss': 0.0004702544550130854}
Evaluation summary: {'test_recon_loss': 0.000436583106987333, 'test_loss': 0.000436583106987333}
Best loss: 0.0003644253337683936
Epoch 74:
Training summary: {'train_recon_loss': 0.0004592976913283093, 'train_loss': 0.0004592976913283093}
Evaluation summary: {'test_recon_loss': 0.00042487701121985983, 'test_loss': 0.00042487701121985983}
Best loss: 0.0003644253337683936
Epoch 75:
Training summary: {'train_recon_loss': 0.0005653755671045224, 'train_loss': 0.0005653755671045224}
Evaluation summary: {'test_recon_loss': 0.35025798236941863, 'test_loss': 0.35025798236941863}
Best loss: 0.0003644253337683936
Epoch 76:
Training summary: {'train_recon_loss': 0.0018518880460503431, 'train_loss': 0.0018518880460503431}
Evaluation summary: {'test_recon_loss': 0.0009262064891454645, 'test_loss': 0.0009262064891454645}
Best loss: 0.0003644253337683936
Epoch 77:
Training summary: {'train_recon_loss': 0.0006790787791245029, 'train_loss': 0.0006790787791245029}
Evaluation summary: {'test_recon_loss': 0.0005393353201081231, 'test_loss': 0.0005393353201081231}
Best loss: 0.0003644253337683936
Epoch 78:
Training summary: {'train_recon_loss': 0.0005385289280288673, 'train_loss': 0.0005385289280288673}
Evaluation summary: {'test_recon_loss': 0.00047582402680223097, 'test_loss': 0.00047582402680223097}
Best loss: 0.0003644253337683936
Epoch 79:
Training summary: {'train_recon_loss': 0.00048173228740509475, 'train_loss': 0.00048173228740509475}
Evaluation summary: {'test_recon_loss': 0.00043709234900699614, 'test_loss': 0.00043709234900699614}
Best loss: 0.0003644253337683936
Epoch 80:
Training summary: {'train_recon_loss': 0.0004568621747104401, 'train_loss': 0.0004568621747104401}
Evaluation summary: {'test_recon_loss': 0.00047005524165725696, 'test_loss': 0.00047005524165725696}
Best loss: 0.0003644253337683936
Epoch 81:
Training summary: {'train_recon_loss': 0.0004399124203437392, 'train_loss': 0.0004399124203437392}
Evaluation summary: {'test_recon_loss': 0.0004031907117758133, 'test_loss': 0.0004031907117758133}
Best loss: 0.0003644253337683936
Epoch 82:
Training summary: {'train_recon_loss': 0.0018170343971849886, 'train_loss': 0.0018170343971849886}
Evaluation summary: {'test_recon_loss': 0.0012115315669248819, 'test_loss': 0.0012115315669248819}
Best loss: 0.0003644253337683936
Epoch 83:
Training summary: {'train_recon_loss': 0.0007653155626544842, 'train_loss': 0.0007653155626544842}
Evaluation summary: {'test_recon_loss': 0.0005757496197938866, 'test_loss': 0.0005757496197938866}
Best loss: 0.0003644253337683936
Epoch 84:
Training summary: {'train_recon_loss': 0.0005545282409696713, 'train_loss': 0.0005545282409696713}
Evaluation summary: {'test_recon_loss': 0.00048820831084245666, 'test_loss': 0.00048820831084245666}
Best loss: 0.0003644253337683936
Epoch 85:
Training summary: {'train_recon_loss': 0.0005005440369697605, 'train_loss': 0.0005005440369697605}
Evaluation summary: {'test_recon_loss': 0.00046358238032055904, 'test_loss': 0.00046358238032055904}
Best loss: 0.0003644253337683936
Epoch 86:
Training summary: {'train_recon_loss': 0.00047650498816457164, 'train_loss': 0.00047650498816457164}
Evaluation summary: {'test_recon_loss': 0.0003852907198064767, 'test_loss': 0.0003852907198064767}
Best loss: 0.0003644253337683936
Epoch 87:
Training summary: {'train_recon_loss': 0.0004598764251619775, 'train_loss': 0.0004598764251619775}
Evaluation summary: {'test_recon_loss': 0.00041513233476105527, 'test_loss': 0.00041513233476105527}
Best loss: 0.0003644253337683936
Epoch 88:
Training summary: {'train_recon_loss': 0.002159144415918332, 'train_loss': 0.002159144415918332}
Evaluation summary: {'test_recon_loss': 0.0010554822696378617, 'test_loss': 0.0010554822696378617}
Best loss: 0.0003644253337683936
Epoch 89:
Training summary: {'train_recon_loss': 0.0008191626792314522, 'train_loss': 0.0008191626792314522}
Evaluation summary: {'test_recon_loss': 0.000624394142395761, 'test_loss': 0.000624394142395761}
Best loss: 0.0003644253337683936
Epoch 90:
Training summary: {'train_recon_loss': 0.0005936163892869116, 'train_loss': 0.0005936163892869116}
Evaluation summary: {'test_recon_loss': 0.0004941448794801527, 'test_loss': 0.0004941448794801527}
Best loss: 0.0003644253337683936
Epoch 91:
Training summary: {'train_recon_loss': 0.0005186434346498007, 'train_loss': 0.0005186434346498007}
Evaluation summary: {'test_recon_loss': 0.000436342308417102, 'test_loss': 0.000436342308417102}
Best loss: 0.0003644253337683936
Epoch 92:
Training summary: {'train_recon_loss': 0.00047018293224689717, 'train_loss': 0.00047018293224689717}
Evaluation summary: {'test_recon_loss': 0.0004276615631059767, 'test_loss': 0.0004276615631059767}
Best loss: 0.0003644253337683936
Epoch 93:
Training summary: {'train_recon_loss': 0.001900386469767347, 'train_loss': 0.001900386469767347}
Evaluation summary: {'test_recon_loss': 0.000997805623966784, 'test_loss': 0.000997805623966784}
Best loss: 0.0003644253337683936
Epoch 94:
Training summary: {'train_recon_loss': 0.0006774685108748691, 'train_loss': 0.0006774685108748691}
Evaluation summary: {'test_recon_loss': 0.0005849464386009907, 'test_loss': 0.0005849464386009907}
Best loss: 0.0003644253337683936
Epoch 95:
Training summary: {'train_recon_loss': 0.0005255866467306069, 'train_loss': 0.0005255866467306069}
Evaluation summary: {'test_recon_loss': 0.00046323086936555965, 'test_loss': 0.00046323086936555965}
Best loss: 0.0003644253337683936
Epoch 96:
Training summary: {'train_recon_loss': 0.0004910841833490732, 'train_loss': 0.0004910841833490732}
Evaluation summary: {'test_recon_loss': 0.00043914733820570913, 'test_loss': 0.00043914733820570913}
Best loss: 0.0003644253337683936
Epoch 97:
Training summary: {'train_recon_loss': 0.0021929423471928377, 'train_loss': 0.0021929423471928377}
Evaluation summary: {'test_recon_loss': 0.0025838113170082843, 'test_loss': 0.0025838113170082843}
Best loss: 0.0003644253337683936
Epoch 98:
Training summary: {'train_recon_loss': 0.001320590903734057, 'train_loss': 0.001320590903734057}
Evaluation summary: {'test_recon_loss': 0.0008819715234362369, 'test_loss': 0.0008819715234362369}
Best loss: 0.0003644253337683936
Epoch 99:
Training summary: {'train_recon_loss': 0.0006933408151109221, 'train_loss': 0.0006933408151109221}
Evaluation summary: {'test_recon_loss': 0.0005927739495542917, 'test_loss': 0.0005927739495542917}
Best loss: 0.0003644253337683936
Epoch 100:
Training summary: {'train_recon_loss': 0.0005484091596905794, 'train_loss': 0.0005484091596905794}
Evaluation summary: {'test_recon_loss': 0.0004926208473193778, 'test_loss': 0.0004926208473193778}
Best loss: 0.0003644253337683936
Epoch 101:
Training summary: {'train_recon_loss': 0.0005051676379232889, 'train_loss': 0.0005051676379232889}
Evaluation summary: {'test_recon_loss': 0.0005127650130486961, 'test_loss': 0.0005127650130486961}
Best loss: 0.0003644253337683936
Epoch 102:
Training summary: {'train_recon_loss': 0.0004736022318136635, 'train_loss': 0.0004736022318136635}
Evaluation summary: {'test_recon_loss': 0.0004199897577210387, 'test_loss': 0.0004199897577210387}
Best loss: 0.0003644253337683936
Epoch 103:
Training summary: {'train_recon_loss': 0.0020023148430572254, 'train_loss': 0.0020023148430572254}
Evaluation summary: {'test_recon_loss': 0.0012875052061118942, 'test_loss': 0.0012875052061118942}
Best loss: 0.0003644253337683936
Epoch 104:
Training summary: {'train_recon_loss': 0.0008687560449439919, 'train_loss': 0.0008687560449439919}
Evaluation summary: {'test_recon_loss': 0.0006803801905523445, 'test_loss': 0.0006803801905523445}
Best loss: 0.0003644253337683936
Epoch 105:
Training summary: {'train_recon_loss': 0.0005774527929362091, 'train_loss': 0.0005774527929362091}
Evaluation summary: {'test_recon_loss': 0.0004823193367784867, 'test_loss': 0.0004823193367784867}
Best loss: 0.0003644253337683936
Epoch 106:
Training summary: {'train_recon_loss': 0.0005014983605689699, 'train_loss': 0.0005014983605689699}
Evaluation summary: {'test_recon_loss': 0.0004665436690402417, 'test_loss': 0.0004665436690402417}
Best loss: 0.0003644253337683936
Epoch 107:
Training summary: {'train_recon_loss': 0.00047134849484129605, 'train_loss': 0.00047134849484129605}
Evaluation summary: {'test_recon_loss': 0.00039368117858469673, 'test_loss': 0.00039368117858469673}
Best loss: 0.0003644253337683936
Epoch 108:
Training summary: {'train_recon_loss': 0.00044619585959201295, 'train_loss': 0.00044619585959201295}
Evaluation summary: {'test_recon_loss': 0.0004572609067309161, 'test_loss': 0.0004572609067309161}
Best loss: 0.0003644253337683936
Epoch 109:
Training summary: {'train_recon_loss': 0.001848102916631018, 'train_loss': 0.001848102916631018}
Evaluation summary: {'test_recon_loss': 0.0014186516885384879, 'test_loss': 0.0014186516885384879}
Best loss: 0.0003644253337683936
Epoch 110:
Training summary: {'train_recon_loss': 0.0009302719913311181, 'train_loss': 0.0009302719913311181}
Evaluation summary: {'test_recon_loss': 0.0007064777330706512, 'test_loss': 0.0007064777330706512}
Best loss: 0.0003644253337683936
Epoch 111:
Training summary: {'train_recon_loss': 0.0006332014708030254, 'train_loss': 0.0006332014708030254}
Evaluation summary: {'test_recon_loss': 0.0005316975161263972, 'test_loss': 0.0005316975161263972}
Best loss: 0.0003644253337683936
Epoch 112:
Training summary: {'train_recon_loss': 0.0005454988523354336, 'train_loss': 0.0005454988523354336}
Evaluation summary: {'test_recon_loss': 0.00047834024604753413, 'test_loss': 0.00047834024604753413}
Best loss: 0.0003644253337683936
Epoch 113:
Training summary: {'train_recon_loss': 0.0016158150771037132, 'train_loss': 0.0016158150771037132}
Evaluation summary: {'test_recon_loss': 0.00066152987946953, 'test_loss': 0.00066152987946953}
Best loss: 0.0003644253337683936
Epoch 114:
Training summary: {'train_recon_loss': 0.0005894031254500611, 'train_loss': 0.0005894031254500611}
Evaluation summary: {'test_recon_loss': 0.0004932483907100733, 'test_loss': 0.0004932483907100733}
Best loss: 0.0003644253337683936
Epoch 115:
Training summary: {'train_recon_loss': 0.0005033973550140969, 'train_loss': 0.0005033973550140969}
Evaluation summary: {'test_recon_loss': 0.0004221833880010279, 'test_loss': 0.0004221833880010279}
Best loss: 0.0003644253337683936
Epoch 116:
Training summary: {'train_recon_loss': 0.00046643135291088184, 'train_loss': 0.00046643135291088184}
Evaluation summary: {'test_recon_loss': 0.0003941146033287938, 'test_loss': 0.0003941146033287938}
Best loss: 0.0003644253337683936
Epoch 117:
Training summary: {'train_recon_loss': 0.0004480273671392285, 'train_loss': 0.0004480273671392285}
Evaluation summary: {'test_recon_loss': 0.0005692999184885894, 'test_loss': 0.0005692999184885894}
Best loss: 0.0003644253337683936
Epoch 118:
Training summary: {'train_recon_loss': 0.0004380485438865149, 'train_loss': 0.0004380485438865149}
Evaluation summary: {'test_recon_loss': 0.0004141694165789939, 'test_loss': 0.0004141694165789939}
Best loss: 0.0003644253337683936
Epoch 119:
Training summary: {'train_recon_loss': 0.0008266403506096124, 'train_loss': 0.0008266403506096124}
Evaluation summary: {'test_recon_loss': 0.005579079020701241, 'test_loss': 0.005579079020701241}
Best loss: 0.0003644253337683936
Epoch 120:
Training summary: {'train_recon_loss': 0.0020145879441982512, 'train_loss': 0.0020145879441982512}
Evaluation summary: {'test_recon_loss': 0.0010323731270867008, 'test_loss': 0.0010323731270867008}
Best loss: 0.0003644253337683936
Epoch 121:
Training summary: {'train_recon_loss': 0.0007252661084925738, 'train_loss': 0.0007252661084925738}
Evaluation summary: {'test_recon_loss': 0.0006152096078730864, 'test_loss': 0.0006152096078730864}
Best loss: 0.0003644253337683936
Epoch 122:
Training summary: {'train_recon_loss': 0.0005591236544520405, 'train_loss': 0.0005591236544520405}
Evaluation summary: {'test_recon_loss': 0.0005174929608688645, 'test_loss': 0.0005174929608688645}
Best loss: 0.0003644253337683936
Epoch 123:
Training summary: {'train_recon_loss': 0.0005012193429176841, 'train_loss': 0.0005012193429176841}
Evaluation summary: {'test_recon_loss': 0.0004198053261360565, 'test_loss': 0.0004198053261360565}
Best loss: 0.0003644253337683936
Epoch 124:
Training summary: {'train_recon_loss': 0.0004722053533631408, 'train_loss': 0.0004722053533631408}
Evaluation summary: {'test_recon_loss': 0.00043244066147863166, 'test_loss': 0.00043244066147863166}
Best loss: 0.0003644253337683936
Epoch 125:
Training summary: {'train_recon_loss': 0.0004383990945366076, 'train_loss': 0.0004383990945366076}
Evaluation summary: {'test_recon_loss': 0.00038324687158037895, 'test_loss': 0.00038324687158037895}
Best loss: 0.0003644253337683936
Epoch 126:
Training summary: {'train_recon_loss': 0.00043092517343896054, 'train_loss': 0.00043092517343896054}
Evaluation summary: {'test_recon_loss': 0.00038773675471291967, 'test_loss': 0.00038773675471291967}
Best loss: 0.0003644253337683936
Epoch 127:
Training summary: {'train_recon_loss': 0.0018144671140545505, 'train_loss': 0.0018144671140545505}
Evaluation summary: {'test_recon_loss': 0.003727600272421805, 'test_loss': 0.003727600272421805}
Best loss: 0.0003644253337683936
Epoch 128:
Training summary: {'train_recon_loss': 0.001972835011164866, 'train_loss': 0.001972835011164866}
Evaluation summary: {'test_recon_loss': 0.0012907636882809684, 'test_loss': 0.0012907636882809684}
Best loss: 0.0003644253337683936
Epoch 129:
Training summary: {'train_recon_loss': 0.001001453929964959, 'train_loss': 0.001001453929964959}
Evaluation summary: {'test_recon_loss': 0.0008299220448457463, 'test_loss': 0.0008299220448457463}
Best loss: 0.0003644253337683936
Epoch 130:
Training summary: {'train_recon_loss': 0.0007053042993166684, 'train_loss': 0.0007053042993166684}
Evaluation summary: {'test_recon_loss': 0.0005803266233100794, 'test_loss': 0.0005803266233100794}
Best loss: 0.0003644253337683936
Epoch 131:
Training summary: {'train_recon_loss': 0.0005869513509491482, 'train_loss': 0.0005869513509491482}
Evaluation summary: {'test_recon_loss': 0.0005037171302849866, 'test_loss': 0.0005037171302849866}
Best loss: 0.0003644253337683936
Epoch 132:
Training summary: {'train_recon_loss': 0.0005360457002059402, 'train_loss': 0.0005360457002059402}
Evaluation summary: {'test_recon_loss': 0.0005133559773004322, 'test_loss': 0.0005133559773004322}
Best loss: 0.0003644253337683936
Epoch 133:
Training summary: {'train_recon_loss': 0.0004918460002273498, 'train_loss': 0.0004918460002273498}
Evaluation summary: {'test_recon_loss': 0.00045215233805483954, 'test_loss': 0.00045215233805483954}
Best loss: 0.0003644253337683936
Epoch 134:
Training summary: {'train_recon_loss': 0.00047400516329099547, 'train_loss': 0.00047400516329099547}
Evaluation summary: {'test_recon_loss': 0.00040643175618356445, 'test_loss': 0.00040643175618356445}
Best loss: 0.0003644253337683936
Epoch 135:
Training summary: {'train_recon_loss': 0.0010137232192240777, 'train_loss': 0.0010137232192240777}
Evaluation summary: {'test_recon_loss': 0.005973308571818849, 'test_loss': 0.005973308571818849}
Best loss: 0.0003644253337683936
Epoch 136:
Training summary: {'train_recon_loss': 0.0014242625771857171, 'train_loss': 0.0014242625771857171}
Evaluation summary: {'test_recon_loss': 0.0009762824930051609, 'test_loss': 0.0009762824930051609}
Best loss: 0.0003644253337683936
Epoch 137:
Training summary: {'train_recon_loss': 0.0007375819239783508, 'train_loss': 0.0007375819239783508}
Evaluation summary: {'test_recon_loss': 0.0005585458970521564, 'test_loss': 0.0005585458970521564}
Best loss: 0.0003644253337683936
Epoch 138:
Training summary: {'train_recon_loss': 0.0005663412662906656, 'train_loss': 0.0005663412662906656}
Evaluation summary: {'test_recon_loss': 0.0004790023394735985, 'test_loss': 0.0004790023394735985}
Best loss: 0.0003644253337683936
Epoch 139:
Training summary: {'train_recon_loss': 0.0005073210225743318, 'train_loss': 0.0005073210225743318}
Evaluation summary: {'test_recon_loss': 0.00043671411551726296, 'test_loss': 0.00043671411551726296}
Best loss: 0.0003644253337683936
Epoch 140:
Training summary: {'train_recon_loss': 0.0004734257387298461, 'train_loss': 0.0004734257387298461}
Evaluation summary: {'test_recon_loss': 0.0004083955313475784, 'test_loss': 0.0004083955313475784}
Best loss: 0.0003644253337683936
Epoch 141:
Training summary: {'train_recon_loss': 0.0004501464523604575, 'train_loss': 0.0004501464523604575}
Evaluation summary: {'test_recon_loss': 0.00041401066375116485, 'test_loss': 0.00041401066375116485}
Best loss: 0.0003644253337683936
Epoch 142:
Training summary: {'train_recon_loss': 0.0019740716600708343, 'train_loss': 0.0019740716600708343}
Evaluation summary: {'test_recon_loss': 0.0013945334915794409, 'test_loss': 0.0013945334915794409}
Best loss: 0.0003644253337683936
Epoch 143:
Training summary: {'train_recon_loss': 0.0007660532838750517, 'train_loss': 0.0007660532838750517}
Evaluation summary: {'test_recon_loss': 0.0005724209705441372, 'test_loss': 0.0005724209705441372}
Best loss: 0.0003644253337683936
Epoch 144:
Training summary: {'train_recon_loss': 0.0005514515358062017, 'train_loss': 0.0005514515358062017}
Evaluation summary: {'test_recon_loss': 0.0004714847095917766, 'test_loss': 0.0004714847095917766}
Best loss: 0.0003644253337683936
Epoch 145:
Training summary: {'train_recon_loss': 0.0004932807395732451, 'train_loss': 0.0004932807395732451}
Evaluation summary: {'test_recon_loss': 0.00042433418952251195, 'test_loss': 0.00042433418952251195}
Best loss: 0.0003644253337683936
Epoch 146:
Training summary: {'train_recon_loss': 0.0004707453858297377, 'train_loss': 0.0004707453858297377}
Evaluation summary: {'test_recon_loss': 0.0004104200663651767, 'test_loss': 0.0004104200663651767}
Best loss: 0.0003644253337683936
Epoch 147:
Training summary: {'train_recon_loss': 0.0014487212555595688, 'train_loss': 0.0014487212555595688}
Evaluation summary: {'test_recon_loss': 0.0024931417124483216, 'test_loss': 0.0024931417124483216}
Best loss: 0.0003644253337683936
Epoch 148:
Training summary: {'train_recon_loss': 0.0013764049279274813, 'train_loss': 0.0013764049279274813}
Evaluation summary: {'test_recon_loss': 0.0008517933156700351, 'test_loss': 0.0008517933156700351}
Best loss: 0.0003644253337683936
Epoch 149:
Training summary: {'train_recon_loss': 0.0006867525458390182, 'train_loss': 0.0006867525458390182}
Evaluation summary: {'test_recon_loss': 0.0005561922320663909, 'test_loss': 0.0005561922320663909}
Best loss: 0.0003644253337683936
Epoch 150:
Training summary: {'train_recon_loss': 0.0005514612762823487, 'train_loss': 0.0005514612762823487}
Evaluation summary: {'test_recon_loss': 0.00048742890207100495, 'test_loss': 0.00048742890207100495}
Best loss: 0.0003644253337683936
Epoch 151:
Training summary: {'train_recon_loss': 0.0004973954126418174, 'train_loss': 0.0004973954126418174}
Evaluation summary: {'test_recon_loss': 0.00044485804030172665, 'test_loss': 0.00044485804030172665}
Best loss: 0.0003644253337683936
Epoch 152:
Training summary: {'train_recon_loss': 0.0004670229829809149, 'train_loss': 0.0004670229829809149}
Evaluation summary: {'test_recon_loss': 0.0003860864098258498, 'test_loss': 0.0003860864098258498}
Best loss: 0.0003644253337683936
Epoch 153:
Training summary: {'train_recon_loss': 0.0004481674692767936, 'train_loss': 0.0004481674692767936}
Evaluation summary: {'test_recon_loss': 0.00037571774087955147, 'test_loss': 0.00037571774087955147}
Best loss: 0.0003644253337683936
Epoch 154:
Training summary: {'train_recon_loss': 0.002150805939415505, 'train_loss': 0.002150805939415505}
Evaluation summary: {'test_recon_loss': 0.0016102570384956393, 'test_loss': 0.0016102570384956393}
Best loss: 0.0003644253337683936
Epoch 155:
Training summary: {'train_recon_loss': 0.0010870956151841661, 'train_loss': 0.0010870956151841661}
Evaluation summary: {'test_recon_loss': 0.0008460322358079013, 'test_loss': 0.0008460322358079013}
Best loss: 0.0003644253337683936
Epoch 156:
Training summary: {'train_recon_loss': 0.0007177091119506527, 'train_loss': 0.0007177091119506527}
Evaluation summary: {'test_recon_loss': 0.0005859409724809189, 'test_loss': 0.0005859409724809189}
Best loss: 0.0003644253337683936
Epoch 157:
Training summary: {'train_recon_loss': 0.0005911375357285665, 'train_loss': 0.0005911375357285665}
Evaluation summary: {'test_recon_loss': 0.0005818749133506667, 'test_loss': 0.0005818749133506667}
Best loss: 0.0003644253337683936
Epoch 158:
Training summary: {'train_recon_loss': 0.0005385035938643372, 'train_loss': 0.0005385035938643372}
Evaluation summary: {'test_recon_loss': 0.0004793365603543303, 'test_loss': 0.0004793365603543303}
Best loss: 0.0003644253337683936
Epoch 159:
Training summary: {'train_recon_loss': 0.0004942289134199555, 'train_loss': 0.0004942289134199555}
Evaluation summary: {'test_recon_loss': 0.00046467494044427534, 'test_loss': 0.00046467494044427534}
Best loss: 0.0003644253337683936
Epoch 160:
Training summary: {'train_recon_loss': 0.00047236390650649205, 'train_loss': 0.00047236390650649205}
Evaluation summary: {'test_recon_loss': 0.0004316546342133915, 'test_loss': 0.0004316546342133915}
Best loss: 0.0003644253337683936
Epoch 161:
Training summary: {'train_recon_loss': 0.000464654940508747, 'train_loss': 0.000464654940508747}
Evaluation summary: {'test_recon_loss': 0.00040642866855551164, 'test_loss': 0.00040642866855551164}
Best loss: 0.0003644253337683936
Epoch 162:
Training summary: {'train_recon_loss': 0.000446298005346903, 'train_loss': 0.000446298005346903}
Evaluation summary: {'test_recon_loss': 0.00041075831305808895, 'test_loss': 0.00041075831305808895}
Best loss: 0.0003644253337683936
Epoch 163:
Training summary: {'train_recon_loss': 0.0007246427325710371, 'train_loss': 0.0007246427325710371}
Evaluation summary: {'test_recon_loss': 0.061668893647389776, 'test_loss': 0.061668893647389776}
Best loss: 0.0003644253337683936
Epoch 164:
Training summary: {'train_recon_loss': 0.001700090745142283, 'train_loss': 0.001700090745142283}
Evaluation summary: {'test_recon_loss': 0.0009592590524961937, 'test_loss': 0.0009592590524961937}
Best loss: 0.0003644253337683936
Epoch 165:
Training summary: {'train_recon_loss': 0.0006822025687836918, 'train_loss': 0.0006822025687836918}
Evaluation summary: {'test_recon_loss': 0.0005711843124551788, 'test_loss': 0.0005711843124551788}
Best loss: 0.0003644253337683936
Epoch 166:
Training summary: {'train_recon_loss': 0.0005429711043419208, 'train_loss': 0.0005429711043419208}
Evaluation summary: {'test_recon_loss': 0.000492092433268141, 'test_loss': 0.000492092433268141}
Best loss: 0.0003644253337683936
Epoch 167:
Training summary: {'train_recon_loss': 0.0012581441653773113, 'train_loss': 0.0012581441653773113}
Evaluation summary: {'test_recon_loss': 0.006126161571987484, 'test_loss': 0.006126161571987484}
Best loss: 0.0003644253337683936
Epoch 168:
Training summary: {'train_recon_loss': 0.0011290023727597517, 'train_loss': 0.0011290023727597517}
Evaluation summary: {'test_recon_loss': 0.0006643031801841865, 'test_loss': 0.0006643031801841865}
Best loss: 0.0003644253337683936
Epoch 169:
Training summary: {'train_recon_loss': 0.0005556018226047776, 'train_loss': 0.0005556018226047776}
Evaluation summary: {'test_recon_loss': 0.0005219933724889874, 'test_loss': 0.0005219933724889874}
Best loss: 0.0003644253337683936
Epoch 170:
Training summary: {'train_recon_loss': 0.0004819831889564529, 'train_loss': 0.0004819831889564529}
Evaluation summary: {'test_recon_loss': 0.0003980123531204272, 'test_loss': 0.0003980123531204272}
Best loss: 0.0003644253337683936
Epoch 171:
Training summary: {'train_recon_loss': 0.0004556680979209626, 'train_loss': 0.0004556680979209626}
Evaluation summary: {'test_recon_loss': 0.00039760592679329644, 'test_loss': 0.00039760592679329644}
Best loss: 0.0003644253337683936
Epoch 172:
Training summary: {'train_recon_loss': 0.0018214132102941044, 'train_loss': 0.0018214132102941044}
Evaluation summary: {'test_recon_loss': 0.0032332919149255404, 'test_loss': 0.0032332919149255404}
Best loss: 0.0003644253337683936
Epoch 173:
Training summary: {'train_recon_loss': 0.0013093418782525908, 'train_loss': 0.0013093418782525908}
Evaluation summary: {'test_recon_loss': 0.0008098673387904561, 'test_loss': 0.0008098673387904561}
Best loss: 0.0003644253337683936
Epoch 174:
Training summary: {'train_recon_loss': 0.000638453917964131, 'train_loss': 0.000638453917964131}
Evaluation summary: {'test_recon_loss': 0.0005153332695577358, 'test_loss': 0.0005153332695577358}
Best loss: 0.0003644253337683936
Epoch 175:
Training summary: {'train_recon_loss': 0.0005230705123995321, 'train_loss': 0.0005230705123995321}
Evaluation summary: {'test_recon_loss': 0.00045509655989166883, 'test_loss': 0.00045509655989166883}
Best loss: 0.0003644253337683936
Epoch 176:
Training summary: {'train_recon_loss': 0.002211444925995255, 'train_loss': 0.002211444925995255}
Evaluation summary: {'test_recon_loss': 0.0022492060431277125, 'test_loss': 0.0022492060431277125}
Best loss: 0.0003644253337683936
Epoch 177:
generate_recon.py --datadir . --metafile /mountb/single_cell_flist/ch2_all.csv --save-dir /mountb/autoencoder/ch2 --latent-dims 2048 --ae-features --pretrained-file /mountb/autoencoder/ch2/models/best.pth
Namespace(ae_features=True, batch_size=128, datadir='.', latent_dims=2048, metafile='/mountb/single_cell_flist/ch2_all.csv', pca_features=False, pretrained_file='/mountb/autoencoder/ch2/models/best.pth', save_dir='/mountb/autoencoder/ch2')
Training summary: {'train_recon_loss': 0.001166138044075527, 'train_loss': 0.001166138044075527}
Dataset length is 9068498
AE46(
  (encoder): Sequential(
    (0): Conv2d(1, 46, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(46, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(92, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(184, 368, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (12): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (fc1): Linear(in_features=1472, out_features=2048, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): ConvTranspose2d(368, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): ConvTranspose2d(184, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
    (9): ConvTranspose2d(92, 46, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace=True)
    (12): ConvTranspose2d(46, 1, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Sigmoid()
  )
  (d1): Linear(in_features=2048, out_features=1472, bias=True)
  (mseloss): MSELoss()
)
Evaluation summary: {'test_recon_loss': 0.0006790789880880655, 'test_loss': 0.0006790789880880655}
Best loss: 0.0003644253337683936
Epoch 178:
Training summary: {'train_recon_loss': 0.0006247934319289535, 'train_loss': 0.0006247934319289535}
Evaluation summary: {'test_recon_loss': 0.0005557185768617281, 'test_loss': 0.0005557185768617281}
Best loss: 0.0003644253337683936
Epoch 179:
