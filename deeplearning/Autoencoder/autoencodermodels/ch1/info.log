run_train.py --max-value 36576 --datadir . --train-metafile /mountb/single_cell_flist/train_ch1_small.csv --val-metafile /mountb/single_cell_flist/val_ch1_small.csv --save-dir /mountb/autoencoder/ch1 --model-type AE46 --dataset-type 46 --latent-dims 2048
Namespace(batch_size=128, datadir='.', dataset_type='46', debug_mode=False, latent_dims=2048, learning_rate=0.001, max_epochs=2000, max_value=36576, model_type='AE46', num_workers=8, optimizer='adam', save_dir='/mountb/autoencoder/ch1', save_freq=50, seed=42, train_metafile='/mountb/single_cell_flist/train_ch1_small.csv', val_metafile='/mountb/single_cell_flist/val_ch1_small.csv', weight_decay=1e-05)
AE46(
  (encoder): Sequential(
    (0): Conv2d(1, 46, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(46, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(92, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(184, 368, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (12): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (fc1): Linear(in_features=1472, out_features=2048, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): ConvTranspose2d(368, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): ConvTranspose2d(184, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
    (9): ConvTranspose2d(92, 46, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace=True)
    (12): ConvTranspose2d(46, 1, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Sigmoid()
  )
  (d1): Linear(in_features=2048, out_features=1472, bias=True)
  (mseloss): MSELoss()
)
Epoch 0:
Training summary: {'train_recon_loss': 0.005560592116579054, 'train_loss': 0.005560592116579054}
Evaluation summary: {'test_recon_loss': 0.0012426713813056647, 'test_loss': 0.0012426713813056647}
Best loss: 0.0012426713813056647
Epoch 1:
Training summary: {'train_recon_loss': 0.0008848076945935061, 'train_loss': 0.0008848076945935061}
Evaluation summary: {'test_recon_loss': 0.0006419088755505606, 'test_loss': 0.0006419088755505606}
Best loss: 0.0006419088755505606
Epoch 2:
Training summary: {'train_recon_loss': 0.0006510281774183312, 'train_loss': 0.0006510281774183312}
Evaluation summary: {'test_recon_loss': 0.0006015472461310236, 'test_loss': 0.0006015472461310236}
Best loss: 0.0006015472461310236
Epoch 3:
Training summary: {'train_recon_loss': 0.0005388086256093935, 'train_loss': 0.0005388086256093935}
Evaluation summary: {'test_recon_loss': 0.0005268377165643392, 'test_loss': 0.0005268377165643392}
Best loss: 0.0005268377165643392
Epoch 4:
Training summary: {'train_recon_loss': 0.000447594075533232, 'train_loss': 0.000447594075533232}
Evaluation summary: {'test_recon_loss': 0.0004522373266218236, 'test_loss': 0.0004522373266218236}
Best loss: 0.0004522373266218236
Epoch 5:
Training summary: {'train_recon_loss': 0.00039900197455611784, 'train_loss': 0.00039900197455611784}
Evaluation summary: {'test_recon_loss': 0.0003273442250385125, 'test_loss': 0.0003273442250385125}
Best loss: 0.0003273442250385125
Epoch 6:
Training summary: {'train_recon_loss': 0.0003787780510382593, 'train_loss': 0.0003787780510382593}
Evaluation summary: {'test_recon_loss': 0.0003186458367645621, 'test_loss': 0.0003186458367645621}
Best loss: 0.0003186458367645621
Epoch 7:
Training summary: {'train_recon_loss': 0.00035045200970366117, 'train_loss': 0.00035045200970366117}
Evaluation summary: {'test_recon_loss': 0.0004230158326231883, 'test_loss': 0.0004230158326231883}
Best loss: 0.0003186458367645621
Epoch 8:
Training summary: {'train_recon_loss': 0.00032881561078171523, 'train_loss': 0.00032881561078171523}
Evaluation summary: {'test_recon_loss': 0.0003748142018850628, 'test_loss': 0.0003748142018850628}
Best loss: 0.0003186458367645621
Epoch 9:
Training summary: {'train_recon_loss': 0.0003045676263232715, 'train_loss': 0.0003045676263232715}
Evaluation summary: {'test_recon_loss': 0.00036013437147866306, 'test_loss': 0.00036013437147866306}
Best loss: 0.0003186458367645621
Epoch 10:
Training summary: {'train_recon_loss': 0.0007122957725672286, 'train_loss': 0.0007122957725672286}
Evaluation summary: {'test_recon_loss': 0.00037306849460757126, 'test_loss': 0.00037306849460757126}
Best loss: 0.0003186458367645621
Epoch 11:
Training summary: {'train_recon_loss': 0.00035294500168173566, 'train_loss': 0.00035294500168173566}
Evaluation summary: {'test_recon_loss': 0.0002537412612647547, 'test_loss': 0.0002537412612647547}
Best loss: 0.0002537412612647547
Epoch 12:
Training summary: {'train_recon_loss': 0.0003049326344296934, 'train_loss': 0.0003049326344296934}
Evaluation summary: {'test_recon_loss': 0.000310377149414285, 'test_loss': 0.000310377149414285}
Best loss: 0.0002537412612647547
Epoch 13:
Training summary: {'train_recon_loss': 0.0002930708750274096, 'train_loss': 0.0002930708750274096}
Evaluation summary: {'test_recon_loss': 0.00022250040656441263, 'test_loss': 0.00022250040656441263}
Best loss: 0.00022250040656441263
Epoch 14:
Training summary: {'train_recon_loss': 0.00026828064856797377, 'train_loss': 0.00026828064856797377}
Evaluation summary: {'test_recon_loss': 0.000218583961414514, 'test_loss': 0.000218583961414514}
Best loss: 0.000218583961414514
Epoch 15:
Training summary: {'train_recon_loss': 0.00044457461138242753, 'train_loss': 0.00044457461138242753}
Evaluation summary: {'test_recon_loss': 0.002257969652658877, 'test_loss': 0.002257969652658877}
Best loss: 0.000218583961414514
Epoch 16:
Training summary: {'train_recon_loss': 0.0006002323406722971, 'train_loss': 0.0006002323406722971}
Evaluation summary: {'test_recon_loss': 0.0003621511482337622, 'test_loss': 0.0003621511482337622}
Best loss: 0.000218583961414514
Epoch 17:
Training summary: {'train_recon_loss': 0.0002973641983084064, 'train_loss': 0.0002973641983084064}
Evaluation summary: {'test_recon_loss': 0.00023411944631941757, 'test_loss': 0.00023411944631941757}
Best loss: 0.000218583961414514
Epoch 18:
Training summary: {'train_recon_loss': 0.0002792342456171612, 'train_loss': 0.0002792342456171612}
Evaluation summary: {'test_recon_loss': 0.0003313554598999508, 'test_loss': 0.0003313554598999508}
Best loss: 0.000218583961414514
Epoch 19:
Training summary: {'train_recon_loss': 0.0002676835769814991, 'train_loss': 0.0002676835769814991}
Evaluation summary: {'test_recon_loss': 0.0002200828786079692, 'test_loss': 0.0002200828786079692}
Best loss: 0.000218583961414514
Epoch 20:
Training summary: {'train_recon_loss': 0.00026314293163747947, 'train_loss': 0.00026314293163747947}
Evaluation summary: {'test_recon_loss': 0.0002529285148538357, 'test_loss': 0.0002529285148538357}
Best loss: 0.000218583961414514
Epoch 21:
Training summary: {'train_recon_loss': 0.0002693697777932571, 'train_loss': 0.0002693697777932571}
Evaluation summary: {'test_recon_loss': 0.00022707578533604257, 'test_loss': 0.00022707578533604257}
Best loss: 0.000218583961414514
Epoch 22:
Training summary: {'train_recon_loss': 0.000272075648248021, 'train_loss': 0.000272075648248021}
Evaluation summary: {'test_recon_loss': 0.0002105421145139234, 'test_loss': 0.0002105421145139234}
Best loss: 0.0002105421145139234
Epoch 23:
Training summary: {'train_recon_loss': 0.0006735504276763775, 'train_loss': 0.0006735504276763775}
Evaluation summary: {'test_recon_loss': 0.003960239464714824, 'test_loss': 0.003960239464714824}
Best loss: 0.0002105421145139234
Epoch 24:
Training summary: {'train_recon_loss': 0.0007600276311880058, 'train_loss': 0.0007600276311880058}
Evaluation summary: {'test_recon_loss': 0.0004836204246375073, 'test_loss': 0.0004836204246375073}
Best loss: 0.0002105421145139234
Epoch 25:
Training summary: {'train_recon_loss': 0.0003213097434994835, 'train_loss': 0.0003213097434994835}
Evaluation summary: {'test_recon_loss': 0.0002461310574257414, 'test_loss': 0.0002461310574257414}
Best loss: 0.0002105421145139234
Epoch 26:
Training summary: {'train_recon_loss': 0.0005291399154454209, 'train_loss': 0.0005291399154454209}
Evaluation summary: {'test_recon_loss': 0.00022593827456281556, 'test_loss': 0.00022593827456281556}
Best loss: 0.0002105421145139234
Epoch 27:
Training summary: {'train_recon_loss': 0.0002826173029191685, 'train_loss': 0.0002826173029191685}
Evaluation summary: {'test_recon_loss': 0.00021433353081488877, 'test_loss': 0.00021433353081488877}
Best loss: 0.0002105421145139234
Epoch 28:
Training summary: {'train_recon_loss': 0.0002682431263517174, 'train_loss': 0.0002682431263517174}
Evaluation summary: {'test_recon_loss': 0.00024224454139975442, 'test_loss': 0.00024224454139975442}
Best loss: 0.0002105421145139234
Epoch 29:
Training summary: {'train_recon_loss': 0.00026589264539308966, 'train_loss': 0.00026589264539308966}
Evaluation summary: {'test_recon_loss': 0.00025084454730956086, 'test_loss': 0.00025084454730956086}
Best loss: 0.0002105421145139234
Epoch 30:
Training summary: {'train_recon_loss': 0.00025634401017765395, 'train_loss': 0.00025634401017765395}
Evaluation summary: {'test_recon_loss': 0.00020545715115689026, 'test_loss': 0.00020545715115689026}
Best loss: 0.00020545715115689026
Epoch 31:
Training summary: {'train_recon_loss': 0.0002655114889029306, 'train_loss': 0.0002655114889029306}
Evaluation summary: {'test_recon_loss': 0.0002604835944702046, 'test_loss': 0.0002604835944702046}
Best loss: 0.00020545715115689026
Epoch 32:
Training summary: {'train_recon_loss': 0.0004782282483079902, 'train_loss': 0.0004782282483079902}
Evaluation summary: {'test_recon_loss': 0.0030540201476310755, 'test_loss': 0.0030540201476310755}
Best loss: 0.00020545715115689026
Epoch 33:
Training summary: {'train_recon_loss': 0.0005200127220520076, 'train_loss': 0.0005200127220520076}
Evaluation summary: {'test_recon_loss': 0.00026641475182533845, 'test_loss': 0.00026641475182533845}
Best loss: 0.00020545715115689026
Epoch 34:
Training summary: {'train_recon_loss': 0.00028133904810788337, 'train_loss': 0.00028133904810788337}
Evaluation summary: {'test_recon_loss': 0.00024179099473231166, 'test_loss': 0.00024179099473231166}
Best loss: 0.00020545715115689026
Epoch 35:
Training summary: {'train_recon_loss': 0.0002635318546853354, 'train_loss': 0.0002635318546853354}
Evaluation summary: {'test_recon_loss': 0.00019677941123949052, 'test_loss': 0.00019677941123949052}
Best loss: 0.00019677941123949052
Epoch 36:
Training summary: {'train_recon_loss': 0.0002629971881903042, 'train_loss': 0.0002629971881903042}
Evaluation summary: {'test_recon_loss': 0.0002059511675767307, 'test_loss': 0.0002059511675767307}
Best loss: 0.00019677941123949052
Epoch 37:
Training summary: {'train_recon_loss': 0.0002560889195258374, 'train_loss': 0.0002560889195258374}
Evaluation summary: {'test_recon_loss': 0.00018674350543659843, 'test_loss': 0.00018674350543659843}
Best loss: 0.00018674350543659843
Epoch 38:
Training summary: {'train_recon_loss': 0.0008472058184789623, 'train_loss': 0.0008472058184789623}
Evaluation summary: {'test_recon_loss': 0.0008358720775200499, 'test_loss': 0.0008358720775200499}
Best loss: 0.00018674350543659843
Epoch 39:
Training summary: {'train_recon_loss': 0.00046504115852010597, 'train_loss': 0.00046504115852010597}
Evaluation summary: {'test_recon_loss': 0.00042101276950570656, 'test_loss': 0.00042101276950570656}
Best loss: 0.00018674350543659843
Epoch 40:
Training summary: {'train_recon_loss': 0.0002834546557813141, 'train_loss': 0.0002834546557813141}
Evaluation summary: {'test_recon_loss': 0.00022496463664183587, 'test_loss': 0.00022496463664183587}
Best loss: 0.00018674350543659843
Epoch 41:
Training summary: {'train_recon_loss': 0.00026629270775208253, 'train_loss': 0.00026629270775208253}
Evaluation summary: {'test_recon_loss': 0.00023566724222311362, 'test_loss': 0.00023566724222311362}
Best loss: 0.00018674350543659843
Epoch 42:
Training summary: {'train_recon_loss': 0.000805337987945073, 'train_loss': 0.000805337987945073}
Evaluation summary: {'test_recon_loss': 0.00046787828374010397, 'test_loss': 0.00046787828374010397}
Best loss: 0.00018674350543659843
Epoch 43:
Training summary: {'train_recon_loss': 0.0003240650502554318, 'train_loss': 0.0003240650502554318}
Evaluation summary: {'test_recon_loss': 0.0010430096783322733, 'test_loss': 0.0010430096783322733}
Best loss: 0.00018674350543659843
Epoch 44:
Training summary: {'train_recon_loss': 0.00026179896446492827, 'train_loss': 0.00026179896446492827}
Evaluation summary: {'test_recon_loss': 0.00026655397801764755, 'test_loss': 0.00026655397801764755}
Best loss: 0.00018674350543659843
Epoch 45:
Training summary: {'train_recon_loss': 0.00025913783541614, 'train_loss': 0.00025913783541614}
Evaluation summary: {'test_recon_loss': 0.0002570988992069535, 'test_loss': 0.0002570988992069535}
Best loss: 0.00018674350543659843
Epoch 46:
Training summary: {'train_recon_loss': 0.0002577139876131706, 'train_loss': 0.0002577139876131706}
Evaluation summary: {'test_recon_loss': 0.00021864855420020656, 'test_loss': 0.00021864855420020656}
Best loss: 0.00018674350543659843
Epoch 47:
Training summary: {'train_recon_loss': 0.00025868143572870233, 'train_loss': 0.00025868143572870233}
Evaluation summary: {'test_recon_loss': 0.00021942442548828018, 'test_loss': 0.00021942442548828018}
Best loss: 0.00018674350543659843
Epoch 48:
Training summary: {'train_recon_loss': 0.0009782160018869366, 'train_loss': 0.0009782160018869366}
Evaluation summary: {'test_recon_loss': 0.0005308156770438557, 'test_loss': 0.0005308156770438557}
Best loss: 0.00018674350543659843
Epoch 49:
Training summary: {'train_recon_loss': 0.0003766247228980099, 'train_loss': 0.0003766247228980099}
Evaluation summary: {'test_recon_loss': 0.00028111335549253443, 'test_loss': 0.00028111335549253443}
Best loss: 0.00018674350543659843
Epoch 50:
Training summary: {'train_recon_loss': 0.00027134255014006983, 'train_loss': 0.00027134255014006983}
Evaluation summary: {'test_recon_loss': 0.00022100231383720672, 'test_loss': 0.00022100231383720672}
Best loss: 0.00018674350543659843
Epoch 51:
Training summary: {'train_recon_loss': 0.0002644541876214924, 'train_loss': 0.0002644541876214924}
Evaluation summary: {'test_recon_loss': 0.00022563913232177065, 'test_loss': 0.00022563913232177065}
Best loss: 0.00018674350543659843
Epoch 52:
Training summary: {'train_recon_loss': 0.00025738062801982314, 'train_loss': 0.00025738062801982314}
Evaluation summary: {'test_recon_loss': 0.00021435322985413792, 'test_loss': 0.00021435322985413792}
Best loss: 0.00018674350543659843
Epoch 53:
Training summary: {'train_recon_loss': 0.0002531392621721777, 'train_loss': 0.0002531392621721777}
Evaluation summary: {'test_recon_loss': 0.0001996573435254372, 'test_loss': 0.0001996573435254372}
Best loss: 0.00018674350543659843
Epoch 54:
Training summary: {'train_recon_loss': 0.0009403000449728421, 'train_loss': 0.0009403000449728421}
Evaluation summary: {'test_recon_loss': 0.0008332621309974384, 'test_loss': 0.0008332621309974384}
Best loss: 0.00018674350543659843
Epoch 55:
Training summary: {'train_recon_loss': 0.0003527830464497222, 'train_loss': 0.0003527830464497222}
Evaluation summary: {'test_recon_loss': 0.00025549888625833826, 'test_loss': 0.00025549888625833826}
Best loss: 0.00018674350543659843
Epoch 56:
Training summary: {'train_recon_loss': 0.0002814420433758179, 'train_loss': 0.0002814420433758179}
Evaluation summary: {'test_recon_loss': 0.0002591961952144047, 'test_loss': 0.0002591961952144047}
Best loss: 0.00018674350543659843
Epoch 57:
Training summary: {'train_recon_loss': 0.00025628531806137246, 'train_loss': 0.00025628531806137246}
Evaluation summary: {'test_recon_loss': 0.00020328674621741238, 'test_loss': 0.00020328674621741238}
Best loss: 0.00018674350543659843
Epoch 58:
Training summary: {'train_recon_loss': 0.0006487161678927643, 'train_loss': 0.0006487161678927643}
Evaluation summary: {'test_recon_loss': 0.0006807609274336403, 'test_loss': 0.0006807609274336403}
Best loss: 0.00018674350543659843
Epoch 59:
Training summary: {'train_recon_loss': 0.00041693194199895697, 'train_loss': 0.00041693194199895697}
Evaluation summary: {'test_recon_loss': 0.0002457822914945429, 'test_loss': 0.0002457822914945429}
Best loss: 0.00018674350543659843
Epoch 60:
Training summary: {'train_recon_loss': 0.0002737124334295138, 'train_loss': 0.0002737124334295138}
Evaluation summary: {'test_recon_loss': 0.0002785654596458647, 'test_loss': 0.0002785654596458647}
Best loss: 0.00018674350543659843
Epoch 61:
Training summary: {'train_recon_loss': 0.0004483465906781764, 'train_loss': 0.0004483465906781764}
Evaluation summary: {'test_recon_loss': 0.0034156364965082955, 'test_loss': 0.0034156364965082955}
Best loss: 0.00018674350543659843
Epoch 62:
Training summary: {'train_recon_loss': 0.0007180945582477237, 'train_loss': 0.0007180945582477237}
Evaluation summary: {'test_recon_loss': 0.00028098755784643117, 'test_loss': 0.00028098755784643117}
Best loss: 0.00018674350543659843
Epoch 63:
Training summary: {'train_recon_loss': 0.00029101432313959107, 'train_loss': 0.00029101432313959107}
Evaluation summary: {'test_recon_loss': 0.00022865644067584725, 'test_loss': 0.00022865644067584725}
Best loss: 0.00018674350543659843
Epoch 64:
Training summary: {'train_recon_loss': 0.0002615702474111765, 'train_loss': 0.0002615702474111765}
Evaluation summary: {'test_recon_loss': 0.00026305421381328346, 'test_loss': 0.00026305421381328346}
Best loss: 0.00018674350543659843
Epoch 65:
Training summary: {'train_recon_loss': 0.00025484553102630953, 'train_loss': 0.00025484553102630953}
Evaluation summary: {'test_recon_loss': 0.00023227547546560335, 'test_loss': 0.00023227547546560335}
Best loss: 0.00018674350543659843
Epoch 66:
Training summary: {'train_recon_loss': 0.000257311824019324, 'train_loss': 0.000257311824019324}
Evaluation summary: {'test_recon_loss': 0.0001985110920328442, 'test_loss': 0.0001985110920328442}
Best loss: 0.00018674350543659843
Epoch 67:
Training summary: {'train_recon_loss': 0.0002616939947900505, 'train_loss': 0.0002616939947900505}
Evaluation summary: {'test_recon_loss': 0.0002008996626054803, 'test_loss': 0.0002008996626054803}
Best loss: 0.00018674350543659843
Epoch 68:
Training summary: {'train_recon_loss': 0.00025090665951706017, 'train_loss': 0.00025090665951706017}
Evaluation summary: {'test_recon_loss': 0.00020510124297447966, 'test_loss': 0.00020510124297447966}
Best loss: 0.00018674350543659843
Epoch 69:
Training summary: {'train_recon_loss': 0.0008843501725317587, 'train_loss': 0.0008843501725317587}
Evaluation summary: {'test_recon_loss': 0.0004728936856198841, 'test_loss': 0.0004728936856198841}
Best loss: 0.00018674350543659843
Epoch 70:
Training summary: {'train_recon_loss': 0.0003469968621879026, 'train_loss': 0.0003469968621879026}
Evaluation summary: {'test_recon_loss': 0.0002598355405348999, 'test_loss': 0.0002598355405348999}
Best loss: 0.00018674350543659843
Epoch 71:
Training summary: {'train_recon_loss': 0.00027129824691128764, 'train_loss': 0.00027129824691128764}
Evaluation summary: {'test_recon_loss': 0.00024027603970595737, 'test_loss': 0.00024027603970595737}
Best loss: 0.00018674350543659843
Epoch 72:
Training summary: {'train_recon_loss': 0.00026232721245980905, 'train_loss': 0.00026232721245980905}
Evaluation summary: {'test_recon_loss': 0.00040215353497697937, 'test_loss': 0.00040215353497697937}
Best loss: 0.00018674350543659843
Epoch 73:
Training summary: {'train_recon_loss': 0.00025489747511612073, 'train_loss': 0.00025489747511612073}
Evaluation summary: {'test_recon_loss': 0.0002160592013992739, 'test_loss': 0.0002160592013992739}
Best loss: 0.00018674350543659843
Epoch 74:
Training summary: {'train_recon_loss': 0.0002565087547238636, 'train_loss': 0.0002565087547238636}
Evaluation summary: {'test_recon_loss': 0.00022757498712391283, 'test_loss': 0.00022757498712391283}
Best loss: 0.00018674350543659843
Epoch 75:
Training summary: {'train_recon_loss': 0.0002548016999634687, 'train_loss': 0.0002548016999634687}
Evaluation summary: {'test_recon_loss': 0.00021790813540132953, 'test_loss': 0.00021790813540132953}
Best loss: 0.00018674350543659843
Epoch 76:
Training summary: {'train_recon_loss': 0.00099723337304757, 'train_loss': 0.00099723337304757}
Evaluation summary: {'test_recon_loss': 0.0005219136366458964, 'test_loss': 0.0005219136366458964}
Best loss: 0.00018674350543659843
Epoch 77:
Training summary: {'train_recon_loss': 0.0003651889362596651, 'train_loss': 0.0003651889362596651}
Evaluation summary: {'test_recon_loss': 0.00025897242778950667, 'test_loss': 0.00025897242778950667}
Best loss: 0.00018674350543659843
Epoch 78:
Training summary: {'train_recon_loss': 0.0002737385548372315, 'train_loss': 0.0002737385548372315}
Evaluation summary: {'test_recon_loss': 0.00025759784151629136, 'test_loss': 0.00025759784151629136}
Best loss: 0.00018674350543659843
Epoch 79:
Training summary: {'train_recon_loss': 0.0002554414066561751, 'train_loss': 0.0002554414066561751}
Evaluation summary: {'test_recon_loss': 0.0002494875245136362, 'test_loss': 0.0002494875245136362}
Best loss: 0.00018674350543659843
Epoch 80:
Training summary: {'train_recon_loss': 0.00025717481066717205, 'train_loss': 0.00025717481066717205}
Evaluation summary: {'test_recon_loss': 0.00024581897083206797, 'test_loss': 0.00024581897083206797}
Best loss: 0.00018674350543659843
Epoch 81:
Training summary: {'train_recon_loss': 0.0002558201286314851, 'train_loss': 0.0002558201286314851}
Evaluation summary: {'test_recon_loss': 0.00020197904460157818, 'test_loss': 0.00020197904460157818}
Best loss: 0.00018674350543659843
Epoch 82:
Training summary: {'train_recon_loss': 0.0002462998335794777, 'train_loss': 0.0002462998335794777}
Evaluation summary: {'test_recon_loss': 0.00031040241078653303, 'test_loss': 0.00031040241078653303}
Best loss: 0.00018674350543659843
Epoch 83:
Training summary: {'train_recon_loss': 0.0006714561351650233, 'train_loss': 0.0006714561351650233}
Evaluation summary: {'test_recon_loss': 0.0004979217436067361, 'test_loss': 0.0004979217436067361}
Best loss: 0.00018674350543659843
Epoch 84:
Training summary: {'train_recon_loss': 0.0003028632647213085, 'train_loss': 0.0003028632647213085}
Evaluation summary: {'test_recon_loss': 0.00022064805984979726, 'test_loss': 0.00022064805984979726}
Best loss: 0.00018674350543659843
Epoch 85:
Training summary: {'train_recon_loss': 0.0002552714136506467, 'train_loss': 0.0002552714136506467}
Evaluation summary: {'test_recon_loss': 0.00021187887888076014, 'test_loss': 0.00021187887888076014}
Best loss: 0.00018674350543659843
Epoch 86:
Training summary: {'train_recon_loss': 0.0002497254013451631, 'train_loss': 0.0002497254013451631}
Evaluation summary: {'test_recon_loss': 0.00018579789416576386, 'test_loss': 0.00018579789416576386}
Best loss: 0.00018579789416576386
Epoch 87:
Training summary: {'train_recon_loss': 0.00024184624848775456, 'train_loss': 0.00024184624848775456}
Evaluation summary: {'test_recon_loss': 0.0001883451362441537, 'test_loss': 0.0001883451362441537}
Best loss: 0.00018579789416576386
Epoch 88:
Training summary: {'train_recon_loss': 0.00024177350055828715, 'train_loss': 0.00024177350055828715}
Evaluation summary: {'test_recon_loss': 0.00019758767015731635, 'test_loss': 0.00019758767015731635}
Best loss: 0.00018579789416576386
Epoch 89:
Training summary: {'train_recon_loss': 0.0007339907478071776, 'train_loss': 0.0007339907478071776}
Evaluation summary: {'test_recon_loss': 0.0015411049917215703, 'test_loss': 0.0015411049917215703}
Best loss: 0.00018579789416576386
Epoch 90:
Training summary: {'train_recon_loss': 0.0005309449290456049, 'train_loss': 0.0005309449290456049}
Evaluation summary: {'test_recon_loss': 0.00027361817747244, 'test_loss': 0.00027361817747244}
Best loss: 0.00018579789416576386
Epoch 91:
Training summary: {'train_recon_loss': 0.00026934948411906737, 'train_loss': 0.00026934948411906737}
Evaluation summary: {'test_recon_loss': 0.0002038892647476075, 'test_loss': 0.0002038892647476075}
Best loss: 0.00018579789416576386
Epoch 92:
Training summary: {'train_recon_loss': 0.00025106009606818303, 'train_loss': 0.00025106009606818303}
Evaluation summary: {'test_recon_loss': 0.00020613409492517304, 'test_loss': 0.00020613409492517304}
Best loss: 0.00018579789416576386
Epoch 93:
Training summary: {'train_recon_loss': 0.00024628036100867367, 'train_loss': 0.00024628036100867367}
Evaluation summary: {'test_recon_loss': 0.00031687006113510075, 'test_loss': 0.00031687006113510075}
Best loss: 0.00018579789416576386
Epoch 94:
Training summary: {'train_recon_loss': 0.00024272333856819307, 'train_loss': 0.00024272333856819307}
Evaluation summary: {'test_recon_loss': 0.00020158664576390827, 'test_loss': 0.00020158664576390827}
Best loss: 0.00018579789416576386
Epoch 95:
Training summary: {'train_recon_loss': 0.0002435385783553837, 'train_loss': 0.0002435385783553837}
Evaluation summary: {'test_recon_loss': 0.00021045834085013253, 'test_loss': 0.00021045834085013253}
Best loss: 0.00018579789416576386
Epoch 96:
Training summary: {'train_recon_loss': 0.0006250509725730982, 'train_loss': 0.0006250509725730982}
Evaluation summary: {'test_recon_loss': 0.0007852466137205898, 'test_loss': 0.0007852466137205898}
Best loss: 0.00018579789416576386
Epoch 97:
Training summary: {'train_recon_loss': 0.0004323531277358448, 'train_loss': 0.0004323531277358448}
Evaluation summary: {'test_recon_loss': 0.00023601900552952082, 'test_loss': 0.00023601900552952082}
Best loss: 0.00018579789416576386
Epoch 98:
Training summary: {'train_recon_loss': 0.0002651292230477706, 'train_loss': 0.0002651292230477706}
Evaluation summary: {'test_recon_loss': 0.0002467140023743032, 'test_loss': 0.0002467140023743032}
Best loss: 0.00018579789416576386
Epoch 99:
Training summary: {'train_recon_loss': 0.00025997939990078943, 'train_loss': 0.00025997939990078943}
Evaluation summary: {'test_recon_loss': 0.0005296979951731053, 'test_loss': 0.0005296979951731053}
Best loss: 0.00018579789416576386
Epoch 100:
Training summary: {'train_recon_loss': 0.0002487888310054013, 'train_loss': 0.0002487888310054013}
Evaluation summary: {'test_recon_loss': 0.00030748702616006116, 'test_loss': 0.00030748702616006116}
Best loss: 0.00018579789416576386
Epoch 101:
Training summary: {'train_recon_loss': 0.0002445516589631627, 'train_loss': 0.0002445516589631627}
Evaluation summary: {'test_recon_loss': 0.00022264009009540772, 'test_loss': 0.00022264009009540772}
Best loss: 0.00018579789416576386
Epoch 102:
Training summary: {'train_recon_loss': 0.0008198226115694304, 'train_loss': 0.0008198226115694304}
Evaluation summary: {'test_recon_loss': 0.0006332489144149311, 'test_loss': 0.0006332489144149311}
Best loss: 0.00018579789416576386
Epoch 103:
Training summary: {'train_recon_loss': 0.0004083882544647125, 'train_loss': 0.0004083882544647125}
Evaluation summary: {'test_recon_loss': 0.00025666845643487415, 'test_loss': 0.00025666845643487415}
Best loss: 0.00018579789416576386
Epoch 104:
Training summary: {'train_recon_loss': 0.00028347410508447934, 'train_loss': 0.00028347410508447934}
Evaluation summary: {'test_recon_loss': 0.00023614930926118172, 'test_loss': 0.00023614930926118172}
Best loss: 0.00018579789416576386
Epoch 105:
Training summary: {'train_recon_loss': 0.0002548368113438758, 'train_loss': 0.0002548368113438758}
Evaluation summary: {'test_recon_loss': 0.00020354757588688323, 'test_loss': 0.00020354757588688323}
Best loss: 0.00018579789416576386
Epoch 106:
Training summary: {'train_recon_loss': 0.0002387529718294714, 'train_loss': 0.0002387529718294714}
Evaluation summary: {'test_recon_loss': 0.00048101320442668486, 'test_loss': 0.00048101320442668486}
Best loss: 0.00018579789416576386
Epoch 107:
Training summary: {'train_recon_loss': 0.0002970341616166202, 'train_loss': 0.0002970341616166202}
Evaluation summary: {'test_recon_loss': 0.2532964197801388, 'test_loss': 0.2532964197801388}
Best loss: 0.00018579789416576386
Epoch 108:
Training summary: {'train_recon_loss': 0.0009952438094360295, 'train_loss': 0.0009952438094360295}
Evaluation summary: {'test_recon_loss': 0.0005497929599984814, 'test_loss': 0.0005497929599984814}
Best loss: 0.00018579789416576386
Epoch 109:
Training summary: {'train_recon_loss': 0.0003376205498013274, 'train_loss': 0.0003376205498013274}
Evaluation summary: {'test_recon_loss': 0.00030923980448571464, 'test_loss': 0.00030923980448571464}
Best loss: 0.00018579789416576386
Epoch 110:
Training summary: {'train_recon_loss': 0.00026786083859155397, 'train_loss': 0.00026786083859155397}
Evaluation summary: {'test_recon_loss': 0.0003267712592441368, 'test_loss': 0.0003267712592441368}
Best loss: 0.00018579789416576386
Epoch 111:
Training summary: {'train_recon_loss': 0.00024891211177171423, 'train_loss': 0.00024891211177171423}
Evaluation summary: {'test_recon_loss': 0.0002162484358207299, 'test_loss': 0.0002162484358207299}
Best loss: 0.00018579789416576386
Epoch 112:
Training summary: {'train_recon_loss': 0.0002433849098477613, 'train_loss': 0.0002433849098477613}
Evaluation summary: {'test_recon_loss': 0.00019112395019223345, 'test_loss': 0.00019112395019223345}
Best loss: 0.00018579789416576386
Epoch 113:
Training summary: {'train_recon_loss': 0.0008513208412048626, 'train_loss': 0.0008513208412048626}
Evaluation summary: {'test_recon_loss': 0.0005051006978025854, 'test_loss': 0.0005051006978025854}
Best loss: 0.00018579789416576386
Epoch 114:
Training summary: {'train_recon_loss': 0.00032514773491052596, 'train_loss': 0.00032514773491052596}
Evaluation summary: {'test_recon_loss': 0.0002941967901695597, 'test_loss': 0.0002941967901695597}
Best loss: 0.00018579789416576386
Epoch 115:
Training summary: {'train_recon_loss': 0.0002564893022069354, 'train_loss': 0.0002564893022069354}
Evaluation summary: {'test_recon_loss': 0.000216417420583401, 'test_loss': 0.000216417420583401}
Best loss: 0.00018579789416576386
Epoch 116:
Training summary: {'train_recon_loss': 0.0002458272733217165, 'train_loss': 0.0002458272733217165}
Evaluation summary: {'test_recon_loss': 0.00019670382123279526, 'test_loss': 0.00019670382123279526}
Best loss: 0.00018579789416576386
Epoch 117:
Training summary: {'train_recon_loss': 0.0002512005496627812, 'train_loss': 0.0002512005496627812}
Evaluation summary: {'test_recon_loss': 0.00020419406442941335, 'test_loss': 0.00020419406442941335}
Best loss: 0.00018579789416576386
Epoch 118:
Training summary: {'train_recon_loss': 0.0008284558983823671, 'train_loss': 0.0008284558983823671}
Evaluation summary: {'test_recon_loss': 0.0011823896527332037, 'test_loss': 0.0011823896527332037}
Best loss: 0.00018579789416576386
Epoch 119:
Training summary: {'train_recon_loss': 0.0005049710251455098, 'train_loss': 0.0005049710251455098}
Evaluation summary: {'test_recon_loss': 0.00028492405902807007, 'test_loss': 0.00028492405902807007}
Best loss: 0.00018579789416576386
Epoch 120:
Training summary: {'train_recon_loss': 0.0009260021145021542, 'train_loss': 0.0009260021145021542}
Evaluation summary: {'test_recon_loss': 0.0005283489850530836, 'test_loss': 0.0005283489850530836}
Best loss: 0.00018579789416576386
Epoch 121:
Training summary: {'train_recon_loss': 0.00036729159725351954, 'train_loss': 0.00036729159725351954}
Evaluation summary: {'test_recon_loss': 0.0002968061092676956, 'test_loss': 0.0002968061092676956}
Best loss: 0.00018579789416576386
Epoch 122:
Training summary: {'train_recon_loss': 0.000285366217347846, 'train_loss': 0.000285366217347846}
Evaluation summary: {'test_recon_loss': 0.00027833903837590245, 'test_loss': 0.00027833903837590245}
Best loss: 0.00018579789416576386
Epoch 123:
Training summary: {'train_recon_loss': 0.00025975464811538716, 'train_loss': 0.00025975464811538716}
Evaluation summary: {'test_recon_loss': 0.0002880288367181102, 'test_loss': 0.0002880288367181102}
Best loss: 0.00018579789416576386
Epoch 124:
Training summary: {'train_recon_loss': 0.000508053144495589, 'train_loss': 0.000508053144495589}
Evaluation summary: {'test_recon_loss': 0.0010502577344923677, 'test_loss': 0.0010502577344923677}
Best loss: 0.00018579789416576386
Epoch 125:
Training summary: {'train_recon_loss': 0.0003945716961563396, 'train_loss': 0.0003945716961563396}
Evaluation summary: {'test_recon_loss': 0.00025767955395348196, 'test_loss': 0.00025767955395348196}
Best loss: 0.00018579789416576386
Epoch 126:
Training summary: {'train_recon_loss': 0.0002523587482424812, 'train_loss': 0.0002523587482424812}
Evaluation summary: {'test_recon_loss': 0.000217744037032507, 'test_loss': 0.000217744037032507}
Best loss: 0.00018579789416576386
Epoch 127:
Training summary: {'train_recon_loss': 0.000250448438114949, 'train_loss': 0.000250448438114949}
Evaluation summary: {'test_recon_loss': 0.00019953594408478906, 'test_loss': 0.00019953594408478906}
Best loss: 0.00018579789416576386
Epoch 128:
Training summary: {'train_recon_loss': 0.00025605236187531145, 'train_loss': 0.00025605236187531145}
Evaluation summary: {'test_recon_loss': 0.0002301195736274086, 'test_loss': 0.0002301195736274086}
Best loss: 0.00018579789416576386
Epoch 129:
Training summary: {'train_recon_loss': 0.00024021045682156227, 'train_loss': 0.00024021045682156227}
Evaluation summary: {'test_recon_loss': 0.00022692211173880856, 'test_loss': 0.00022692211173880856}
Best loss: 0.00018579789416576386
Epoch 130:
Training summary: {'train_recon_loss': 0.0007690945610896826, 'train_loss': 0.0007690945610896826}
Evaluation summary: {'test_recon_loss': 0.0003520693670459396, 'test_loss': 0.0003520693670459396}
Best loss: 0.00018579789416576386
Epoch 131:
Training summary: {'train_recon_loss': 0.00029784424210710966, 'train_loss': 0.00029784424210710966}
Evaluation summary: {'test_recon_loss': 0.0002303152012154279, 'test_loss': 0.0002303152012154279}
Best loss: 0.00018579789416576386
Epoch 132:
Training summary: {'train_recon_loss': 0.0002547912135602603, 'train_loss': 0.0002547912135602603}
Evaluation summary: {'test_recon_loss': 0.00020933931521106405, 'test_loss': 0.00020933931521106405}
Best loss: 0.00018579789416576386
Epoch 133:
Training summary: {'train_recon_loss': 0.0008672405820364191, 'train_loss': 0.0008672405820364191}
Evaluation summary: {'test_recon_loss': 0.0006144753890221161, 'test_loss': 0.0006144753890221161}
Best loss: 0.00018579789416576386
Epoch 134:
Training summary: {'train_recon_loss': 0.0004016931562150941, 'train_loss': 0.0004016931562150941}
Evaluation summary: {'test_recon_loss': 0.0002947261872120174, 'test_loss': 0.0002947261872120174}
Best loss: 0.00018579789416576386
Epoch 135:
Training summary: {'train_recon_loss': 0.0002772956735877382, 'train_loss': 0.0002772956735877382}
Evaluation summary: {'test_recon_loss': 0.00021295004362928538, 'test_loss': 0.00021295004362928538}
Best loss: 0.00018579789416576386
Epoch 136:
Training summary: {'train_recon_loss': 0.00025331301358261026, 'train_loss': 0.00025331301358261026}
Evaluation summary: {'test_recon_loss': 0.00020064165320421182, 'test_loss': 0.00020064165320421182}
Best loss: 0.00018579789416576386
Epoch 137:
Training summary: {'train_recon_loss': 0.0002534328117876564, 'train_loss': 0.0002534328117876564}
Evaluation summary: {'test_recon_loss': 0.000198715745905018, 'test_loss': 0.000198715745905018}
Best loss: 0.00018579789416576386
Epoch 138:
Training summary: {'train_recon_loss': 0.0007757575379404029, 'train_loss': 0.0007757575379404029}
Evaluation summary: {'test_recon_loss': 0.00031625768060579223, 'test_loss': 0.00031625768060579223}
Best loss: 0.00018579789416576386
Epoch 139:
Training summary: {'train_recon_loss': 0.0002761396537845468, 'train_loss': 0.0002761396537845468}
Evaluation summary: {'test_recon_loss': 0.00020092899228387568, 'test_loss': 0.00020092899228387568}
Best loss: 0.00018579789416576386
Epoch 140:
Training summary: {'train_recon_loss': 0.0002516446906728538, 'train_loss': 0.0002516446906728538}
Evaluation summary: {'test_recon_loss': 0.0002107822370431079, 'test_loss': 0.0002107822370431079}
Best loss: 0.00018579789416576386
Epoch 141:
Training summary: {'train_recon_loss': 0.00024685282270977746, 'train_loss': 0.00024685282270977746}
Evaluation summary: {'test_recon_loss': 0.0002538373199326676, 'test_loss': 0.0002538373199326676}
Best loss: 0.00018579789416576386
Epoch 142:
Training summary: {'train_recon_loss': 0.0002456199774327738, 'train_loss': 0.0002456199774327738}
Evaluation summary: {'test_recon_loss': 0.00018387439811499195, 'test_loss': 0.00018387439811499195}
Best loss: 0.00018387439811499195
Epoch 143:
Training summary: {'train_recon_loss': 0.0002483674014470946, 'train_loss': 0.0002483674014470946}
Evaluation summary: {'test_recon_loss': 0.00025404739040687174, 'test_loss': 0.00025404739040687174}
Best loss: 0.00018387439811499195
Epoch 144:
Training summary: {'train_recon_loss': 0.00023189258197418746, 'train_loss': 0.00023189258197418746}
Evaluation summary: {'test_recon_loss': 0.0002127554512386963, 'test_loss': 0.0002127554512386963}
Best loss: 0.00018387439811499195
Epoch 145:
Training summary: {'train_recon_loss': 0.0008207880710603342, 'train_loss': 0.0008207880710603342}
Evaluation summary: {'test_recon_loss': 0.0002831874039565106, 'test_loss': 0.0002831874039565106}
Best loss: 0.00018387439811499195
Epoch 146:
Training summary: {'train_recon_loss': 0.0002678998152794505, 'train_loss': 0.0002678998152794505}
Evaluation summary: {'test_recon_loss': 0.00023134222511404307, 'test_loss': 0.00023134222511404307}
Best loss: 0.00018387439811499195
Epoch 147:
Training summary: {'train_recon_loss': 0.00025827303249985377, 'train_loss': 0.00025827303249985377}
Evaluation summary: {'test_recon_loss': 0.0002215827901055417, 'test_loss': 0.0002215827901055417}
Best loss: 0.00018387439811499195
Epoch 148:
Training summary: {'train_recon_loss': 0.0002511048557540377, 'train_loss': 0.0002511048557540377}
Evaluation summary: {'test_recon_loss': 0.0001966374808468905, 'test_loss': 0.0001966374808468905}
Best loss: 0.00018387439811499195
Epoch 149:
Training summary: {'train_recon_loss': 0.00024044233094674586, 'train_loss': 0.00024044233094674586}
Evaluation summary: {'test_recon_loss': 0.00019271730878357368, 'test_loss': 0.00019271730878357368}
Best loss: 0.00018387439811499195
Epoch 150:
Training summary: {'train_recon_loss': 0.0007109365572242963, 'train_loss': 0.0007109365572242963}
Evaluation summary: {'test_recon_loss': 0.0006470901474773917, 'test_loss': 0.0006470901474773917}
Best loss: 0.00018387439811499195
Epoch 151:
Training summary: {'train_recon_loss': 0.000463086743337224, 'train_loss': 0.000463086743337224}
Evaluation summary: {'test_recon_loss': 0.0014999920206648497, 'test_loss': 0.0014999920206648497}
Best loss: 0.00018387439811499195
Epoch 152:
Training summary: {'train_recon_loss': 0.00027596093502900166, 'train_loss': 0.00027596093502900166}
Evaluation summary: {'test_recon_loss': 0.0002847378247306158, 'test_loss': 0.0002847378247306158}
Best loss: 0.00018387439811499195
Epoch 153:
Training summary: {'train_recon_loss': 0.00025896807328728823, 'train_loss': 0.00025896807328728823}
Evaluation summary: {'test_recon_loss': 0.00020526989121458344, 'test_loss': 0.00020526989121458344}
Best loss: 0.00018387439811499195
Epoch 154:
Training summary: {'train_recon_loss': 0.0002564339673151953, 'train_loss': 0.0002564339673151953}
Evaluation summary: {'test_recon_loss': 0.0001899000360732149, 'test_loss': 0.0001899000360732149}
Best loss: 0.00018387439811499195
Epoch 155:
Training summary: {'train_recon_loss': 0.00024365996924955423, 'train_loss': 0.00024365996924955423}
Evaluation summary: {'test_recon_loss': 0.00028521099468743625, 'test_loss': 0.00028521099468743625}
Best loss: 0.00018387439811499195
Epoch 156:
Training summary: {'train_recon_loss': 0.00024360212836889287, 'train_loss': 0.00024360212836889287}
Evaluation summary: {'test_recon_loss': 0.00023116754508060604, 'test_loss': 0.00023116754508060604}
Best loss: 0.00018387439811499195
Epoch 157:
Training summary: {'train_recon_loss': 0.0008248621407888474, 'train_loss': 0.0008248621407888474}
Evaluation summary: {'test_recon_loss': 0.00042819948518622446, 'test_loss': 0.00042819948518622446}
Best loss: 0.00018387439811499195
Epoch 158:
Training summary: {'train_recon_loss': 0.00029807949556751896, 'train_loss': 0.00029807949556751896}
Evaluation summary: {'test_recon_loss': 0.0002380758111862766, 'test_loss': 0.0002380758111862766}
Best loss: 0.00018387439811499195
Epoch 159:
Training summary: {'train_recon_loss': 0.00025051385442444114, 'train_loss': 0.00025051385442444114}
Evaluation summary: {'test_recon_loss': 0.00022989506833447844, 'test_loss': 0.00022989506833447844}
Best loss: 0.00018387439811499195
Epoch 160:
Training summary: {'train_recon_loss': 0.0002524747052303985, 'train_loss': 0.0002524747052303985}
Evaluation summary: {'test_recon_loss': 0.0001904786882124008, 'test_loss': 0.0001904786882124008}
Best loss: 0.00018387439811499195
Epoch 161:
Training summary: {'train_recon_loss': 0.0004049584870831382, 'train_loss': 0.0004049584870831382}
Evaluation summary: {'test_recon_loss': 0.0033879944272446165, 'test_loss': 0.0033879944272446165}
Best loss: 0.00018387439811499195
Epoch 162:
Training summary: {'train_recon_loss': 0.0006780925759041511, 'train_loss': 0.0006780925759041511}
Evaluation summary: {'test_recon_loss': 0.00039901468294202113, 'test_loss': 0.00039901468294202113}
Best loss: 0.00018387439811499195
Epoch 163:
Training summary: {'train_recon_loss': 0.0002611530084445148, 'train_loss': 0.0002611530084445148}
Evaluation summary: {'test_recon_loss': 0.0004080009026385093, 'test_loss': 0.0004080009026385093}
Best loss: 0.00018387439811499195
Epoch 164:
Training summary: {'train_recon_loss': 0.00025172374102138046, 'train_loss': 0.00025172374102138046}
Evaluation summary: {'test_recon_loss': 0.00020688068583741716, 'test_loss': 0.00020688068583741716}
Best loss: 0.00018387439811499195
Epoch 165:
Training summary: {'train_recon_loss': 0.0002489851524620625, 'train_loss': 0.0002489851524620625}
Evaluation summary: {'test_recon_loss': 0.00026560469237979327, 'test_loss': 0.00026560469237979327}
Best loss: 0.00018387439811499195
Epoch 166:
Training summary: {'train_recon_loss': 0.0008060722270928645, 'train_loss': 0.0008060722270928645}
Evaluation summary: {'test_recon_loss': 0.0005912504296478914, 'test_loss': 0.0005912504296478914}
Best loss: 0.00018387439811499195
Epoch 167:
Training summary: {'train_recon_loss': 0.0003764353327293939, 'train_loss': 0.0003764353327293939}
Evaluation summary: {'test_recon_loss': 0.0002301828879490805, 'test_loss': 0.0002301828879490805}
Best loss: 0.00018387439811499195
Epoch 168:
Training summary: {'train_recon_loss': 0.00025628581835416105, 'train_loss': 0.00025628581835416105}
Evaluation summary: {'test_recon_loss': 0.00019983999045204638, 'test_loss': 0.00019983999045204638}
Best loss: 0.00018387439811499195
Epoch 169:
Training summary: {'train_recon_loss': 0.0007324420775833144, 'train_loss': 0.0007324420775833144}
Evaluation summary: {'test_recon_loss': 0.0003105285057403716, 'test_loss': 0.0003105285057403716}
Best loss: 0.00018387439811499195
Epoch 170:
Training summary: {'train_recon_loss': 0.00029188421804354244, 'train_loss': 0.00029188421804354244}
Evaluation summary: {'test_recon_loss': 0.0002061932489828952, 'test_loss': 0.0002061932489828952}
Best loss: 0.00018387439811499195
Epoch 171:
Training summary: {'train_recon_loss': 0.0002528716876482519, 'train_loss': 0.0002528716876482519}
Evaluation summary: {'test_recon_loss': 0.0002073971546621648, 'test_loss': 0.0002073971546621648}
Best loss: 0.00018387439811499195
Epoch 172:
Training summary: {'train_recon_loss': 0.00024587649545778755, 'train_loss': 0.00024587649545778755}
Evaluation summary: {'test_recon_loss': 0.00022741517693901627, 'test_loss': 0.00022741517693901627}
Best loss: 0.00018387439811499195
Epoch 173:
Training summary: {'train_recon_loss': 0.0007299427576817634, 'train_loss': 0.0007299427576817634}
Evaluation summary: {'test_recon_loss': 0.00028916407616258493, 'test_loss': 0.00028916407616258493}
Best loss: 0.00018387439811499195
Epoch 174:
Training summary: {'train_recon_loss': 0.00027226641598937496, 'train_loss': 0.00027226641598937496}
Evaluation summary: {'test_recon_loss': 0.0002033453525078929, 'test_loss': 0.0002033453525078929}
Best loss: 0.00018387439811499195
Epoch 175:
Training summary: {'train_recon_loss': 0.0002527941270970387, 'train_loss': 0.0002527941270970387}
Evaluation summary: {'test_recon_loss': 0.0002046939934006459, 'test_loss': 0.0002046939934006459}
Best loss: 0.00018387439811499195
Epoch 176:
Training summary: {'train_recon_loss': 0.00024879306676968714, 'train_loss': 0.00024879306676968714}
Evaluation summary: {'test_recon_loss': 0.00019251336027932556, 'test_loss': 0.00019251336027932556}
Best loss: 0.00018387439811499195
Epoch 177:
Training summary: {'train_recon_loss': 0.00024782748824103104, 'train_loss': 0.00024782748824103104}
Evaluation summary: {'test_recon_loss': 0.0002139345825089487, 'test_loss': 0.0002139345825089487}
Best loss: 0.00018387439811499195
Epoch 178:
generate_recon.py --datadir . --metafile /mountb/single_cell_flist/ch1_all.csv --save-dir /mountb/autoencoder/ch1 --latent-dims 2048 --ae-features --pretrained-file /mountb/autoencoder/ch1/models/best.pth
Namespace(ae_features=True, batch_size=128, datadir='.', latent_dims=2048, metafile='/mountb/single_cell_flist/ch1_all.csv', pca_features=False, pretrained_file='/mountb/autoencoder/ch1/models/best.pth', save_dir='/mountb/autoencoder/ch1')
Dataset length is 9068498
AE46(
  (encoder): Sequential(
    (0): Conv2d(1, 46, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(46, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(92, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(184, 368, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (12): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (fc1): Linear(in_features=1472, out_features=2048, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): ConvTranspose2d(368, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): ConvTranspose2d(184, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
    (9): ConvTranspose2d(92, 46, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace=True)
    (12): ConvTranspose2d(46, 1, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Sigmoid()
  )
  (d1): Linear(in_features=2048, out_features=1472, bias=True)
  (mseloss): MSELoss()
)
Training summary: {'train_recon_loss': 0.00024318440908618772, 'train_loss': 0.00024318440908618772}
Evaluation summary: {'test_recon_loss': 0.000194722307219129, 'test_loss': 0.000194722307219129}
Best loss: 0.00018387439811499195
Epoch 179:
Training summary: {'train_recon_loss': 0.00024091625551083507, 'train_loss': 0.00024091625551083507}
Evaluation summary: {'test_recon_loss': 0.00017844755716281733, 'test_loss': 0.00017844755716281733}
Best loss: 0.00017844755716281733
Epoch 180:
Training summary: {'train_recon_loss': 0.0009063577061992502, 'train_loss': 0.0009063577061992502}
Evaluation summary: {'test_recon_loss': 0.0005253301771015568, 'test_loss': 0.0005253301771015568}
Best loss: 0.00017844755716281733
Epoch 181:
