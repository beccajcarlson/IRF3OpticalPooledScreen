run_train.py --max-value 16945 --datadir . --train-metafile /mountb/single_cell_flist/train_ch0_small.csv --val-metafile /mountb/single_cell_flist/val_ch0_small.csv --save-dir /mountb/autoencoder/ch0 --model-type AE46 --dataset-type 46 --latent-dims 2048
Namespace(batch_size=128, datadir='.', dataset_type='46', debug_mode=False, latent_dims=2048, learning_rate=0.001, max_epochs=2000, max_value=16945, model_type='AE46', num_workers=8, optimizer='adam', save_dir='/mountb/autoencoder/ch0', save_freq=50, seed=42, train_metafile='/mountb/single_cell_flist/train_ch0_small.csv', val_metafile='/mountb/single_cell_flist/val_ch0_small.csv', weight_decay=1e-05)
AE46(
  (encoder): Sequential(
    (0): Conv2d(1, 46, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(46, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(92, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(184, 368, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (12): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (fc1): Linear(in_features=1472, out_features=2048, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): ConvTranspose2d(368, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): ConvTranspose2d(184, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
    (9): ConvTranspose2d(92, 46, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace=True)
    (12): ConvTranspose2d(46, 1, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Sigmoid()
  )
  (d1): Linear(in_features=2048, out_features=1472, bias=True)
  (mseloss): MSELoss()
)
Epoch 0:
Training summary: {'train_recon_loss': 0.012483889500317641, 'train_loss': 0.012483889500317641}
Evaluation summary: {'test_recon_loss': 0.004071259583081225, 'test_loss': 0.004071259583081225}
Best loss: 0.004071259583081225
Epoch 1:
Training summary: {'train_recon_loss': 0.003048952865536083, 'train_loss': 0.003048952865536083}
Evaluation summary: {'test_recon_loss': 0.0020622888286066826, 'test_loss': 0.0020622888286066826}
Best loss: 0.0020622888286066826
Epoch 2:
Training summary: {'train_recon_loss': 0.0020495306121682353, 'train_loss': 0.0020495306121682353}
Evaluation summary: {'test_recon_loss': 0.002801863451729608, 'test_loss': 0.002801863451729608}
Best loss: 0.0020622888286066826
Epoch 3:
Training summary: {'train_recon_loss': 0.0015518401207257552, 'train_loss': 0.0015518401207257552}
Evaluation summary: {'test_recon_loss': 0.0014141806442045193, 'test_loss': 0.0014141806442045193}
Best loss: 0.0014141806442045193
Epoch 4:
Training summary: {'train_recon_loss': 0.0013341356195137554, 'train_loss': 0.0013341356195137554}
Evaluation summary: {'test_recon_loss': 0.0011763230774517427, 'test_loss': 0.0011763230774517427}
Best loss: 0.0011763230774517427
Epoch 5:
Training summary: {'train_recon_loss': 0.001134035197171373, 'train_loss': 0.001134035197171373}
Evaluation summary: {'test_recon_loss': 0.0010507415142837176, 'test_loss': 0.0010507415142837176}
Best loss: 0.0010507415142837176
Epoch 6:
Training summary: {'train_recon_loss': 0.0010609146290460362, 'train_loss': 0.0010609146290460362}
Evaluation summary: {'test_recon_loss': 0.001029687285422098, 'test_loss': 0.001029687285422098}
Best loss: 0.001029687285422098
Epoch 7:
Training summary: {'train_recon_loss': 0.0010273713307321903, 'train_loss': 0.0010273713307321903}
Evaluation summary: {'test_recon_loss': 0.0009720213020870174, 'test_loss': 0.0009720213020870174}
Best loss: 0.0009720213020870174
Epoch 8:
Training summary: {'train_recon_loss': 0.0009722920691441466, 'train_loss': 0.0009722920691441466}
Evaluation summary: {'test_recon_loss': 0.0009167754237789929, 'test_loss': 0.0009167754237789929}
Best loss: 0.0009167754237789929
Epoch 9:
Training summary: {'train_recon_loss': 0.0009476659375624634, 'train_loss': 0.0009476659375624634}
Evaluation summary: {'test_recon_loss': 0.0009649106949402088, 'test_loss': 0.0009649106949402088}
Best loss: 0.0009167754237789929
Epoch 10:
Training summary: {'train_recon_loss': 0.0009136011365549347, 'train_loss': 0.0009136011365549347}
Evaluation summary: {'test_recon_loss': 0.0008714457983157756, 'test_loss': 0.0008714457983157756}
Best loss: 0.0008714457983157756
Epoch 11:
Training summary: {'train_recon_loss': 0.0008860893946349984, 'train_loss': 0.0008860893946349984}
Evaluation summary: {'test_recon_loss': 0.0009341651821813663, 'test_loss': 0.0009341651821813663}
Best loss: 0.0008714457983157756
Epoch 12:
Training summary: {'train_recon_loss': 0.0008833727158866034, 'train_loss': 0.0008833727158866034}
Evaluation summary: {'test_recon_loss': 0.0008269881372527037, 'test_loss': 0.0008269881372527037}
Best loss: 0.0008269881372527037
Epoch 13:
Training summary: {'train_recon_loss': 0.0008504533565968491, 'train_loss': 0.0008504533565968491}
Evaluation summary: {'test_recon_loss': 0.0007469043933746198, 'test_loss': 0.0007469043933746198}
Best loss: 0.0007469043933746198
Epoch 14:
Training summary: {'train_recon_loss': 0.0008317443268421326, 'train_loss': 0.0008317443268421326}
Evaluation summary: {'test_recon_loss': 0.0007558706021617773, 'test_loss': 0.0007558706021617773}
Best loss: 0.0007469043933746198
Epoch 15:
Training summary: {'train_recon_loss': 0.0008125311237193852, 'train_loss': 0.0008125311237193852}
Evaluation summary: {'test_recon_loss': 0.000723002477937962, 'test_loss': 0.000723002477937962}
Best loss: 0.000723002477937962
Epoch 16:
Training summary: {'train_recon_loss': 0.0033466931288097675, 'train_loss': 0.0033466931288097675}
Evaluation summary: {'test_recon_loss': 0.0045040709747268225, 'test_loss': 0.0045040709747268225}
Best loss: 0.000723002477937962
Epoch 17:
Training summary: {'train_recon_loss': 0.0018551805334917682, 'train_loss': 0.0018551805334917682}
Evaluation summary: {'test_recon_loss': 0.0011144952350452446, 'test_loss': 0.0011144952350452446}
Best loss: 0.000723002477937962
Epoch 18:
Training summary: {'train_recon_loss': 0.0009766879089196387, 'train_loss': 0.0009766879089196387}
Evaluation summary: {'test_recon_loss': 0.0008733167739514645, 'test_loss': 0.0008733167739514645}
Best loss: 0.000723002477937962
Epoch 19:
Training summary: {'train_recon_loss': 0.0008756511478788511, 'train_loss': 0.0008756511478788511}
Evaluation summary: {'test_recon_loss': 0.0007596202215840201, 'test_loss': 0.0007596202215840201}
Best loss: 0.000723002477937962
Epoch 20:
Training summary: {'train_recon_loss': 0.0008464688772513357, 'train_loss': 0.0008464688772513357}
Evaluation summary: {'test_recon_loss': 0.0007905145358558594, 'test_loss': 0.0007905145358558594}
Best loss: 0.000723002477937962
Epoch 21:
Training summary: {'train_recon_loss': 0.0008111935042670858, 'train_loss': 0.0008111935042670858}
Evaluation summary: {'test_recon_loss': 0.0007374606578688991, 'test_loss': 0.0007374606578688991}
Best loss: 0.000723002477937962
Epoch 22:
Training summary: {'train_recon_loss': 0.000788044392389604, 'train_loss': 0.000788044392389604}
Evaluation summary: {'test_recon_loss': 0.0007112958907912164, 'test_loss': 0.0007112958907912164}
Best loss: 0.0007112958907912164
Epoch 23:
Training summary: {'train_recon_loss': 0.0007658951417847407, 'train_loss': 0.0007658951417847407}
Evaluation summary: {'test_recon_loss': 0.0006885791933081585, 'test_loss': 0.0006885791933081585}
Best loss: 0.0006885791933081585
Epoch 24:
Training summary: {'train_recon_loss': 0.0007676711976906616, 'train_loss': 0.0007676711976906616}
Evaluation summary: {'test_recon_loss': 0.0006830401617150237, 'test_loss': 0.0006830401617150237}
Best loss: 0.0006830401617150237
Epoch 25:
Training summary: {'train_recon_loss': 0.003938852184408512, 'train_loss': 0.003938852184408512}
Evaluation summary: {'test_recon_loss': 0.003500754607422566, 'test_loss': 0.003500754607422566}
Best loss: 0.0006830401617150237
Epoch 26:
Training summary: {'train_recon_loss': 0.0018690750817356883, 'train_loss': 0.0018690750817356883}
Evaluation summary: {'test_recon_loss': 0.001157668283151539, 'test_loss': 0.001157668283151539}
Best loss: 0.0006830401617150237
Epoch 27:
Training summary: {'train_recon_loss': 0.0010063000388037043, 'train_loss': 0.0010063000388037043}
Evaluation summary: {'test_recon_loss': 0.0009120062155240173, 'test_loss': 0.0009120062155240173}
Best loss: 0.0006830401617150237
Epoch 28:
Training summary: {'train_recon_loss': 0.0008738674237820664, 'train_loss': 0.0008738674237820664}
Evaluation summary: {'test_recon_loss': 0.0007659590294933907, 'test_loss': 0.0007659590294933907}
Best loss: 0.0006830401617150237
Epoch 29:
Training summary: {'train_recon_loss': 0.0008216869888593553, 'train_loss': 0.0008216869888593553}
Evaluation summary: {'test_recon_loss': 0.0007372337934703724, 'test_loss': 0.0007372337934703724}
Best loss: 0.0006830401617150237
Epoch 30:
Training summary: {'train_recon_loss': 0.0007848354926918618, 'train_loss': 0.0007848354926918618}
Evaluation summary: {'test_recon_loss': 0.0007115370729071527, 'test_loss': 0.0007115370729071527}
Best loss: 0.0006830401617150237
Epoch 31:
Training summary: {'train_recon_loss': 0.0007673466458625419, 'train_loss': 0.0007673466458625419}
Evaluation summary: {'test_recon_loss': 0.0007000771580105972, 'test_loss': 0.0007000771580105972}
Best loss: 0.0006830401617150237
Epoch 32:
Training summary: {'train_recon_loss': 0.0007463701506632352, 'train_loss': 0.0007463701506632352}
Evaluation summary: {'test_recon_loss': 0.000722124754628396, 'test_loss': 0.000722124754628396}
Best loss: 0.0006830401617150237
Epoch 33:
Training summary: {'train_recon_loss': 0.0026523173191665282, 'train_loss': 0.0026523173191665282}
Evaluation summary: {'test_recon_loss': 0.007972400033743901, 'test_loss': 0.007972400033743901}
Best loss: 0.0006830401617150237
Epoch 34:
Training summary: {'train_recon_loss': 0.002240798080277504, 'train_loss': 0.002240798080277504}
Evaluation summary: {'test_recon_loss': 0.0011943101617022125, 'test_loss': 0.0011943101617022125}
Best loss: 0.0006830401617150237
Epoch 35:
Training summary: {'train_recon_loss': 0.0009775433545173623, 'train_loss': 0.0009775433545173623}
Evaluation summary: {'test_recon_loss': 0.0008799026239384379, 'test_loss': 0.0008799026239384379}
Best loss: 0.0006830401617150237
Epoch 36:
Training summary: {'train_recon_loss': 0.0008462401088030981, 'train_loss': 0.0008462401088030981}
Evaluation summary: {'test_recon_loss': 0.000754165072692545, 'test_loss': 0.000754165072692545}
Best loss: 0.0006830401617150237
Epoch 37:
Training summary: {'train_recon_loss': 0.0008011859931732942, 'train_loss': 0.0008011859931732942}
Evaluation summary: {'test_recon_loss': 0.0007492992265236783, 'test_loss': 0.0007492992265236783}
Best loss: 0.0006830401617150237
Epoch 38:
Training summary: {'train_recon_loss': 0.0007719762192203172, 'train_loss': 0.0007719762192203172}
Evaluation summary: {'test_recon_loss': 0.000740630231582824, 'test_loss': 0.000740630231582824}
Best loss: 0.0006830401617150237
Epoch 39:
Training summary: {'train_recon_loss': 0.0007568625906028193, 'train_loss': 0.0007568625906028193}
Evaluation summary: {'test_recon_loss': 0.0006717467344485762, 'test_loss': 0.0006717467344485762}
Best loss: 0.0006717467344485762
Epoch 40:
Training summary: {'train_recon_loss': 0.0007472107797374048, 'train_loss': 0.0007472107797374048}
Evaluation summary: {'test_recon_loss': 0.0007321289066639318, 'test_loss': 0.0007321289066639318}
Best loss: 0.0006717467344485762
Epoch 41:
Training summary: {'train_recon_loss': 0.0007389828952707265, 'train_loss': 0.0007389828952707265}
Evaluation summary: {'test_recon_loss': 0.0006979124089874472, 'test_loss': 0.0006979124089874472}
Best loss: 0.0006717467344485762
Epoch 42:
Training summary: {'train_recon_loss': 0.0007429086250893106, 'train_loss': 0.0007429086250893106}
Evaluation summary: {'test_recon_loss': 0.0007630892546370735, 'test_loss': 0.0007630892546370735}
Best loss: 0.0006717467344485762
Epoch 43:
Training summary: {'train_recon_loss': 0.004159393789643233, 'train_loss': 0.004159393789643233}
Evaluation summary: {'test_recon_loss': 0.0019500000617895792, 'test_loss': 0.0019500000617895792}
Best loss: 0.0006717467344485762
Epoch 44:
Training summary: {'train_recon_loss': 0.001297405825281194, 'train_loss': 0.001297405825281194}
Evaluation summary: {'test_recon_loss': 0.000931625024038212, 'test_loss': 0.000931625024038212}
Best loss: 0.0006717467344485762
Epoch 45:
Training summary: {'train_recon_loss': 0.000930543934437693, 'train_loss': 0.000930543934437693}
Evaluation summary: {'test_recon_loss': 0.0008460988398749591, 'test_loss': 0.0008460988398749591}
Best loss: 0.0006717467344485762
Epoch 46:
Training summary: {'train_recon_loss': 0.0008278267691323249, 'train_loss': 0.0008278267691323249}
Evaluation summary: {'test_recon_loss': 0.0007729673178229212, 'test_loss': 0.0007729673178229212}
Best loss: 0.0006717467344485762
Epoch 47:
Training summary: {'train_recon_loss': 0.0007840954627045315, 'train_loss': 0.0007840954627045315}
Evaluation summary: {'test_recon_loss': 0.0009072960822905352, 'test_loss': 0.0009072960822905352}
Best loss: 0.0006717467344485762
Epoch 48:
Training summary: {'train_recon_loss': 0.0007567491929265643, 'train_loss': 0.0007567491929265643}
Evaluation summary: {'test_recon_loss': 0.000717100205851333, 'test_loss': 0.000717100205851333}
Best loss: 0.0006717467344485762
Epoch 49:
Training summary: {'train_recon_loss': 0.0007442545661803126, 'train_loss': 0.0007442545661803126}
Evaluation summary: {'test_recon_loss': 0.0006434379612929469, 'test_loss': 0.0006434379612929469}
Best loss: 0.0006434379612929469
Epoch 50:
Training summary: {'train_recon_loss': 0.0007351260706732973, 'train_loss': 0.0007351260706732973}
Evaluation summary: {'test_recon_loss': 0.0007285863580572447, 'test_loss': 0.0007285863580572447}
Best loss: 0.0006434379612929469
Epoch 51:
Training summary: {'train_recon_loss': 0.0009030022901316695, 'train_loss': 0.0009030022901316695}
Evaluation summary: {'test_recon_loss': 0.2781200145106863, 'test_loss': 0.2781200145106863}
Best loss: 0.0006434379612929469
Epoch 52:
Training summary: {'train_recon_loss': 0.005072662736619938, 'train_loss': 0.005072662736619938}
Evaluation summary: {'test_recon_loss': 0.0017973340487555606, 'test_loss': 0.0017973340487555606}
Best loss: 0.0006434379612929469
Epoch 53:
Training summary: {'train_recon_loss': 0.0013558292176694586, 'train_loss': 0.0013558292176694586}
Evaluation summary: {'test_recon_loss': 0.00142035020665314, 'test_loss': 0.00142035020665314}
Best loss: 0.0006434379612929469
Epoch 54:
Training summary: {'train_recon_loss': 0.0009752505509488873, 'train_loss': 0.0009752505509488873}
Evaluation summary: {'test_recon_loss': 0.0009239188187264027, 'test_loss': 0.0009239188187264027}
Best loss: 0.0006434379612929469
Epoch 55:
Training summary: {'train_recon_loss': 0.0008636578733830425, 'train_loss': 0.0008636578733830425}
Evaluation summary: {'test_recon_loss': 0.000755900538541187, 'test_loss': 0.000755900538541187}
Best loss: 0.0006434379612929469
Epoch 56:
Training summary: {'train_recon_loss': 0.0008087848349558294, 'train_loss': 0.0008087848349558294}
Evaluation summary: {'test_recon_loss': 0.0009146295489677928, 'test_loss': 0.0009146295489677928}
Best loss: 0.0006434379612929469
Epoch 57:
Training summary: {'train_recon_loss': 0.004353290211693991, 'train_loss': 0.004353290211693991}
Evaluation summary: {'test_recon_loss': 0.0014720980712389926, 'test_loss': 0.0014720980712389926}
Best loss: 0.0006434379612929469
Epoch 58:
Training summary: {'train_recon_loss': 0.0010911279533621155, 'train_loss': 0.0010911279533621155}
Evaluation summary: {'test_recon_loss': 0.0008680593968767688, 'test_loss': 0.0008680593968767688}
Best loss: 0.0006434379612929469
Epoch 59:
Training summary: {'train_recon_loss': 0.0008660705268338592, 'train_loss': 0.0008660705268338592}
Evaluation summary: {'test_recon_loss': 0.0007863978387275676, 'test_loss': 0.0007863978387275676}
Best loss: 0.0006434379612929469
Epoch 60:
Training summary: {'train_recon_loss': 0.0008139104445385917, 'train_loss': 0.0008139104445385917}
Evaluation summary: {'test_recon_loss': 0.0007027406917985641, 'test_loss': 0.0007027406917985641}
Best loss: 0.0006434379612929469
Epoch 61:
Training summary: {'train_recon_loss': 0.0007813706190461894, 'train_loss': 0.0007813706190461894}
Evaluation summary: {'test_recon_loss': 0.0007262331153875237, 'test_loss': 0.0007262331153875237}
Best loss: 0.0006434379612929469
Epoch 62:
Training summary: {'train_recon_loss': 0.0007661018931338167, 'train_loss': 0.0007661018931338167}
Evaluation summary: {'test_recon_loss': 0.0008624052970245041, 'test_loss': 0.0008624052970245041}
Best loss: 0.0006434379612929469
Epoch 63:
Training summary: {'train_recon_loss': 0.003842343017314942, 'train_loss': 0.003842343017314942}
Evaluation summary: {'test_recon_loss': 0.0030135560761173873, 'test_loss': 0.0030135560761173873}
Best loss: 0.0006434379612929469
Epoch 64:
Training summary: {'train_recon_loss': 0.0014243179008935653, 'train_loss': 0.0014243179008935653}
Evaluation summary: {'test_recon_loss': 0.0009994839707151164, 'test_loss': 0.0009994839707151164}
Best loss: 0.0006434379612929469
Epoch 65:
Training summary: {'train_recon_loss': 0.0009093161163499492, 'train_loss': 0.0009093161163499492}
Evaluation summary: {'test_recon_loss': 0.0008044266376264441, 'test_loss': 0.0008044266376264441}
Best loss: 0.0006434379612929469
Epoch 66:
Training summary: {'train_recon_loss': 0.000827368884429651, 'train_loss': 0.000827368884429651}
Evaluation summary: {'test_recon_loss': 0.0007614129426824779, 'test_loss': 0.0007614129426824779}
Best loss: 0.0006434379612929469
Epoch 67:
Training summary: {'train_recon_loss': 0.0007794132855615508, 'train_loss': 0.0007794132855615508}
Evaluation summary: {'test_recon_loss': 0.0007631605074862334, 'test_loss': 0.0007631605074862334}
Best loss: 0.0006434379612929469
Epoch 68:
Training summary: {'train_recon_loss': 0.000755743993209286, 'train_loss': 0.000755743993209286}
Evaluation summary: {'test_recon_loss': 0.0007523651685145518, 'test_loss': 0.0007523651685145518}
Best loss: 0.0006434379612929469
Epoch 69:
Training summary: {'train_recon_loss': 0.0007462433592602277, 'train_loss': 0.0007462433592602277}
Evaluation summary: {'test_recon_loss': 0.0006669523730833646, 'test_loss': 0.0006669523730833646}
Best loss: 0.0006434379612929469
Epoch 70:
Training summary: {'train_recon_loss': 0.0007498362364885881, 'train_loss': 0.0007498362364885881}
Evaluation summary: {'test_recon_loss': 0.0006671137914831581, 'test_loss': 0.0006671137914831581}
Best loss: 0.0006434379612929469
Epoch 71:
Training summary: {'train_recon_loss': 0.0007358485646257941, 'train_loss': 0.0007358485646257941}
Evaluation summary: {'test_recon_loss': 0.0007002230525231838, 'test_loss': 0.0007002230525231838}
Best loss: 0.0006434379612929469
Epoch 72:
Training summary: {'train_recon_loss': 0.002600944957546988, 'train_loss': 0.002600944957546988}
Evaluation summary: {'test_recon_loss': 0.0092550148657418, 'test_loss': 0.0092550148657418}
Best loss: 0.0006434379612929469
Epoch 73:
Training summary: {'train_recon_loss': 0.0031487685761927855, 'train_loss': 0.0031487685761927855}
Evaluation summary: {'test_recon_loss': 0.002123208594813844, 'test_loss': 0.002123208594813844}
Best loss: 0.0006434379612929469
Epoch 74:
Training summary: {'train_recon_loss': 0.0011164980857014365, 'train_loss': 0.0011164980857014365}
Evaluation summary: {'test_recon_loss': 0.0008531217906619611, 'test_loss': 0.0008531217906619611}
Best loss: 0.0006434379612929469
Epoch 75:
Training summary: {'train_recon_loss': 0.000874120234153908, 'train_loss': 0.000874120234153908}
Evaluation summary: {'test_recon_loss': 0.0008025883601290287, 'test_loss': 0.0008025883601290287}
Best loss: 0.0006434379612929469
Epoch 76:
Training summary: {'train_recon_loss': 0.000802331165654927, 'train_loss': 0.000802331165654927}
Evaluation summary: {'test_recon_loss': 0.0007849053729693143, 'test_loss': 0.0007849053729693143}
Best loss: 0.0006434379612929469
Epoch 77:
Training summary: {'train_recon_loss': 0.0007726977144897825, 'train_loss': 0.0007726977144897825}
Evaluation summary: {'test_recon_loss': 0.0007051826550266537, 'test_loss': 0.0007051826550266537}
Best loss: 0.0006434379612929469
Epoch 78:
Training summary: {'train_recon_loss': 0.0007534886231315205, 'train_loss': 0.0007534886231315205}
Evaluation summary: {'test_recon_loss': 0.0009241850913866395, 'test_loss': 0.0009241850913866395}
Best loss: 0.0006434379612929469
Epoch 79:
Training summary: {'train_recon_loss': 0.0007356375727560634, 'train_loss': 0.0007356375727560634}
Evaluation summary: {'test_recon_loss': 0.0006883259467791527, 'test_loss': 0.0006883259467791527}
Best loss: 0.0006434379612929469
Epoch 80:
Training summary: {'train_recon_loss': 0.0024642974354019023, 'train_loss': 0.0024642974354019023}
Evaluation summary: {'test_recon_loss': 0.0014656904007976188, 'test_loss': 0.0014656904007976188}
Best loss: 0.0006434379612929469
Epoch 81:
Training summary: {'train_recon_loss': 0.0009748793297402844, 'train_loss': 0.0009748793297402844}
Evaluation summary: {'test_recon_loss': 0.0008357829212402557, 'test_loss': 0.0008357829212402557}
Best loss: 0.0006434379612929469
Epoch 82:
Training summary: {'train_recon_loss': 0.0008055365327852632, 'train_loss': 0.0008055365327852632}
Evaluation summary: {'test_recon_loss': 0.0007304496780809299, 'test_loss': 0.0007304496780809299}
Best loss: 0.0006434379612929469
Epoch 83:
Training summary: {'train_recon_loss': 0.0007554370554718569, 'train_loss': 0.0007554370554718569}
Evaluation summary: {'test_recon_loss': 0.0007888227333590208, 'test_loss': 0.0007888227333590208}
Best loss: 0.0006434379612929469
Epoch 84:
Training summary: {'train_recon_loss': 0.0038168333516482487, 'train_loss': 0.0038168333516482487}
Evaluation summary: {'test_recon_loss': 0.0012437109818243853, 'test_loss': 0.0012437109818243853}
Best loss: 0.0006434379612929469
Epoch 85:
Training summary: {'train_recon_loss': 0.0009657198271357081, 'train_loss': 0.0009657198271357081}
Evaluation summary: {'test_recon_loss': 0.0009651174269401291, 'test_loss': 0.0009651174269401291}
Best loss: 0.0006434379612929469
Epoch 86:
Training summary: {'train_recon_loss': 0.0008047029039536206, 'train_loss': 0.0008047029039536206}
Evaluation summary: {'test_recon_loss': 0.0007185960252046394, 'test_loss': 0.0007185960252046394}
Best loss: 0.0006434379612929469
Epoch 87:
Training summary: {'train_recon_loss': 0.000761544136511484, 'train_loss': 0.000761544136511484}
Evaluation summary: {'test_recon_loss': 0.0007365752468860995, 'test_loss': 0.0007365752468860995}
Best loss: 0.0006434379612929469
Epoch 88:
Training summary: {'train_recon_loss': 0.0007540557350241003, 'train_loss': 0.0007540557350241003}
Evaluation summary: {'test_recon_loss': 0.0007030169179206776, 'test_loss': 0.0007030169179206776}
Best loss: 0.0006434379612929469
Epoch 89:
Training summary: {'train_recon_loss': 0.0007426449103452026, 'train_loss': 0.0007426449103452026}
Evaluation summary: {'test_recon_loss': 0.0007901033471603311, 'test_loss': 0.0007901033471603311}
Best loss: 0.0006434379612929469
Epoch 90:
Training summary: {'train_recon_loss': 0.0007352847035179503, 'train_loss': 0.0007352847035179503}
Evaluation summary: {'test_recon_loss': 0.0006727523087431093, 'test_loss': 0.0006727523087431093}
Best loss: 0.0006434379612929469
Epoch 91:
Training summary: {'train_recon_loss': 0.002731892863282762, 'train_loss': 0.002731892863282762}
Evaluation summary: {'test_recon_loss': 0.009180520649364908, 'test_loss': 0.009180520649364908}
Best loss: 0.0006434379612929469
Epoch 92:
Training summary: {'train_recon_loss': 0.003028618141164674, 'train_loss': 0.003028618141164674}
Evaluation summary: {'test_recon_loss': 0.0013256091016971751, 'test_loss': 0.0013256091016971751}
Best loss: 0.0006434379612929469
Epoch 93:
Training summary: {'train_recon_loss': 0.000995751397002178, 'train_loss': 0.000995751397002178}
Evaluation summary: {'test_recon_loss': 0.000816928684617641, 'test_loss': 0.000816928684617641}
Best loss: 0.0006434379612929469
Epoch 94:
Training summary: {'train_recon_loss': 0.0008055276399710328, 'train_loss': 0.0008055276399710328}
Evaluation summary: {'test_recon_loss': 0.0008589601382076735, 'test_loss': 0.0008589601382076735}
Best loss: 0.0006434379612929469
Epoch 95:
Training summary: {'train_recon_loss': 0.0007658265259564445, 'train_loss': 0.0007658265259564445}
Evaluation summary: {'test_recon_loss': 0.0006907850506854839, 'test_loss': 0.0006907850506854839}
Best loss: 0.0006434379612929469
Epoch 96:
Training summary: {'train_recon_loss': 0.0007466048235896415, 'train_loss': 0.0007466048235896415}
Evaluation summary: {'test_recon_loss': 0.0009056693399055175, 'test_loss': 0.0009056693399055175}
Best loss: 0.0006434379612929469
Epoch 97:
Training summary: {'train_recon_loss': 0.0007392325219097664, 'train_loss': 0.0007392325219097664}
Evaluation summary: {'test_recon_loss': 0.0007052425796354464, 'test_loss': 0.0007052425796354464}
Best loss: 0.0006434379612929469
Epoch 98:
Training summary: {'train_recon_loss': 0.0007329655775402148, 'train_loss': 0.0007329655775402148}
Evaluation summary: {'test_recon_loss': 0.0007387650452778157, 'test_loss': 0.0007387650452778157}
Best loss: 0.0006434379612929469
Epoch 99:
Training summary: {'train_recon_loss': 0.0033269843498784546, 'train_loss': 0.0033269843498784546}
Evaluation summary: {'test_recon_loss': 0.002028162771498148, 'test_loss': 0.002028162771498148}
Best loss: 0.0006434379612929469
Epoch 100:
Training summary: {'train_recon_loss': 0.0011918883579009787, 'train_loss': 0.0011918883579009787}
Evaluation summary: {'test_recon_loss': 0.0008888738648464014, 'test_loss': 0.0008888738648464014}
Best loss: 0.0006434379612929469
Epoch 101:
Training summary: {'train_recon_loss': 0.0008218748603582174, 'train_loss': 0.0008218748603582174}
Evaluation summary: {'test_recon_loss': 0.0007808631068535015, 'test_loss': 0.0007808631068535015}
Best loss: 0.0006434379612929469
Epoch 102:
Training summary: {'train_recon_loss': 0.0007642230035222138, 'train_loss': 0.0007642230035222138}
Evaluation summary: {'test_recon_loss': 0.0007012688721342817, 'test_loss': 0.0007012688721342817}
Best loss: 0.0006434379612929469
Epoch 103:
Training summary: {'train_recon_loss': 0.0007448559212490133, 'train_loss': 0.0007448559212490133}
Evaluation summary: {'test_recon_loss': 0.0006904348153534436, 'test_loss': 0.0006904348153534436}
Best loss: 0.0006434379612929469
Epoch 104:
Training summary: {'train_recon_loss': 0.0007295212900725129, 'train_loss': 0.0007295212900725129}
Evaluation summary: {'test_recon_loss': 0.0007377325250308776, 'test_loss': 0.0007377325250308776}
Best loss: 0.0006434379612929469
Epoch 105:
Training summary: {'train_recon_loss': 0.0007267049220662118, 'train_loss': 0.0007267049220662118}
Evaluation summary: {'test_recon_loss': 0.000747516404245004, 'test_loss': 0.000747516404245004}
Best loss: 0.0006434379612929469
Epoch 106:
Training summary: {'train_recon_loss': 0.004325991938348909, 'train_loss': 0.004325991938348909}
Evaluation summary: {'test_recon_loss': 0.0014962924568751976, 'test_loss': 0.0014962924568751976}
Best loss: 0.0006434379612929469
Epoch 107:
Training summary: {'train_recon_loss': 0.0011171657613037642, 'train_loss': 0.0011171657613037642}
Evaluation summary: {'test_recon_loss': 0.0008623621171714581, 'test_loss': 0.0008623621171714581}
Best loss: 0.0006434379612929469
Epoch 108:
Training summary: {'train_recon_loss': 0.0008382682584459784, 'train_loss': 0.0008382682584459784}
Evaluation summary: {'test_recon_loss': 0.0008017786871015413, 'test_loss': 0.0008017786871015413}
Best loss: 0.0006434379612929469
Epoch 109:
Training summary: {'train_recon_loss': 0.0007814739403181608, 'train_loss': 0.0007814739403181608}
Evaluation summary: {'test_recon_loss': 0.0007742304432469228, 'test_loss': 0.0007742304432469228}
Best loss: 0.0006434379612929469
Epoch 110:
Training summary: {'train_recon_loss': 0.002756506475178168, 'train_loss': 0.002756506475178168}
Evaluation summary: {'test_recon_loss': 0.0028549684307378224, 'test_loss': 0.0028549684307378224}
Best loss: 0.0006434379612929469
Epoch 111:
Training summary: {'train_recon_loss': 0.001260556511798143, 'train_loss': 0.001260556511798143}
Evaluation summary: {'test_recon_loss': 0.0008270119788371791, 'test_loss': 0.0008270119788371791}
Best loss: 0.0006434379612929469
Epoch 112:
Training summary: {'train_recon_loss': 0.0008372543889752753, 'train_loss': 0.0008372543889752753}
Evaluation summary: {'test_recon_loss': 0.0007491455504327933, 'test_loss': 0.0007491455504327933}
Best loss: 0.0006434379612929469
Epoch 113:
Training summary: {'train_recon_loss': 0.0007808589325706039, 'train_loss': 0.0007808589325706039}
Evaluation summary: {'test_recon_loss': 0.00114369214492741, 'test_loss': 0.00114369214492741}
Best loss: 0.0006434379612929469
Epoch 114:
Training summary: {'train_recon_loss': 0.0007527308236616714, 'train_loss': 0.0007527308236616714}
Evaluation summary: {'test_recon_loss': 0.0009125851485664358, 'test_loss': 0.0009125851485664358}
Best loss: 0.0006434379612929469
Epoch 115:
Training summary: {'train_recon_loss': 0.0007367771457841246, 'train_loss': 0.0007367771457841246}
Evaluation summary: {'test_recon_loss': 0.0007101160818463678, 'test_loss': 0.0007101160818463678}
Best loss: 0.0006434379612929469
Epoch 116:
Training summary: {'train_recon_loss': 0.0007249755582684976, 'train_loss': 0.0007249755582684976}
Evaluation summary: {'test_recon_loss': 0.0006945240284526671, 'test_loss': 0.0006945240284526671}
Best loss: 0.0006434379612929469
Epoch 117:
Training summary: {'train_recon_loss': 0.003681773587842484, 'train_loss': 0.003681773587842484}
Evaluation summary: {'test_recon_loss': 0.002129877773292502, 'test_loss': 0.002129877773292502}
Best loss: 0.0006434379612929469
Epoch 118:
Training summary: {'train_recon_loss': 0.0010456641749914915, 'train_loss': 0.0010456641749914915}
Evaluation summary: {'test_recon_loss': 0.001294689183933445, 'test_loss': 0.001294689183933445}
Best loss: 0.0006434379612929469
Epoch 119:
Training summary: {'train_recon_loss': 0.0008108581301333325, 'train_loss': 0.0008108581301333325}
Evaluation summary: {'test_recon_loss': 0.0008422589680992708, 'test_loss': 0.0008422589680992708}
Best loss: 0.0006434379612929469
Epoch 120:
Training summary: {'train_recon_loss': 0.0007531559303552636, 'train_loss': 0.0007531559303552636}
Evaluation summary: {'test_recon_loss': 0.0007364437641307785, 'test_loss': 0.0007364437641307785}
Best loss: 0.0006434379612929469
Epoch 121:
Training summary: {'train_recon_loss': 0.0007413705907985825, 'train_loss': 0.0007413705907985825}
Evaluation summary: {'test_recon_loss': 0.0007870130388206303, 'test_loss': 0.0007870130388206303}
Best loss: 0.0006434379612929469
Epoch 122:
Training summary: {'train_recon_loss': 0.0007101708748328497, 'train_loss': 0.0007101708748328497}
Evaluation summary: {'test_recon_loss': 0.0006899927421679132, 'test_loss': 0.0006899927421679132}
Best loss: 0.0006434379612929469
Epoch 123:
Training summary: {'train_recon_loss': 0.0007102960172930381, 'train_loss': 0.0007102960172930381}
Evaluation summary: {'test_recon_loss': 0.00068613299900541, 'test_loss': 0.00068613299900541}
Best loss: 0.0006434379612929469
Epoch 124:
Training summary: {'train_recon_loss': 0.0006888912199435312, 'train_loss': 0.0006888912199435312}
Evaluation summary: {'test_recon_loss': 0.0006527282876311627, 'test_loss': 0.0006527282876311627}
Best loss: 0.0006434379612929469
Epoch 125:
Training summary: {'train_recon_loss': 0.0006939960889848997, 'train_loss': 0.0006939960889848997}
Evaluation summary: {'test_recon_loss': 0.0006858401468760574, 'test_loss': 0.0006858401468760574}
Best loss: 0.0006434379612929469
Epoch 126:
Training summary: {'train_recon_loss': 0.0038520225664961105, 'train_loss': 0.0038520225664961105}
Evaluation summary: {'test_recon_loss': 0.003636568900403757, 'test_loss': 0.003636568900403757}
Best loss: 0.0006434379612929469
Epoch 127:
Training summary: {'train_recon_loss': 0.0020348424033933203, 'train_loss': 0.0020348424033933203}
Evaluation summary: {'test_recon_loss': 0.0013102558499292311, 'test_loss': 0.0013102558499292311}
Best loss: 0.0006434379612929469
Epoch 128:
Training summary: {'train_recon_loss': 0.001137848879196665, 'train_loss': 0.001137848879196665}
Evaluation summary: {'test_recon_loss': 0.001033792713602438, 'test_loss': 0.001033792713602438}
Best loss: 0.0006434379612929469
Epoch 129:
Training summary: {'train_recon_loss': 0.0009053450210641929, 'train_loss': 0.0009053450210641929}
Evaluation summary: {'test_recon_loss': 0.000812614157586863, 'test_loss': 0.000812614157586863}
Best loss: 0.0006434379612929469
Epoch 130:
Training summary: {'train_recon_loss': 0.0008234712101894269, 'train_loss': 0.0008234712101894269}
Evaluation summary: {'test_recon_loss': 0.0013546312345935783, 'test_loss': 0.0013546312345935783}
Best loss: 0.0006434379612929469
Epoch 131:
Training summary: {'train_recon_loss': 0.000776458308968673, 'train_loss': 0.000776458308968673}
Evaluation summary: {'test_recon_loss': 0.0007333745616347462, 'test_loss': 0.0007333745616347462}
Best loss: 0.0006434379612929469
Epoch 132:
Training summary: {'train_recon_loss': 0.0007387428279544877, 'train_loss': 0.0007387428279544877}
Evaluation summary: {'test_recon_loss': 0.0007524747042409379, 'test_loss': 0.0007524747042409379}
Best loss: 0.0006434379612929469
Epoch 133:
Training summary: {'train_recon_loss': 0.000728025667981472, 'train_loss': 0.000728025667981472}
Evaluation summary: {'test_recon_loss': 0.0006728311050060138, 'test_loss': 0.0006728311050060138}
Best loss: 0.0006434379612929469
Epoch 134:
Training summary: {'train_recon_loss': 0.0034510518019844508, 'train_loss': 0.0034510518019844508}
Evaluation summary: {'test_recon_loss': 0.002836871908183458, 'test_loss': 0.002836871908183458}
Best loss: 0.0006434379612929469
Epoch 135:
Training summary: {'train_recon_loss': 0.0016208217887976304, 'train_loss': 0.0016208217887976304}
Evaluation summary: {'test_recon_loss': 0.0012144595539736905, 'test_loss': 0.0012144595539736905}
Best loss: 0.0006434379612929469
Epoch 136:
Training summary: {'train_recon_loss': 0.000967340487509623, 'train_loss': 0.000967340487509623}
Evaluation summary: {'test_recon_loss': 0.0008089806604487283, 'test_loss': 0.0008089806604487283}
Best loss: 0.0006434379612929469
Epoch 137:
Training summary: {'train_recon_loss': 0.0008108743063096848, 'train_loss': 0.0008108743063096848}
Evaluation summary: {'test_recon_loss': 0.000709218094639012, 'test_loss': 0.000709218094639012}
Best loss: 0.0006434379612929469
Epoch 138:
Training summary: {'train_recon_loss': 0.0007597403666629805, 'train_loss': 0.0007597403666629805}
Evaluation summary: {'test_recon_loss': 0.0007773523701087021, 'test_loss': 0.0007773523701087021}
Best loss: 0.0006434379612929469
Epoch 139:
Training summary: {'train_recon_loss': 0.0007246122697562426, 'train_loss': 0.0007246122697562426}
Evaluation summary: {'test_recon_loss': 0.0007155220812121027, 'test_loss': 0.0007155220812121027}
Best loss: 0.0006434379612929469
Epoch 140:
Training summary: {'train_recon_loss': 0.0007104639523595161, 'train_loss': 0.0007104639523595161}
Evaluation summary: {'test_recon_loss': 0.0007226025373874935, 'test_loss': 0.0007226025373874935}
Best loss: 0.0006434379612929469
Epoch 141:
Training summary: {'train_recon_loss': 0.0007069893866241002, 'train_loss': 0.0007069893866241002}
Evaluation summary: {'test_recon_loss': 0.008567138317346573, 'test_loss': 0.008567138317346573}
Best loss: 0.0006434379612929469
Epoch 142:
Training summary: {'train_recon_loss': 0.0034300622828724353, 'train_loss': 0.0034300622828724353}
Evaluation summary: {'test_recon_loss': 0.0011646597949946545, 'test_loss': 0.0011646597949946545}
Best loss: 0.0006434379612929469
Epoch 143:
Training summary: {'train_recon_loss': 0.0008931607032662043, 'train_loss': 0.0008931607032662043}
Evaluation summary: {'test_recon_loss': 0.0009765473286451153, 'test_loss': 0.0009765473286451153}
Best loss: 0.0006434379612929469
Epoch 144:
Training summary: {'train_recon_loss': 0.0007673419124278974, 'train_loss': 0.0007673419124278974}
Evaluation summary: {'test_recon_loss': 0.0006910290346127518, 'test_loss': 0.0006910290346127518}
Best loss: 0.0006434379612929469
Epoch 145:
Training summary: {'train_recon_loss': 0.0007337720549662103, 'train_loss': 0.0007337720549662103}
Evaluation summary: {'test_recon_loss': 0.0007217258931742109, 'test_loss': 0.0007217258931742109}
Best loss: 0.0006434379612929469
Epoch 146:
Training summary: {'train_recon_loss': 0.0007063863397281381, 'train_loss': 0.0007063863397281381}
Evaluation summary: {'test_recon_loss': 0.0007219364111176014, 'test_loss': 0.0007219364111176014}
Best loss: 0.0006434379612929469
Epoch 147:
Training summary: {'train_recon_loss': 0.0038327233250460236, 'train_loss': 0.0038327233250460236}
Evaluation summary: {'test_recon_loss': 0.0015973128634585846, 'test_loss': 0.0015973128634585846}
Best loss: 0.0006434379612929469
Epoch 148:
Training summary: {'train_recon_loss': 0.001035453193774116, 'train_loss': 0.001035453193774116}
Evaluation summary: {'test_recon_loss': 0.000795167373324914, 'test_loss': 0.000795167373324914}
Best loss: 0.0006434379612929469
Epoch 149:
Training summary: {'train_recon_loss': 0.0007954844228994071, 'train_loss': 0.0007954844228994071}
Evaluation summary: {'test_recon_loss': 0.0007197495250569956, 'test_loss': 0.0007197495250569956}
Best loss: 0.0006434379612929469
Epoch 150:
Training summary: {'train_recon_loss': 0.003929014183073251, 'train_loss': 0.003929014183073251}
Evaluation summary: {'test_recon_loss': 0.0033689207774587736, 'test_loss': 0.0033689207774587736}
Best loss: 0.0006434379612929469
Epoch 151:
Training summary: {'train_recon_loss': 0.0014288318750708521, 'train_loss': 0.0014288318750708521}
Evaluation summary: {'test_recon_loss': 0.0009472178952468207, 'test_loss': 0.0009472178952468207}
Best loss: 0.0006434379612929469
Epoch 152:
Training summary: {'train_recon_loss': 0.0008665597961611671, 'train_loss': 0.0008665597961611671}
Evaluation summary: {'test_recon_loss': 0.0007832152518320677, 'test_loss': 0.0007832152518320677}
Best loss: 0.0006434379612929469
Epoch 153:
Training summary: {'train_recon_loss': 0.0007569090738421964, 'train_loss': 0.0007569090738421964}
Evaluation summary: {'test_recon_loss': 0.0008284448800063341, 'test_loss': 0.0008284448800063341}
Best loss: 0.0006434379612929469
Epoch 154:
Training summary: {'train_recon_loss': 0.0007379618221392047, 'train_loss': 0.0007379618221392047}
Evaluation summary: {'test_recon_loss': 0.0007032141442600747, 'test_loss': 0.0007032141442600747}
Best loss: 0.0006434379612929469
Epoch 155:
Training summary: {'train_recon_loss': 0.0007115575950181395, 'train_loss': 0.0007115575950181395}
Evaluation summary: {'test_recon_loss': 0.00069409076310648, 'test_loss': 0.00069409076310648}
Best loss: 0.0006434379612929469
Epoch 156:
Training summary: {'train_recon_loss': 0.0006965220114586436, 'train_loss': 0.0006965220114586436}
Evaluation summary: {'test_recon_loss': 0.0006862150492585289, 'test_loss': 0.0006862150492585289}
Best loss: 0.0006434379612929469
Epoch 157:
Training summary: {'train_recon_loss': 0.0006853582729526227, 'train_loss': 0.0006853582729526227}
Evaluation summary: {'test_recon_loss': 0.0008930541327765794, 'test_loss': 0.0008930541327765794}
Best loss: 0.0006434379612929469
Epoch 158:
Training summary: {'train_recon_loss': 0.0006883618694996678, 'train_loss': 0.0006883618694996678}
Evaluation summary: {'test_recon_loss': 0.0006638519674009997, 'test_loss': 0.0006638519674009997}
Best loss: 0.0006434379612929469
Epoch 159:
Training summary: {'train_recon_loss': 0.0006797203499792539, 'train_loss': 0.0006797203499792539}
Evaluation summary: {'test_recon_loss': 0.0006500649157861065, 'test_loss': 0.0006500649157861065}
Best loss: 0.0006434379612929469
Epoch 160:
Training summary: {'train_recon_loss': 0.0006840990990188051, 'train_loss': 0.0006840990990188051}
Evaluation summary: {'test_recon_loss': 0.0007120296602201216, 'test_loss': 0.0007120296602201216}
Best loss: 0.0006434379612929469
Epoch 161:
Training summary: {'train_recon_loss': 0.0038566771733645313, 'train_loss': 0.0038566771733645313}
Evaluation summary: {'test_recon_loss': 0.002413414132026952, 'test_loss': 0.002413414132026952}
Best loss: 0.0006434379612929469
Epoch 162:
Training summary: {'train_recon_loss': 0.0014552429135166467, 'train_loss': 0.0014552429135166467}
Evaluation summary: {'test_recon_loss': 0.0013357547900329381, 'test_loss': 0.0013357547900329381}
Best loss: 0.0006434379612929469
Epoch 163:
Training summary: {'train_recon_loss': 0.0009415751960097287, 'train_loss': 0.0009415751960097287}
Evaluation summary: {'test_recon_loss': 0.000817795907347979, 'test_loss': 0.000817795907347979}
Best loss: 0.0006434379612929469
Epoch 164:
Training summary: {'train_recon_loss': 0.0008222641769505364, 'train_loss': 0.0008222641769505364}
Evaluation summary: {'test_recon_loss': 0.000845075941646098, 'test_loss': 0.000845075941646098}
Best loss: 0.0006434379612929469
Epoch 165:
Training summary: {'train_recon_loss': 0.0007520501076921731, 'train_loss': 0.0007520501076921731}
Evaluation summary: {'test_recon_loss': 0.0007113921511752961, 'test_loss': 0.0007113921511752961}
Best loss: 0.0006434379612929469
Epoch 166:
Training summary: {'train_recon_loss': 0.0007258024844777027, 'train_loss': 0.0007258024844777027}
Evaluation summary: {'test_recon_loss': 0.0006988665829230863, 'test_loss': 0.0006988665829230863}
Best loss: 0.0006434379612929469
Epoch 167:
Training summary: {'train_recon_loss': 0.0007025378757459195, 'train_loss': 0.0007025378757459195}
Evaluation summary: {'test_recon_loss': 0.0007715188460354709, 'test_loss': 0.0007715188460354709}
Best loss: 0.0006434379612929469
Epoch 168:
Training summary: {'train_recon_loss': 0.000694006648841858, 'train_loss': 0.000694006648841858}
Evaluation summary: {'test_recon_loss': 0.0006862681952759889, 'test_loss': 0.0006862681952759889}
Best loss: 0.0006434379612929469
Epoch 169:
generate_recon.py --datadir . --metafile /mountb/single_cell_flist/ch0_all.csv --save-dir /mountb/autoencoder/ch0 --latent-dims 2048 --ae-features --pretrained-file /mountb/autoencoder/ch0/models/best.pth
Namespace(ae_features=True, batch_size=128, datadir='.', latent_dims=2048, metafile='/mountb/single_cell_flist/ch0_all.csv', pca_features=False, pretrained_file='/mountb/autoencoder/ch0/models/best.pth', save_dir='/mountb/autoencoder/ch0')
Dataset length is 9068498
AE46(
  (encoder): Sequential(
    (0): Conv2d(1, 46, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(46, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(92, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(184, 368, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (12): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (fc1): Linear(in_features=1472, out_features=2048, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): ConvTranspose2d(368, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): ConvTranspose2d(184, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
    (9): ConvTranspose2d(92, 46, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace=True)
    (12): ConvTranspose2d(46, 1, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Sigmoid()
  )
  (d1): Linear(in_features=2048, out_features=1472, bias=True)
  (mseloss): MSELoss()
)
Training summary: {'train_recon_loss': 0.0006887375455482962, 'train_loss': 0.0006887375455482962}
Evaluation summary: {'test_recon_loss': 0.0006979629239172192, 'test_loss': 0.0006979629239172192}
Best loss: 0.0006434379612929469
Epoch 170:
Training summary: {'train_recon_loss': 0.0006760107259744903, 'train_loss': 0.0006760107259744903}
Evaluation summary: {'test_recon_loss': 0.0006214464581081391, 'test_loss': 0.0006214464581081391}
Best loss: 0.0006214464581081391
Epoch 171:
Training summary: {'train_recon_loss': 0.0006841433992652165, 'train_loss': 0.0006841433992652165}
Evaluation summary: {'test_recon_loss': 0.0006884143001642249, 'test_loss': 0.0006884143001642249}
Best loss: 0.0006214464581081391
Epoch 172:
generate_recon.py --datadir . --metafile /mountb/single_cell_flist/ch0_all.csv --save-dir /mountb/autoencoder/ch0 --latent-dims 2048 --ae-features --pretrained-file /mountb/autoencoder/ch0/models/best.pth
Namespace(ae_features=True, batch_size=128, datadir='.', latent_dims=2048, metafile='/mountb/single_cell_flist/ch0_all.csv', pca_features=False, pretrained_file='/mountb/autoencoder/ch0/models/best.pth', save_dir='/mountb/autoencoder/ch0')
Training summary: {'train_recon_loss': 0.0006804764370537641, 'train_loss': 0.0006804764370537641}
Dataset length is 9068498
AE46(
  (encoder): Sequential(
    (0): Conv2d(1, 46, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(46, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(92, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(184, 368, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (12): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (fc1): Linear(in_features=1472, out_features=2048, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): ConvTranspose2d(368, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): ConvTranspose2d(184, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
    (9): ConvTranspose2d(92, 46, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace=True)
    (12): ConvTranspose2d(46, 1, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Sigmoid()
  )
  (d1): Linear(in_features=2048, out_features=1472, bias=True)
  (mseloss): MSELoss()
)
Evaluation summary: {'test_recon_loss': 0.0007021659890027968, 'test_loss': 0.0007021659890027968}
Best loss: 0.0006214464581081391
Epoch 173:
Training summary: {'train_recon_loss': 0.0035837249349689156, 'train_loss': 0.0035837249349689156}
Evaluation summary: {'test_recon_loss': 0.0021497337442081843, 'test_loss': 0.0021497337442081843}
Best loss: 0.0006214464581081391
Epoch 174:
Training summary: {'train_recon_loss': 0.0012968688527189613, 'train_loss': 0.0012968688527189613}
Evaluation summary: {'test_recon_loss': 0.0009575784201961504, 'test_loss': 0.0009575784201961504}
Best loss: 0.0006214464581081391
Epoch 175:
Training summary: {'train_recon_loss': 0.000886539073291567, 'train_loss': 0.000886539073291567}
Evaluation summary: {'test_recon_loss': 0.0007959269924271758, 'test_loss': 0.0007959269924271758}
Best loss: 0.0006214464581081391
Epoch 176:
Training summary: {'train_recon_loss': 0.0007805269635850133, 'train_loss': 0.0007805269635850133}
Evaluation summary: {'test_recon_loss': 0.0007193152244379589, 'test_loss': 0.0007193152244379589}
Best loss: 0.0006214464581081391
Epoch 177:
Training summary: {'train_recon_loss': 0.000739623581749542, 'train_loss': 0.000739623581749542}
generate_recon.py --datadir . --metafile /mountb/single_cell_flist/ch0_all.csv --save-dir /mountb/autoencoder/ch0 --latent-dims 2048 --ae-features --pretrained-file /mountb/autoencoder/ch0/models/best.pth
Namespace(ae_features=True, batch_size=128, datadir='.', latent_dims=2048, metafile='/mountb/single_cell_flist/ch0_all.csv', pca_features=False, pretrained_file='/mountb/autoencoder/ch0/models/best.pth', save_dir='/mountb/autoencoder/ch0')
Evaluation summary: {'test_recon_loss': 0.0007603920993474026, 'test_loss': 0.0007603920993474026}
Best loss: 0.0006214464581081391
Epoch 178:
Dataset length is 9068498
AE46(
  (encoder): Sequential(
    (0): Conv2d(1, 46, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(46, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(92, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(184, 368, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (12): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (fc1): Linear(in_features=1472, out_features=2048, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): ConvTranspose2d(368, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): ConvTranspose2d(184, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
    (9): ConvTranspose2d(92, 46, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace=True)
    (12): ConvTranspose2d(46, 1, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Sigmoid()
  )
  (d1): Linear(in_features=2048, out_features=1472, bias=True)
  (mseloss): MSELoss()
)
Training summary: {'train_recon_loss': 0.0007255383046893497, 'train_loss': 0.0007255383046893497}
Evaluation summary: {'test_recon_loss': 0.0007101794474531705, 'test_loss': 0.0007101794474531705}
Best loss: 0.0006214464581081391
Epoch 179:
Training summary: {'train_recon_loss': 0.0007199612650781701, 'train_loss': 0.0007199612650781701}
Evaluation summary: {'test_recon_loss': 0.000732470139802671, 'test_loss': 0.000732470139802671}
Best loss: 0.0006214464581081391
Epoch 180:
Training summary: {'train_recon_loss': 0.0026434896557629706, 'train_loss': 0.0026434896557629706}
Evaluation summary: {'test_recon_loss': 0.006233443499592018, 'test_loss': 0.006233443499592018}
Best loss: 0.0006214464581081391
Epoch 181:
