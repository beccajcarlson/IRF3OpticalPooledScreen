run_train.py --max-value 50155 --datadir . --train-metafile /mountb/single_cell_flist/train_ch6_small.csv --val-metafile /mountb/single_cell_flist/val_ch6_small.csv --save-dir /mountb/autoencoder/ch6 --model-type AE46 --dataset-type 46 --latent-dims 2048
Namespace(batch_size=128, datadir='.', dataset_type='46', debug_mode=False, latent_dims=2048, learning_rate=0.001, max_epochs=2000, max_value=50155, model_type='AE46', num_workers=8, optimizer='adam', save_dir='/mountb/autoencoder/ch6', save_freq=50, seed=42, train_metafile='/mountb/single_cell_flist/train_ch6_small.csv', val_metafile='/mountb/single_cell_flist/val_ch6_small.csv', weight_decay=1e-05)
AE46(
  (encoder): Sequential(
    (0): Conv2d(1, 46, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(46, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(92, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(184, 368, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (12): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (fc1): Linear(in_features=1472, out_features=2048, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): ConvTranspose2d(368, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): ConvTranspose2d(184, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
    (9): ConvTranspose2d(92, 46, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace=True)
    (12): ConvTranspose2d(46, 1, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Sigmoid()
  )
  (d1): Linear(in_features=2048, out_features=1472, bias=True)
  (mseloss): MSELoss()
)
Epoch 0:
Training summary: {'train_recon_loss': 0.009558885496491464, 'train_loss': 0.009558885496491464}
Evaluation summary: {'test_recon_loss': 0.0023680603918426113, 'test_loss': 0.0023680603918426113}
Best loss: 0.0023680603918426113
Epoch 1:
Training summary: {'train_recon_loss': 0.0017687929524750482, 'train_loss': 0.0017687929524750482}
Evaluation summary: {'test_recon_loss': 0.0014926031630196845, 'test_loss': 0.0014926031630196845}
Best loss: 0.0014926031630196845
Epoch 2:
Training summary: {'train_recon_loss': 0.0012327712959924204, 'train_loss': 0.0012327712959924204}
Evaluation summary: {'test_recon_loss': 0.0010514835877959018, 'test_loss': 0.0010514835877959018}
Best loss: 0.0010514835877959018
Epoch 3:
Training summary: {'train_recon_loss': 0.0010084691750545517, 'train_loss': 0.0010084691750545517}
Evaluation summary: {'test_recon_loss': 0.0068386933447323476, 'test_loss': 0.0068386933447323476}
Best loss: 0.0010514835877959018
Epoch 4:
Training summary: {'train_recon_loss': 0.0014710023285707558, 'train_loss': 0.0014710023285707558}
Evaluation summary: {'test_recon_loss': 0.003074307349076743, 'test_loss': 0.003074307349076743}
Best loss: 0.0010514835877959018
Epoch 5:
Training summary: {'train_recon_loss': 0.001659722828331761, 'train_loss': 0.001659722828331761}
Evaluation summary: {'test_recon_loss': 0.001261039807585929, 'test_loss': 0.001261039807585929}
Best loss: 0.0010514835877959018
Epoch 6:
Training summary: {'train_recon_loss': 0.000956846747667505, 'train_loss': 0.000956846747667505}
Evaluation summary: {'test_recon_loss': 0.0009065329066382517, 'test_loss': 0.0009065329066382517}
Best loss: 0.0009065329066382517
Epoch 7:
Training summary: {'train_recon_loss': 0.0009065854001967991, 'train_loss': 0.0009065854001967991}
Evaluation summary: {'test_recon_loss': 0.0008383330735877596, 'test_loss': 0.0008383330735877596}
Best loss: 0.0008383330735877596
Epoch 8:
Training summary: {'train_recon_loss': 0.0008700152823303303, 'train_loss': 0.0008700152823303303}
Evaluation summary: {'test_recon_loss': 0.0008158991532283432, 'test_loss': 0.0008158991532283432}
Best loss: 0.0008158991532283432
Epoch 9:
Training summary: {'train_recon_loss': 0.0012676816649838626, 'train_loss': 0.0012676816649838626}
Evaluation summary: {'test_recon_loss': 0.0008481987554389671, 'test_loss': 0.0008481987554389671}
Best loss: 0.0008158991532283432
Epoch 10:
Training summary: {'train_recon_loss': 0.001073011447463265, 'train_loss': 0.001073011447463265}
Evaluation summary: {'test_recon_loss': 0.0010401685527012758, 'test_loss': 0.0010401685527012758}
Best loss: 0.0008158991532283432
Epoch 11:
Training summary: {'train_recon_loss': 0.000858647363279311, 'train_loss': 0.000858647363279311}
Evaluation summary: {'test_recon_loss': 0.000821795609025899, 'test_loss': 0.000821795609025899}
Best loss: 0.0008158991532283432
Epoch 12:
Training summary: {'train_recon_loss': 0.0008248156108342236, 'train_loss': 0.0008248156108342236}
Evaluation summary: {'test_recon_loss': 0.0009387515335776754, 'test_loss': 0.0009387515335776754}
Best loss: 0.0008158991532283432
Epoch 13:
Training summary: {'train_recon_loss': 0.0012743726546313391, 'train_loss': 0.0012743726546313391}
Evaluation summary: {'test_recon_loss': 0.0017847246262299565, 'test_loss': 0.0017847246262299565}
Best loss: 0.0008158991532283432
Epoch 14:
Training summary: {'train_recon_loss': 0.0009858140168841532, 'train_loss': 0.0009858140168841532}
Evaluation summary: {'test_recon_loss': 0.0007986084058357401, 'test_loss': 0.0007986084058357401}
Best loss: 0.0007986084058357401
Epoch 15:
Training summary: {'train_recon_loss': 0.0010728899877174508, 'train_loss': 0.0010728899877174508}
Evaluation summary: {'test_recon_loss': 0.0007729159000630273, 'test_loss': 0.0007729159000630273}
Best loss: 0.0007729159000630273
Epoch 16:
Training summary: {'train_recon_loss': 0.0007530741843801355, 'train_loss': 0.0007530741843801355}
Evaluation summary: {'test_recon_loss': 0.0007465998333408814, 'test_loss': 0.0007465998333408814}
Best loss: 0.0007465998333408814
Epoch 17:
Training summary: {'train_recon_loss': 0.001050814312932907, 'train_loss': 0.001050814312932907}
Evaluation summary: {'test_recon_loss': 0.0008984342657708, 'test_loss': 0.0008984342657708}
Best loss: 0.0007465998333408814
Epoch 18:
Training summary: {'train_recon_loss': 0.0007367071926193931, 'train_loss': 0.0007367071926193931}
Evaluation summary: {'test_recon_loss': 0.0006696809664921256, 'test_loss': 0.0006696809664921256}
Best loss: 0.0006696809664921256
Epoch 19:
Training summary: {'train_recon_loss': 0.0006868517190438459, 'train_loss': 0.0006868517190438459}
Evaluation summary: {'test_recon_loss': 0.0006551531306982727, 'test_loss': 0.0006551531306982727}
Best loss: 0.0006551531306982727
Epoch 20:
Training summary: {'train_recon_loss': 0.0013035717542660052, 'train_loss': 0.0013035717542660052}
Evaluation summary: {'test_recon_loss': 0.0007410858718871119, 'test_loss': 0.0007410858718871119}
Best loss: 0.0006551531306982727
Epoch 21:
Training summary: {'train_recon_loss': 0.0009891750184447242, 'train_loss': 0.0009891750184447242}
Evaluation summary: {'test_recon_loss': 0.003133410521037189, 'test_loss': 0.003133410521037189}
Best loss: 0.0006551531306982727
Epoch 22:
Training summary: {'train_recon_loss': 0.0010189157637089563, 'train_loss': 0.0010189157637089563}
Evaluation summary: {'test_recon_loss': 0.0006921133467475033, 'test_loss': 0.0006921133467475033}
Best loss: 0.0006551531306982727
Epoch 23:
Training summary: {'train_recon_loss': 0.0006643597286707943, 'train_loss': 0.0006643597286707943}
Evaluation summary: {'test_recon_loss': 0.0006306600596534375, 'test_loss': 0.0006306600596534375}
Best loss: 0.0006306600596534375
Epoch 24:
Training summary: {'train_recon_loss': 0.0006312756395410059, 'train_loss': 0.0006312756395410059}
Evaluation summary: {'test_recon_loss': 0.0005954872771863999, 'test_loss': 0.0005954872771863999}
Best loss: 0.0005954872771863999
Epoch 25:
Training summary: {'train_recon_loss': 0.0015367198150930768, 'train_loss': 0.0015367198150930768}
Evaluation summary: {'test_recon_loss': 0.0007747466353469883, 'test_loss': 0.0007747466353469883}
Best loss: 0.0005954872771863999
Epoch 26:
Training summary: {'train_recon_loss': 0.0006931545831964018, 'train_loss': 0.0006931545831964018}
Evaluation summary: {'test_recon_loss': 0.0006276063895910638, 'test_loss': 0.0006276063895910638}
Best loss: 0.0005954872771863999
Epoch 27:
Training summary: {'train_recon_loss': 0.0012966920614494305, 'train_loss': 0.0012966920614494305}
Evaluation summary: {'test_recon_loss': 0.000894388065700318, 'test_loss': 0.000894388065700318}
Best loss: 0.0005954872771863999
Epoch 28:
Training summary: {'train_recon_loss': 0.0006927706669586589, 'train_loss': 0.0006927706669586589}
Evaluation summary: {'test_recon_loss': 0.0006303086670489879, 'test_loss': 0.0006303086670489879}
Best loss: 0.0005954872771863999
Epoch 29:
Training summary: {'train_recon_loss': 0.0008718943937686554, 'train_loss': 0.0008718943937686554}
Evaluation summary: {'test_recon_loss': 0.0023397053422839396, 'test_loss': 0.0023397053422839396}
Best loss: 0.0005954872771863999
Epoch 30:
Training summary: {'train_recon_loss': 0.0009233415685840909, 'train_loss': 0.0009233415685840909}
Evaluation summary: {'test_recon_loss': 0.0007373472600672597, 'test_loss': 0.0007373472600672597}
Best loss: 0.0005954872771863999
Epoch 31:
Training summary: {'train_recon_loss': 0.0012884623317176319, 'train_loss': 0.0012884623317176319}
Evaluation summary: {'test_recon_loss': 0.0011173779022774475, 'test_loss': 0.0011173779022774475}
Best loss: 0.0005954872771863999
Epoch 32:
Training summary: {'train_recon_loss': 0.0006930054734747313, 'train_loss': 0.0006930054734747313}
Evaluation summary: {'test_recon_loss': 0.0006586115762120285, 'test_loss': 0.0006586115762120285}
Best loss: 0.0005954872771863999
Epoch 33:
Training summary: {'train_recon_loss': 0.000610301493936097, 'train_loss': 0.000610301493936097}
Evaluation summary: {'test_recon_loss': 0.000607118535118402, 'test_loss': 0.000607118535118402}
Best loss: 0.0005954872771863999
Epoch 34:
Training summary: {'train_recon_loss': 0.0015829870738121995, 'train_loss': 0.0015829870738121995}
Evaluation summary: {'test_recon_loss': 0.0014225822221495452, 'test_loss': 0.0014225822221495452}
Best loss: 0.0005954872771863999
Epoch 35:
Training summary: {'train_recon_loss': 0.0008884155325790665, 'train_loss': 0.0008884155325790665}
Evaluation summary: {'test_recon_loss': 0.0006959938613059406, 'test_loss': 0.0006959938613059406}
Best loss: 0.0005954872771863999
Epoch 36:
Training summary: {'train_recon_loss': 0.0006785529534835965, 'train_loss': 0.0006785529534835965}
Evaluation summary: {'test_recon_loss': 0.000638724665143684, 'test_loss': 0.000638724665143684}
Best loss: 0.0005954872771863999
Epoch 37:
Training summary: {'train_recon_loss': 0.0009675888901423364, 'train_loss': 0.0009675888901423364}
Evaluation summary: {'test_recon_loss': 0.002506858709402243, 'test_loss': 0.002506858709402243}
Best loss: 0.0005954872771863999
Epoch 38:
Training summary: {'train_recon_loss': 0.001024953266539918, 'train_loss': 0.001024953266539918}
Evaluation summary: {'test_recon_loss': 0.0006595875698527594, 'test_loss': 0.0006595875698527594}
Best loss: 0.0005954872771863999
Epoch 39:
Training summary: {'train_recon_loss': 0.0006439306959592118, 'train_loss': 0.0006439306959592118}
Evaluation summary: {'test_recon_loss': 0.000586142833250284, 'test_loss': 0.000586142833250284}
Best loss: 0.000586142833250284
Epoch 40:
Training summary: {'train_recon_loss': 0.0016033050551510332, 'train_loss': 0.0016033050551510332}
Evaluation summary: {'test_recon_loss': 0.001376767926866884, 'test_loss': 0.001376767926866884}
Best loss: 0.000586142833250284
Epoch 41:
Training summary: {'train_recon_loss': 0.0009586392718164891, 'train_loss': 0.0009586392718164891}
Evaluation summary: {'test_recon_loss': 0.000826402370947976, 'test_loss': 0.000826402370947976}
Best loss: 0.000586142833250284
Epoch 42:
Training summary: {'train_recon_loss': 0.0007674661836242991, 'train_loss': 0.0007674661836242991}
Evaluation summary: {'test_recon_loss': 0.0007078774336067377, 'test_loss': 0.0007078774336067377}
Best loss: 0.000586142833250284
Epoch 43:
Training summary: {'train_recon_loss': 0.0011710561239103008, 'train_loss': 0.0011710561239103008}
Evaluation summary: {'test_recon_loss': 0.001078924759853747, 'test_loss': 0.001078924759853747}
Best loss: 0.000586142833250284
Epoch 44:
Training summary: {'train_recon_loss': 0.0007606203287927101, 'train_loss': 0.0007606203287927101}
Evaluation summary: {'test_recon_loss': 0.000668973831973553, 'test_loss': 0.000668973831973553}
Best loss: 0.000586142833250284
Epoch 45:
Training summary: {'train_recon_loss': 0.0007108835837278882, 'train_loss': 0.0007108835837278882}
Evaluation summary: {'test_recon_loss': 0.024300781887439758, 'test_loss': 0.024300781887439758}
Best loss: 0.000586142833250284
Epoch 46:
Training summary: {'train_recon_loss': 0.001299081740871256, 'train_loss': 0.001299081740871256}
Evaluation summary: {'test_recon_loss': 0.0007093470649235681, 'test_loss': 0.0007093470649235681}
Best loss: 0.000586142833250284
Epoch 47:
Training summary: {'train_recon_loss': 0.0006916890887119041, 'train_loss': 0.0006916890887119041}
Evaluation summary: {'test_recon_loss': 0.0006417258952064133, 'test_loss': 0.0006417258952064133}
Best loss: 0.000586142833250284
Epoch 48:
Training summary: {'train_recon_loss': 0.0013040759546810584, 'train_loss': 0.0013040759546810584}
Evaluation summary: {'test_recon_loss': 0.0021499763966155525, 'test_loss': 0.0021499763966155525}
Best loss: 0.000586142833250284
Epoch 49:
Training summary: {'train_recon_loss': 0.0011076660578545538, 'train_loss': 0.0011076660578545538}
Evaluation summary: {'test_recon_loss': 0.0007162567787927616, 'test_loss': 0.0007162567787927616}
Best loss: 0.000586142833250284
Epoch 50:
Training summary: {'train_recon_loss': 0.0006986886115626237, 'train_loss': 0.0006986886115626237}
Evaluation summary: {'test_recon_loss': 0.0006607035237804588, 'test_loss': 0.0006607035237804588}
Best loss: 0.000586142833250284
Epoch 51:
Training summary: {'train_recon_loss': 0.0006815968144087734, 'train_loss': 0.0006815968144087734}
Evaluation summary: {'test_recon_loss': 0.0006848595673368823, 'test_loss': 0.0006848595673368823}
Best loss: 0.000586142833250284
Epoch 52:
Training summary: {'train_recon_loss': 0.0012380994232939141, 'train_loss': 0.0012380994232939141}
Evaluation summary: {'test_recon_loss': 0.002044510033338049, 'test_loss': 0.002044510033338049}
Best loss: 0.000586142833250284
Epoch 53:
Training summary: {'train_recon_loss': 0.0011382201817520165, 'train_loss': 0.0011382201817520165}
Evaluation summary: {'test_recon_loss': 0.0007608251039898946, 'test_loss': 0.0007608251039898946}
Best loss: 0.000586142833250284
Epoch 54:
Training summary: {'train_recon_loss': 0.0007912609000137413, 'train_loss': 0.0007912609000137413}
Evaluation summary: {'test_recon_loss': 0.0877547157337728, 'test_loss': 0.0877547157337728}
Best loss: 0.000586142833250284
Epoch 55:
Training summary: {'train_recon_loss': 0.0014460052074798686, 'train_loss': 0.0014460052074798686}
Evaluation summary: {'test_recon_loss': 0.000796541650871589, 'test_loss': 0.000796541650871589}
Best loss: 0.000586142833250284
Epoch 56:
Training summary: {'train_recon_loss': 0.0007270780028347517, 'train_loss': 0.0007270780028347517}
Evaluation summary: {'test_recon_loss': 0.0006913781714930261, 'test_loss': 0.0006913781714930261}
Best loss: 0.000586142833250284
Epoch 57:
Training summary: {'train_recon_loss': 0.0011726234605134373, 'train_loss': 0.0011726234605134373}
Evaluation summary: {'test_recon_loss': 0.001869690985250277, 'test_loss': 0.001869690985250277}
Best loss: 0.000586142833250284
Epoch 58:
Training summary: {'train_recon_loss': 0.0009202131607229142, 'train_loss': 0.0009202131607229142}
Evaluation summary: {'test_recon_loss': 0.0006812232073715892, 'test_loss': 0.0006812232073715892}
Best loss: 0.000586142833250284
Epoch 59:
Training summary: {'train_recon_loss': 0.000693100152143142, 'train_loss': 0.000693100152143142}
Evaluation summary: {'test_recon_loss': 0.0006726034390959869, 'test_loss': 0.0006726034390959869}
Best loss: 0.000586142833250284
Epoch 60:
Training summary: {'train_recon_loss': 0.0011664846940410362, 'train_loss': 0.0011664846940410362}
Evaluation summary: {'test_recon_loss': 0.000844000530061883, 'test_loss': 0.000844000530061883}
Best loss: 0.000586142833250284
Epoch 61:
Training summary: {'train_recon_loss': 0.0007081301283303568, 'train_loss': 0.0007081301283303568}
Evaluation summary: {'test_recon_loss': 0.0006648870967934212, 'test_loss': 0.0006648870967934212}
Best loss: 0.000586142833250284
Epoch 62:
Training summary: {'train_recon_loss': 0.0006882806878097612, 'train_loss': 0.0006882806878097612}
Evaluation summary: {'test_recon_loss': 0.0006615629496624945, 'test_loss': 0.0006615629496624945}
Best loss: 0.000586142833250284
Epoch 63:
Training summary: {'train_recon_loss': 0.0015076460072428464, 'train_loss': 0.0015076460072428464}
Evaluation summary: {'test_recon_loss': 0.0009527940000267467, 'test_loss': 0.0009527940000267467}
Best loss: 0.000586142833250284
Epoch 64:
Training summary: {'train_recon_loss': 0.0007827133631379775, 'train_loss': 0.0007827133631379775}
Evaluation summary: {'test_recon_loss': 0.0007106054964871855, 'test_loss': 0.0007106054964871855}
Best loss: 0.000586142833250284
Epoch 65:
Training summary: {'train_recon_loss': 0.0006892573428397846, 'train_loss': 0.0006892573428397846}
Evaluation summary: {'test_recon_loss': 0.0006523816782445377, 'test_loss': 0.0006523816782445377}
Best loss: 0.000586142833250284
Epoch 66:
Training summary: {'train_recon_loss': 0.0012777068313045013, 'train_loss': 0.0012777068313045013}
Evaluation summary: {'test_recon_loss': 0.0006948060055764049, 'test_loss': 0.0006948060055764049}
Best loss: 0.000586142833250284
Epoch 67:
Training summary: {'train_recon_loss': 0.0010977354044236194, 'train_loss': 0.0010977354044236194}
Evaluation summary: {'test_recon_loss': 0.0022956961460485277, 'test_loss': 0.0022956961460485277}
Best loss: 0.000586142833250284
Epoch 68:
Training summary: {'train_recon_loss': 0.0009428023815429822, 'train_loss': 0.0009428023815429822}
Evaluation summary: {'test_recon_loss': 0.0006902274695879662, 'test_loss': 0.0006902274695879662}
Best loss: 0.000586142833250284
Epoch 69:
Training summary: {'train_recon_loss': 0.0006937315701317792, 'train_loss': 0.0006937315701317792}
Evaluation summary: {'test_recon_loss': 0.0007655375477244365, 'test_loss': 0.0007655375477244365}
Best loss: 0.000586142833250284
Epoch 70:
Training summary: {'train_recon_loss': 0.0006899596956046789, 'train_loss': 0.0006899596956046789}
Evaluation summary: {'test_recon_loss': 0.0006956780221249926, 'test_loss': 0.0006956780221249926}
Best loss: 0.000586142833250284
Epoch 71:
Training summary: {'train_recon_loss': 0.0014943405000621282, 'train_loss': 0.0014943405000621282}
Evaluation summary: {'test_recon_loss': 0.0007421828864469958, 'test_loss': 0.0007421828864469958}
Best loss: 0.000586142833250284
Epoch 72:
Training summary: {'train_recon_loss': 0.0013857467722002894, 'train_loss': 0.0013857467722002894}
Evaluation summary: {'test_recon_loss': 0.0008928499938530146, 'test_loss': 0.0008928499938530146}
Best loss: 0.000586142833250284
Epoch 73:
Training summary: {'train_recon_loss': 0.0007210008236670091, 'train_loss': 0.0007210008236670091}
Evaluation summary: {'test_recon_loss': 0.0006777617312275224, 'test_loss': 0.0006777617312275224}
Best loss: 0.000586142833250284
Epoch 74:
Training summary: {'train_recon_loss': 0.0006876230251591973, 'train_loss': 0.0006876230251591973}
Evaluation summary: {'test_recon_loss': 0.0006631712948097463, 'test_loss': 0.0006631712948097463}
Best loss: 0.000586142833250284
Epoch 75:
Training summary: {'train_recon_loss': 0.0012046503241037343, 'train_loss': 0.0012046503241037343}
Evaluation summary: {'test_recon_loss': 0.0008496187959917891, 'test_loss': 0.0008496187959917891}
Best loss: 0.000586142833250284
Epoch 76:
Training summary: {'train_recon_loss': 0.0007102415391388794, 'train_loss': 0.0007102415391388794}
Evaluation summary: {'test_recon_loss': 0.0006627660142287081, 'test_loss': 0.0006627660142287081}
Best loss: 0.000586142833250284
Epoch 77:
Training summary: {'train_recon_loss': 0.000692099954993809, 'train_loss': 0.000692099954993809}
Evaluation summary: {'test_recon_loss': 0.0006689720131069062, 'test_loss': 0.0006689720131069062}
Best loss: 0.000586142833250284
Epoch 78:
Training summary: {'train_recon_loss': 0.0015088132217110143, 'train_loss': 0.0015088132217110143}
Evaluation summary: {'test_recon_loss': 0.00079213163435441, 'test_loss': 0.00079213163435441}
Best loss: 0.000586142833250284
Epoch 79:
Training summary: {'train_recon_loss': 0.0007105293858947736, 'train_loss': 0.0007105293858947736}
Evaluation summary: {'test_recon_loss': 0.0007228305645367606, 'test_loss': 0.0007228305645367606}
Best loss: 0.000586142833250284
Epoch 80:
Training summary: {'train_recon_loss': 0.0006888485350111319, 'train_loss': 0.0006888485350111319}
Evaluation summary: {'test_recon_loss': 0.0007003359440815278, 'test_loss': 0.0007003359440815278}
Best loss: 0.000586142833250284
Epoch 81:
Training summary: {'train_recon_loss': 0.0012688669888220399, 'train_loss': 0.0012688669888220399}
Evaluation summary: {'test_recon_loss': 0.0020001576093798875, 'test_loss': 0.0020001576093798875}
Best loss: 0.000586142833250284
Epoch 82:
Training summary: {'train_recon_loss': 0.0011388577887781837, 'train_loss': 0.0011388577887781837}
Evaluation summary: {'test_recon_loss': 0.0008070888058852156, 'test_loss': 0.0008070888058852156}
Best loss: 0.000586142833250284
Epoch 83:
Training summary: {'train_recon_loss': 0.0007255233900560653, 'train_loss': 0.0007255233900560653}
Evaluation summary: {'test_recon_loss': 0.000689963580181145, 'test_loss': 0.000689963580181145}
Best loss: 0.000586142833250284
Epoch 84:
Training summary: {'train_recon_loss': 0.0009261912550257244, 'train_loss': 0.0009261912550257244}
Evaluation summary: {'test_recon_loss': 0.0026486812052561124, 'test_loss': 0.0026486812052561124}
Best loss: 0.000586142833250284
Epoch 85:
Training summary: {'train_recon_loss': 0.0008979181660538336, 'train_loss': 0.0008979181660538336}
Evaluation summary: {'test_recon_loss': 0.0006657199788010465, 'test_loss': 0.0006657199788010465}
Best loss: 0.000586142833250284
Epoch 86:
Training summary: {'train_recon_loss': 0.0006894409173586189, 'train_loss': 0.0006894409173586189}
Evaluation summary: {'test_recon_loss': 0.0006530212439226068, 'test_loss': 0.0006530212439226068}
Best loss: 0.000586142833250284
Epoch 87:
Training summary: {'train_recon_loss': 0.001220419313495339, 'train_loss': 0.001220419313495339}
Evaluation summary: {'test_recon_loss': 0.001868961347390681, 'test_loss': 0.001868961347390681}
Best loss: 0.000586142833250284
Epoch 88:
Training summary: {'train_recon_loss': 0.0009007447738777986, 'train_loss': 0.0009007447738777986}
Evaluation summary: {'test_recon_loss': 0.0006840555905533906, 'test_loss': 0.0006840555905533906}
Best loss: 0.000586142833250284
Epoch 89:
Training summary: {'train_recon_loss': 0.001706678876916587, 'train_loss': 0.001706678876916587}
Evaluation summary: {'test_recon_loss': 0.001059847367171211, 'test_loss': 0.001059847367171211}
Best loss: 0.000586142833250284
Epoch 90:
Training summary: {'train_recon_loss': 0.000754168340006626, 'train_loss': 0.000754168340006626}
Evaluation summary: {'test_recon_loss': 0.000667054872040468, 'test_loss': 0.000667054872040468}
Best loss: 0.000586142833250284
Epoch 91:
Training summary: {'train_recon_loss': 0.001382986080747216, 'train_loss': 0.001382986080747216}
Evaluation summary: {'test_recon_loss': 0.0019496987846364653, 'test_loss': 0.0019496987846364653}
Best loss: 0.000586142833250284
Epoch 92:
Training summary: {'train_recon_loss': 0.0010297692043734743, 'train_loss': 0.0010297692043734743}
Evaluation summary: {'test_recon_loss': 0.0007142746421349205, 'test_loss': 0.0007142746421349205}
Best loss: 0.000586142833250284
Epoch 93:
Training summary: {'train_recon_loss': 0.000699208912874864, 'train_loss': 0.000699208912874864}
Evaluation summary: {'test_recon_loss': 0.000671721296994704, 'test_loss': 0.000671721296994704}
Best loss: 0.000586142833250284
Epoch 94:
Training summary: {'train_recon_loss': 0.0006885956858684615, 'train_loss': 0.0006885956858684615}
Evaluation summary: {'test_recon_loss': 0.0007740193268529087, 'test_loss': 0.0007740193268529087}
Best loss: 0.000586142833250284
Epoch 95:
Training summary: {'train_recon_loss': 0.0006826293596943555, 'train_loss': 0.0006826293596943555}
Evaluation summary: {'test_recon_loss': 0.0006507384154906635, 'test_loss': 0.0006507384154906635}
Best loss: 0.000586142833250284
Epoch 96:
Training summary: {'train_recon_loss': 0.0018527128494282125, 'train_loss': 0.0018527128494282125}
Evaluation summary: {'test_recon_loss': 0.0010241935568768052, 'test_loss': 0.0010241935568768052}
Best loss: 0.000586142833250284
Epoch 97:
Training summary: {'train_recon_loss': 0.0008269228949664043, 'train_loss': 0.0008269228949664043}
Evaluation summary: {'test_recon_loss': 0.0007114925137665033, 'test_loss': 0.0007114925137665033}
Best loss: 0.000586142833250284
Epoch 98:
Training summary: {'train_recon_loss': 0.00070413704525495, 'train_loss': 0.00070413704525495}
Evaluation summary: {'test_recon_loss': 0.0006637119731432488, 'test_loss': 0.0006637119731432488}
Best loss: 0.000586142833250284
Epoch 99:
Training summary: {'train_recon_loss': 0.0016425660263842416, 'train_loss': 0.0016425660263842416}
Evaluation summary: {'test_recon_loss': 0.0010529149999150788, 'test_loss': 0.0010529149999150788}
Best loss: 0.000586142833250284
Epoch 100:
Training summary: {'train_recon_loss': 0.0008647834949809129, 'train_loss': 0.0008647834949809129}
Evaluation summary: {'test_recon_loss': 0.0007480645534517118, 'test_loss': 0.0007480645534517118}
Best loss: 0.000586142833250284
Epoch 101:
Training summary: {'train_recon_loss': 0.0007621015416081452, 'train_loss': 0.0007621015416081452}
Evaluation summary: {'test_recon_loss': 0.012579270778657772, 'test_loss': 0.012579270778657772}
Best loss: 0.000586142833250284
Epoch 102:
Training summary: {'train_recon_loss': 0.0015173500999002033, 'train_loss': 0.0015173500999002033}
Evaluation summary: {'test_recon_loss': 0.0007696929510055898, 'test_loss': 0.0007696929510055898}
Best loss: 0.000586142833250284
Epoch 103:
Training summary: {'train_recon_loss': 0.0007187646007216316, 'train_loss': 0.0007187646007216316}
Evaluation summary: {'test_recon_loss': 0.0006594456917939396, 'test_loss': 0.0006594456917939396}
Best loss: 0.000586142833250284
Epoch 104:
Training summary: {'train_recon_loss': 0.0006772017248539261, 'train_loss': 0.0006772017248539261}
Evaluation summary: {'test_recon_loss': 0.0006620509353031508, 'test_loss': 0.0006620509353031508}
Best loss: 0.000586142833250284
Epoch 105:
Training summary: {'train_recon_loss': 0.0006562752863918772, 'train_loss': 0.0006562752863918772}
Evaluation summary: {'test_recon_loss': 0.000649932291894899, 'test_loss': 0.000649932291894899}
Best loss: 0.000586142833250284
Epoch 106:
Training summary: {'train_recon_loss': 0.0011764506756142116, 'train_loss': 0.0011764506756142116}
Evaluation summary: {'test_recon_loss': 0.0007918481851259679, 'test_loss': 0.0007918481851259679}
Best loss: 0.000586142833250284
Epoch 107:
Training summary: {'train_recon_loss': 0.0007098843289050518, 'train_loss': 0.0007098843289050518}
Evaluation summary: {'test_recon_loss': 0.0006718309507539157, 'test_loss': 0.0006718309507539157}
Best loss: 0.000586142833250284
Epoch 108:
Training summary: {'train_recon_loss': 0.0015268165664665085, 'train_loss': 0.0015268165664665085}
Evaluation summary: {'test_recon_loss': 0.0010316596942886854, 'test_loss': 0.0010316596942886854}
Best loss: 0.000586142833250284
Epoch 109:
Training summary: {'train_recon_loss': 0.000772942717939076, 'train_loss': 0.000772942717939076}
Evaluation summary: {'test_recon_loss': 0.0007112273070410773, 'test_loss': 0.0007112273070410773}
Best loss: 0.000586142833250284
Epoch 110:
Training summary: {'train_recon_loss': 0.0006899190037190428, 'train_loss': 0.0006899190037190428}
Evaluation summary: {'test_recon_loss': 0.00072489345092997, 'test_loss': 0.00072489345092997}
Best loss: 0.000586142833250284
Epoch 111:
Training summary: {'train_recon_loss': 0.0012783192723615977, 'train_loss': 0.0012783192723615977}
Evaluation summary: {'test_recon_loss': 0.0018225847154731665, 'test_loss': 0.0018225847154731665}
Best loss: 0.000586142833250284
Epoch 112:
Training summary: {'train_recon_loss': 0.0008465948758577738, 'train_loss': 0.0008465948758577738}
Evaluation summary: {'test_recon_loss': 0.0009216096807751254, 'test_loss': 0.0009216096807751254}
Best loss: 0.000586142833250284
Epoch 113:
Training summary: {'train_recon_loss': 0.0006955305178972232, 'train_loss': 0.0006955305178972232}
Evaluation summary: {'test_recon_loss': 0.0006732947035013692, 'test_loss': 0.0006732947035013692}
Best loss: 0.000586142833250284
Epoch 114:
Training summary: {'train_recon_loss': 0.0015820947813253532, 'train_loss': 0.0015820947813253532}
Evaluation summary: {'test_recon_loss': 0.0009442300261963163, 'test_loss': 0.0009442300261963163}
Best loss: 0.000586142833250284
Epoch 115:
Training summary: {'train_recon_loss': 0.000787836678865836, 'train_loss': 0.000787836678865836}
Evaluation summary: {'test_recon_loss': 0.000678805056747703, 'test_loss': 0.000678805056747703}
Best loss: 0.000586142833250284
Epoch 116:
Training summary: {'train_recon_loss': 0.001917329991903558, 'train_loss': 0.001917329991903558}
Evaluation summary: {'test_recon_loss': 0.0011650861643360845, 'test_loss': 0.0011650861643360845}
Best loss: 0.000586142833250284
Epoch 117:
Training summary: {'train_recon_loss': 0.0009128992205531775, 'train_loss': 0.0009128992205531775}
Evaluation summary: {'test_recon_loss': 0.000871502133408284, 'test_loss': 0.000871502133408284}
Best loss: 0.000586142833250284
Epoch 118:
Training summary: {'train_recon_loss': 0.0010444569207486037, 'train_loss': 0.0010444569207486037}
Evaluation summary: {'test_recon_loss': 0.002975880944099657, 'test_loss': 0.002975880944099657}
Best loss: 0.000586142833250284
Epoch 119:
Training summary: {'train_recon_loss': 0.0009999805290084123, 'train_loss': 0.0009999805290084123}
Evaluation summary: {'test_recon_loss': 0.0008064344698808051, 'test_loss': 0.0008064344698808051}
Best loss: 0.000586142833250284
Epoch 120:
Training summary: {'train_recon_loss': 0.0008172439586111197, 'train_loss': 0.0008172439586111197}
Evaluation summary: {'test_recon_loss': 0.0008003787521911221, 'test_loss': 0.0008003787521911221}
Best loss: 0.000586142833250284
Epoch 121:
Training summary: {'train_recon_loss': 0.0007721810988742897, 'train_loss': 0.0007721810988742897}
Evaluation summary: {'test_recon_loss': 0.0007326980255968947, 'test_loss': 0.0007326980255968947}
Best loss: 0.000586142833250284
Epoch 122:
Training summary: {'train_recon_loss': 0.0007263194228063396, 'train_loss': 0.0007263194228063396}
Evaluation summary: {'test_recon_loss': 0.0007467860867033744, 'test_loss': 0.0007467860867033744}
Best loss: 0.000586142833250284
Epoch 123:
Training summary: {'train_recon_loss': 0.001735226404108601, 'train_loss': 0.001735226404108601}
Evaluation summary: {'test_recon_loss': 0.0017281348598289527, 'test_loss': 0.0017281348598289527}
Best loss: 0.000586142833250284
Epoch 124:
Training summary: {'train_recon_loss': 0.0009866950382699021, 'train_loss': 0.0009866950382699021}
Evaluation summary: {'test_recon_loss': 0.0008002881105167784, 'test_loss': 0.0008002881105167784}
Best loss: 0.000586142833250284
Epoch 125:
Training summary: {'train_recon_loss': 0.0007621394193693407, 'train_loss': 0.0007621394193693407}
Evaluation summary: {'test_recon_loss': 0.0007173552548152033, 'test_loss': 0.0007173552548152033}
Best loss: 0.000586142833250284
Epoch 126:
Training summary: {'train_recon_loss': 0.001451436823066128, 'train_loss': 0.001451436823066128}
Evaluation summary: {'test_recon_loss': 0.0009597639273285982, 'test_loss': 0.0009597639273285982}
Best loss: 0.000586142833250284
Epoch 127:
Training summary: {'train_recon_loss': 0.0007814228182572987, 'train_loss': 0.0007814228182572987}
Evaluation summary: {'test_recon_loss': 0.0007282558820132502, 'test_loss': 0.0007282558820132502}
Best loss: 0.000586142833250284
Epoch 128:
Training summary: {'train_recon_loss': 0.0012011610364579262, 'train_loss': 0.0012011610364579262}
Evaluation summary: {'test_recon_loss': 0.0007718144957976048, 'test_loss': 0.0007718144957976048}
Best loss: 0.000586142833250284
Epoch 129:
Training summary: {'train_recon_loss': 0.0007285288890474885, 'train_loss': 0.0007285288890474885}
Evaluation summary: {'test_recon_loss': 0.0007059095503416579, 'test_loss': 0.0007059095503416579}
Best loss: 0.000586142833250284
Epoch 130:
Training summary: {'train_recon_loss': 0.0006796525794989671, 'train_loss': 0.0006796525794989671}
Evaluation summary: {'test_recon_loss': 0.0006932746428287595, 'test_loss': 0.0006932746428287595}
Best loss: 0.000586142833250284
Epoch 131:
Training summary: {'train_recon_loss': 0.0011662569838204145, 'train_loss': 0.0011662569838204145}
Evaluation summary: {'test_recon_loss': 0.001133732101185514, 'test_loss': 0.001133732101185514}
Best loss: 0.000586142833250284
Epoch 132:
Training summary: {'train_recon_loss': 0.0007770872195029148, 'train_loss': 0.0007770872195029148}
Evaluation summary: {'test_recon_loss': 0.0006857177794205374, 'test_loss': 0.0006857177794205374}
Best loss: 0.000586142833250284
Epoch 133:
Training summary: {'train_recon_loss': 0.000893532010140853, 'train_loss': 0.000893532010140853}
Evaluation summary: {'test_recon_loss': 0.00893650315766662, 'test_loss': 0.00893650315766662}
Best loss: 0.000586142833250284
Epoch 134:
Training summary: {'train_recon_loss': 0.001169161094116482, 'train_loss': 0.001169161094116482}
Evaluation summary: {'test_recon_loss': 0.0007404346026115825, 'test_loss': 0.0007404346026115825}
Best loss: 0.000586142833250284
Epoch 135:
Training summary: {'train_recon_loss': 0.0006945742789471638, 'train_loss': 0.0006945742789471638}
Evaluation summary: {'test_recon_loss': 0.0006601446674611485, 'test_loss': 0.0006601446674611485}
Best loss: 0.000586142833250284
Epoch 136:
Training summary: {'train_recon_loss': 0.00115873126978262, 'train_loss': 0.00115873126978262}
Evaluation summary: {'test_recon_loss': 0.0020907508210657143, 'test_loss': 0.0020907508210657143}
Best loss: 0.000586142833250284
Epoch 137:
Training summary: {'train_recon_loss': 0.0010452205571304845, 'train_loss': 0.0010452205571304845}
Evaluation summary: {'test_recon_loss': 0.0007531203221004263, 'test_loss': 0.0007531203221004263}
Best loss: 0.000586142833250284
Epoch 138:
Training summary: {'train_recon_loss': 0.0006995137296320848, 'train_loss': 0.0006995137296320848}
Evaluation summary: {'test_recon_loss': 0.0006669719428956375, 'test_loss': 0.0006669719428956375}
Best loss: 0.000586142833250284
Epoch 139:
Training summary: {'train_recon_loss': 0.0006920950334640913, 'train_loss': 0.0006920950334640913}
Evaluation summary: {'test_recon_loss': 0.0006530797429748512, 'test_loss': 0.0006530797429748512}
Best loss: 0.000586142833250284
Epoch 140:
Training summary: {'train_recon_loss': 0.0006862260001611175, 'train_loss': 0.0006862260001611175}
Evaluation summary: {'test_recon_loss': 0.0006899836047301374, 'test_loss': 0.0006899836047301374}
Best loss: 0.000586142833250284
Epoch 141:
Training summary: {'train_recon_loss': 0.0019244380501368793, 'train_loss': 0.0019244380501368793}
Evaluation summary: {'test_recon_loss': 0.00137015076384134, 'test_loss': 0.00137015076384134}
Best loss: 0.000586142833250284
Epoch 142:
Training summary: {'train_recon_loss': 0.0009121120224094718, 'train_loss': 0.0009121120224094718}
Evaluation summary: {'test_recon_loss': 0.0008806534361095982, 'test_loss': 0.0008806534361095982}
Best loss: 0.000586142833250284
Epoch 143:
Training summary: {'train_recon_loss': 0.0013699748007458873, 'train_loss': 0.0013699748007458873}
Evaluation summary: {'test_recon_loss': 0.0010036152727575507, 'test_loss': 0.0010036152727575507}
Best loss: 0.000586142833250284
Epoch 144:
Training summary: {'train_recon_loss': 0.0008171500035276965, 'train_loss': 0.0008171500035276965}
Evaluation summary: {'test_recon_loss': 0.0007366757992387099, 'test_loss': 0.0007366757992387099}
Best loss: 0.000586142833250284
Epoch 145:
Training summary: {'train_recon_loss': 0.0007180792766799262, 'train_loss': 0.0007180792766799262}
Evaluation summary: {'test_recon_loss': 0.0006866438698623373, 'test_loss': 0.0006866438698623373}
Best loss: 0.000586142833250284
Epoch 146:
Training summary: {'train_recon_loss': 0.001447340164394463, 'train_loss': 0.001447340164394463}
Evaluation summary: {'test_recon_loss': 0.0008684455303820019, 'test_loss': 0.0008684455303820019}
Best loss: 0.000586142833250284
Epoch 147:
Training summary: {'train_recon_loss': 0.0013347423222827535, 'train_loss': 0.0013347423222827535}
Evaluation summary: {'test_recon_loss': 0.0010932674155724983, 'test_loss': 0.0010932674155724983}
Best loss: 0.000586142833250284
Epoch 148:
Training summary: {'train_recon_loss': 0.0007942282241380809, 'train_loss': 0.0007942282241380809}
Evaluation summary: {'test_recon_loss': 0.0007041001316806864, 'test_loss': 0.0007041001316806864}
Best loss: 0.000586142833250284
Epoch 149:
Training summary: {'train_recon_loss': 0.0009768520327212535, 'train_loss': 0.0009768520327212535}
Evaluation summary: {'test_recon_loss': 0.00255447352193524, 'test_loss': 0.00255447352193524}
Best loss: 0.000586142833250284
Epoch 150:
Training summary: {'train_recon_loss': 0.0010086397205186556, 'train_loss': 0.0010086397205186556}
Evaluation summary: {'test_recon_loss': 0.0007142956118034077, 'test_loss': 0.0007142956118034077}
Best loss: 0.000586142833250284
Epoch 151:
Training summary: {'train_recon_loss': 0.0007170253088154794, 'train_loss': 0.0007170253088154794}
Evaluation summary: {'test_recon_loss': 0.0006842251968040746, 'test_loss': 0.0006842251968040746}
Best loss: 0.000586142833250284
Epoch 152:
Training summary: {'train_recon_loss': 0.0014247034128028046, 'train_loss': 0.0014247034128028046}
Evaluation summary: {'test_recon_loss': 0.0010881531750321187, 'test_loss': 0.0010881531750321187}
Best loss: 0.000586142833250284
Epoch 153:
Training summary: {'train_recon_loss': 0.0008022146179775179, 'train_loss': 0.0008022146179775179}
Evaluation summary: {'test_recon_loss': 0.0007141491988841563, 'test_loss': 0.0007141491988841563}
Best loss: 0.000586142833250284
Epoch 154:
Training summary: {'train_recon_loss': 0.0007145231915267628, 'train_loss': 0.0007145231915267628}
Evaluation summary: {'test_recon_loss': 0.0007330400557508591, 'test_loss': 0.0007330400557508591}
Best loss: 0.000586142833250284
Epoch 155:
Training summary: {'train_recon_loss': 0.0012566622911439056, 'train_loss': 0.0012566622911439056}
Evaluation summary: {'test_recon_loss': 0.0007307575543177898, 'test_loss': 0.0007307575543177898}
Best loss: 0.000586142833250284
Epoch 156:
Training summary: {'train_recon_loss': 0.0007199917347318501, 'train_loss': 0.0007199917347318501}
Evaluation summary: {'test_recon_loss': 0.000673556086987673, 'test_loss': 0.000673556086987673}
Best loss: 0.000586142833250284
Epoch 157:
Training summary: {'train_recon_loss': 0.0006897149013327397, 'train_loss': 0.0006897149013327397}
Evaluation summary: {'test_recon_loss': 0.0006520996646467381, 'test_loss': 0.0006520996646467381}
Best loss: 0.000586142833250284
Epoch 158:
Training summary: {'train_recon_loss': 0.001323057363894126, 'train_loss': 0.001323057363894126}
Evaluation summary: {'test_recon_loss': 0.002053012967987446, 'test_loss': 0.002053012967987446}
Best loss: 0.000586142833250284
Epoch 159:
Training summary: {'train_recon_loss': 0.0008500540369254458, 'train_loss': 0.0008500540369254458}
Evaluation summary: {'test_recon_loss': 0.0007327329582071458, 'test_loss': 0.0007327329582071458}
Best loss: 0.000586142833250284
Epoch 160:
Training summary: {'train_recon_loss': 0.0007042532769038407, 'train_loss': 0.0007042532769038407}
Evaluation summary: {'test_recon_loss': 0.0006633298437839934, 'test_loss': 0.0006633298437839934}
Best loss: 0.000586142833250284
Epoch 161:
Training summary: {'train_recon_loss': 0.001249190121983727, 'train_loss': 0.001249190121983727}
Evaluation summary: {'test_recon_loss': 0.0009040977331442964, 'test_loss': 0.0009040977331442964}
Best loss: 0.000586142833250284
Epoch 162:
Training summary: {'train_recon_loss': 0.0007444926009590778, 'train_loss': 0.0007444926009590778}
Evaluation summary: {'test_recon_loss': 0.0007403098561261282, 'test_loss': 0.0007403098561261282}
Best loss: 0.000586142833250284
Epoch 163:
Training summary: {'train_recon_loss': 0.0009028768095322773, 'train_loss': 0.0009028768095322773}
Evaluation summary: {'test_recon_loss': 0.0015714678439541878, 'test_loss': 0.0015714678439541878}
Best loss: 0.000586142833250284
Epoch 164:
Training summary: {'train_recon_loss': 0.0008190603960303809, 'train_loss': 0.0008190603960303809}
Evaluation summary: {'test_recon_loss': 0.0006960117574289252, 'test_loss': 0.0006960117574289252}
Best loss: 0.000586142833250284
Epoch 165:
Training summary: {'train_recon_loss': 0.0007092259066753651, 'train_loss': 0.0007092259066753651}
Evaluation summary: {'test_recon_loss': 0.000680039160904532, 'test_loss': 0.000680039160904532}
Best loss: 0.000586142833250284
Epoch 166:
Training summary: {'train_recon_loss': 0.0014545199168803239, 'train_loss': 0.0014545199168803239}
Evaluation summary: {'test_recon_loss': 0.0020598723176050208, 'test_loss': 0.0020598723176050208}
Best loss: 0.000586142833250284
Epoch 167:
Training summary: {'train_recon_loss': 0.0009253510402954862, 'train_loss': 0.0009253510402954862}
Evaluation summary: {'test_recon_loss': 0.0007007642425718922, 'test_loss': 0.0007007642425718922}
Best loss: 0.000586142833250284
Epoch 168:
Training summary: {'train_recon_loss': 0.0009763036931078392, 'train_loss': 0.0009763036931078392}
Evaluation summary: {'test_recon_loss': 0.002412550607098982, 'test_loss': 0.002412550607098982}
Best loss: 0.000586142833250284
Epoch 169:
Training summary: {'train_recon_loss': 0.0009502928799459241, 'train_loss': 0.0009502928799459241}
Evaluation summary: {'test_recon_loss': 0.0007163295450122212, 'test_loss': 0.0007163295450122212}
Best loss: 0.000586142833250284
Epoch 170:
Training summary: {'train_recon_loss': 0.0007190705128318493, 'train_loss': 0.0007190705128318493}
Evaluation summary: {'test_recon_loss': 0.0030879281200410003, 'test_loss': 0.0030879281200410003}
Best loss: 0.000586142833250284
Epoch 171:
Training summary: {'train_recon_loss': 0.0017763266603992229, 'train_loss': 0.0017763266603992229}
Evaluation summary: {'test_recon_loss': 0.00092119898011635, 'test_loss': 0.00092119898011635}
Best loss: 0.000586142833250284
Epoch 172:
Training summary: {'train_recon_loss': 0.0008106410199802619, 'train_loss': 0.0008106410199802619}
Evaluation summary: {'test_recon_loss': 0.0007248332900276644, 'test_loss': 0.0007248332900276644}
Best loss: 0.000586142833250284
Epoch 173:
Training summary: {'train_recon_loss': 0.0007097703310522802, 'train_loss': 0.0007097703310522802}
Evaluation summary: {'test_recon_loss': 0.0006685757723100785, 'test_loss': 0.0006685757723100785}
Best loss: 0.000586142833250284
Epoch 174:
Training summary: {'train_recon_loss': 0.001161878182332265, 'train_loss': 0.001161878182332265}
Evaluation summary: {'test_recon_loss': 0.0012320694044478744, 'test_loss': 0.0012320694044478744}
Best loss: 0.000586142833250284
Epoch 175:
Training summary: {'train_recon_loss': 0.0008711620838037444, 'train_loss': 0.0008711620838037444}
Evaluation summary: {'test_recon_loss': 0.003640980259525872, 'test_loss': 0.003640980259525872}
Best loss: 0.000586142833250284
Epoch 176:
Training summary: {'train_recon_loss': 0.0011656769552776545, 'train_loss': 0.0011656769552776545}
Evaluation summary: {'test_recon_loss': 0.0007235950663012199, 'test_loss': 0.0007235950663012199}
Best loss: 0.000586142833250284
Epoch 177:
Training summary: {'train_recon_loss': 0.0007082782311417659, 'train_loss': 0.0007082782311417659}
Evaluation summary: {'test_recon_loss': 0.0007051855930741446, 'test_loss': 0.0007051855930741446}
Best loss: 0.000586142833250284
Epoch 178:
Training summary: {'train_recon_loss': 0.0006717475426923025, 'train_loss': 0.0006717475426923025}
Evaluation summary: {'test_recon_loss': 0.0006597095028834228, 'test_loss': 0.0006597095028834228}
Best loss: 0.000586142833250284
Epoch 179:
generate_recon.py --datadir . --metafile /mountb/single_cell_flist/ch6_all.csv --save-dir /mountb/autoencoder/ch6 --latent-dims 2048 --ae-features --pretrained-file /mountb/autoencoder/ch6/models/best.pth
Namespace(ae_features=True, batch_size=128, datadir='.', latent_dims=2048, metafile='/mountb/single_cell_flist/ch6_all.csv', pca_features=False, pretrained_file='/mountb/autoencoder/ch6/models/best.pth', save_dir='/mountb/autoencoder/ch6')
Dataset length is 9068498
AE46(
  (encoder): Sequential(
    (0): Conv2d(1, 46, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
    (2): Conv2d(46, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (3): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): LeakyReLU(negative_slope=0.2, inplace=True)
    (5): Conv2d(92, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (6): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): LeakyReLU(negative_slope=0.2, inplace=True)
    (8): Conv2d(184, 368, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (9): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): LeakyReLU(negative_slope=0.2, inplace=True)
    (11): Conv2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (12): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (fc1): Linear(in_features=1472, out_features=2048, bias=True)
  (decoder): Sequential(
    (0): ConvTranspose2d(368, 368, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): ConvTranspose2d(368, 184, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): ConvTranspose2d(184, 92, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
    (9): ConvTranspose2d(92, 46, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace=True)
    (12): ConvTranspose2d(46, 1, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Sigmoid()
  )
  (d1): Linear(in_features=2048, out_features=1472, bias=True)
  (mseloss): MSELoss()
)
Training summary: {'train_recon_loss': 0.0014562583815383775, 'train_loss': 0.0014562583815383775}
Evaluation summary: {'test_recon_loss': 0.001764806057652564, 'test_loss': 0.001764806057652564}
Best loss: 0.000586142833250284
Epoch 180:
